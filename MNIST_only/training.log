2020-06-07 22:49:11,165 | Robust self-training
2020-06-07 22:49:11,165 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:51:46,470 | Robust self-training
2020-06-07 22:51:46,470 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:52:01,036 | Robust self-training
2020-06-07 22:52:01,036 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:52:01,551 | Training set
2020-06-07 22:52:01,552 | Number of training samples: 59001
2020-06-07 22:52:01,552 | Number of supervised samples: 59001
2020-06-07 22:52:01,552 | Number of unsup samples: 0
2020-06-07 22:52:01,559 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:52:01,560 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:52:20,991 | Robust self-training
2020-06-07 22:52:20,991 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:52:21,318 | Training set
2020-06-07 22:52:21,318 | Number of training samples: 59001
2020-06-07 22:52:21,318 | Number of supervised samples: 59001
2020-06-07 22:52:21,318 | Number of unsup samples: 0
2020-06-07 22:52:21,326 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:52:21,326 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:52:21,385 | Test set
2020-06-07 22:52:21,385 | Number of samples: 9001
2020-06-07 22:52:21,387 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 22:52:21,387 | Shape of data: (9001, 3, 32, 32)
2020-06-07 22:52:21,553 | Training set
2020-06-07 22:52:21,554 | Number of training samples: 59001
2020-06-07 22:52:21,554 | Number of supervised samples: 59001
2020-06-07 22:52:21,554 | Number of unsup samples: 0
2020-06-07 22:52:21,562 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:52:21,562 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:52:24,031 | Setting learning rate to 0.1
2020-06-07 22:53:29,983 | Robust self-training
2020-06-07 22:53:29,983 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:53:30,313 | Training set
2020-06-07 22:53:30,313 | Number of training samples: 59001
2020-06-07 22:53:30,313 | Number of supervised samples: 59001
2020-06-07 22:53:30,313 | Number of unsup samples: 0
2020-06-07 22:53:30,320 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:53:30,320 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:53:30,345 | Test set
2020-06-07 22:53:30,345 | Number of samples: 9001
2020-06-07 22:53:30,346 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 22:53:30,347 | Shape of data: (9001, 3, 32, 32)
2020-06-07 22:53:30,487 | Training set
2020-06-07 22:53:30,487 | Number of training samples: 59001
2020-06-07 22:53:30,487 | Number of supervised samples: 59001
2020-06-07 22:53:30,487 | Number of unsup samples: 0
2020-06-07 22:53:30,494 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:53:30,494 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:53:32,866 | Setting learning rate to 0.1
2020-06-07 22:53:40,727 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341400
2020-06-07 22:53:41,308 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.306215
2020-06-07 22:53:41,761 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.288552
2020-06-07 22:53:42,216 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.213340
2020-06-07 22:53:42,680 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.062618
2020-06-07 22:53:43,129 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.878494
2020-06-07 22:53:43,583 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.721252
2020-06-07 22:53:44,047 | Train Epoch: 1 [17920/59392 (30%)]	Loss: 1.378310
2020-06-07 22:53:44,507 | Train Epoch: 1 [20480/59392 (34%)]	Loss: 1.235265
2020-06-07 22:53:44,986 | Train Epoch: 1 [23040/59392 (39%)]	Loss: 0.917154
2020-06-07 22:53:45,457 | Train Epoch: 1 [25600/59392 (43%)]	Loss: 0.723060
2020-06-07 22:53:46,064 | Train Epoch: 1 [28160/59392 (47%)]	Loss: 0.779089
2020-06-07 22:53:46,518 | Train Epoch: 1 [30720/59392 (52%)]	Loss: 0.551690
2020-06-07 22:53:46,970 | Train Epoch: 1 [33280/59392 (56%)]	Loss: 0.424834
2020-06-07 22:53:47,421 | Train Epoch: 1 [35840/59392 (60%)]	Loss: 0.473872
2020-06-07 22:53:47,895 | Train Epoch: 1 [38400/59392 (65%)]	Loss: 0.308954
2020-06-07 22:53:48,345 | Train Epoch: 1 [40960/59392 (69%)]	Loss: 0.287891
2020-06-07 22:53:48,807 | Train Epoch: 1 [43520/59392 (73%)]	Loss: 0.280578
2020-06-07 22:53:49,282 | Train Epoch: 1 [46080/59392 (78%)]	Loss: 0.301528
2020-06-07 22:53:49,746 | Train Epoch: 1 [48640/59392 (82%)]	Loss: 0.246429
2020-06-07 22:53:50,198 | Train Epoch: 1 [51200/59392 (86%)]	Loss: 0.189522
2020-06-07 22:53:50,649 | Train Epoch: 1 [53760/59392 (91%)]	Loss: 0.208243
2020-06-07 22:53:51,099 | Train Epoch: 1 [56320/59392 (95%)]	Loss: 0.165446
2020-06-07 22:53:51,924 | Train Epoch: 1 [13915/59392 (99%)]	Loss: 0.189054
2020-06-07 22:53:51,985 | ================================================================================
2020-06-07 22:53:51,992 | Setting learning rate to 0.0999497
2020-06-07 22:53:52,566 | Train Epoch: 2 [0/59392 (0%)]	Loss: 0.173953
2020-06-07 22:53:53,027 | Train Epoch: 2 [2560/59392 (4%)]	Loss: 0.140983
2020-06-07 22:53:53,567 | Train Epoch: 2 [5120/59392 (9%)]	Loss: 0.172937
2020-06-07 22:53:54,033 | Train Epoch: 2 [7680/59392 (13%)]	Loss: 0.128551
2020-06-07 22:53:54,490 | Train Epoch: 2 [10240/59392 (17%)]	Loss: 0.151790
2020-06-07 22:53:54,956 | Train Epoch: 2 [12800/59392 (22%)]	Loss: 0.107701
2020-06-07 22:53:55,407 | Train Epoch: 2 [15360/59392 (26%)]	Loss: 0.114356
2020-06-07 22:53:55,878 | Train Epoch: 2 [17920/59392 (30%)]	Loss: 0.123865
2020-06-07 22:53:56,327 | Train Epoch: 2 [20480/59392 (34%)]	Loss: 0.125017
2020-06-07 22:53:56,773 | Train Epoch: 2 [23040/59392 (39%)]	Loss: 0.142136
2020-06-07 22:53:57,211 | Train Epoch: 2 [25600/59392 (43%)]	Loss: 0.112166
2020-06-07 22:53:57,663 | Train Epoch: 2 [28160/59392 (47%)]	Loss: 0.122611
2020-06-07 22:53:58,103 | Train Epoch: 2 [30720/59392 (52%)]	Loss: 0.153799
2020-06-07 22:53:58,547 | Train Epoch: 2 [33280/59392 (56%)]	Loss: 0.117863
2020-06-07 22:53:59,009 | Train Epoch: 2 [35840/59392 (60%)]	Loss: 0.112726
2020-06-07 22:53:59,534 | Train Epoch: 2 [38400/59392 (65%)]	Loss: 0.072393
2020-06-07 22:53:59,978 | Train Epoch: 2 [40960/59392 (69%)]	Loss: 0.112122
2020-06-07 22:54:00,430 | Train Epoch: 2 [43520/59392 (73%)]	Loss: 0.071024
2020-06-07 22:54:00,885 | Train Epoch: 2 [46080/59392 (78%)]	Loss: 0.090700
2020-06-07 22:54:01,336 | Train Epoch: 2 [48640/59392 (82%)]	Loss: 0.131696
2020-06-07 22:54:01,815 | Train Epoch: 2 [51200/59392 (86%)]	Loss: 0.085022
2020-06-07 22:54:02,269 | Train Epoch: 2 [53760/59392 (91%)]	Loss: 0.094642
2020-06-07 22:54:02,754 | Train Epoch: 2 [56320/59392 (95%)]	Loss: 0.068487
2020-06-07 22:54:03,204 | Train Epoch: 2 [13915/59392 (99%)]	Loss: 0.077674
2020-06-07 22:54:03,356 | ================================================================================
2020-06-07 22:54:03,362 | Setting learning rate to 0.0997987
2020-06-07 22:54:03,839 | Train Epoch: 3 [0/59392 (0%)]	Loss: 0.084988
2020-06-07 22:54:04,301 | Train Epoch: 3 [2560/59392 (4%)]	Loss: 0.072579
2020-06-07 22:54:04,820 | Train Epoch: 3 [5120/59392 (9%)]	Loss: 0.079328
2020-06-07 22:54:05,266 | Train Epoch: 3 [7680/59392 (13%)]	Loss: 0.059843
2020-06-07 22:54:05,712 | Train Epoch: 3 [10240/59392 (17%)]	Loss: 0.085529
2020-06-07 22:54:06,155 | Train Epoch: 3 [12800/59392 (22%)]	Loss: 0.059522
2020-06-07 22:54:06,618 | Train Epoch: 3 [15360/59392 (26%)]	Loss: 0.094768
2020-06-07 22:54:07,066 | Train Epoch: 3 [17920/59392 (30%)]	Loss: 0.054005
2020-06-07 22:54:07,522 | Train Epoch: 3 [20480/59392 (34%)]	Loss: 0.064953
2020-06-07 22:54:07,989 | Train Epoch: 3 [23040/59392 (39%)]	Loss: 0.056638
2020-06-07 22:54:08,434 | Train Epoch: 3 [25600/59392 (43%)]	Loss: 0.057526
2020-06-07 22:54:08,899 | Train Epoch: 3 [28160/59392 (47%)]	Loss: 0.072937
2020-06-07 22:54:09,347 | Train Epoch: 3 [30720/59392 (52%)]	Loss: 0.080478
2020-06-07 22:54:09,812 | Train Epoch: 3 [33280/59392 (56%)]	Loss: 0.078986
2020-06-07 22:54:10,261 | Train Epoch: 3 [35840/59392 (60%)]	Loss: 0.070520
2020-06-07 22:54:10,703 | Train Epoch: 3 [38400/59392 (65%)]	Loss: 0.066385
2020-06-07 22:54:11,149 | Train Epoch: 3 [40960/59392 (69%)]	Loss: 0.115571
2020-06-07 22:54:11,600 | Train Epoch: 3 [43520/59392 (73%)]	Loss: 0.065500
2020-06-07 22:54:12,052 | Train Epoch: 3 [46080/59392 (78%)]	Loss: 0.065763
2020-06-07 22:54:12,513 | Train Epoch: 3 [48640/59392 (82%)]	Loss: 0.061973
2020-06-07 22:54:12,964 | Train Epoch: 3 [51200/59392 (86%)]	Loss: 0.076952
2020-06-07 22:54:13,423 | Train Epoch: 3 [53760/59392 (91%)]	Loss: 0.060200
2020-06-07 22:54:13,892 | Train Epoch: 3 [56320/59392 (95%)]	Loss: 0.077645
2020-06-07 22:54:14,359 | Train Epoch: 3 [13915/59392 (99%)]	Loss: 0.069761
2020-06-07 22:54:14,519 | ================================================================================
2020-06-07 22:54:14,528 | Setting learning rate to 0.0995475
2020-06-07 22:54:14,907 | Train Epoch: 4 [0/59392 (0%)]	Loss: 0.053546
2020-06-07 22:54:15,372 | Train Epoch: 4 [2560/59392 (4%)]	Loss: 0.094518
2020-06-07 22:54:15,820 | Train Epoch: 4 [5120/59392 (9%)]	Loss: 0.072952
2020-06-07 22:54:16,287 | Train Epoch: 4 [7680/59392 (13%)]	Loss: 0.085677
2020-06-07 22:54:16,740 | Train Epoch: 4 [10240/59392 (17%)]	Loss: 0.041132
2020-06-07 22:54:17,266 | Train Epoch: 4 [12800/59392 (22%)]	Loss: 0.042582
2020-06-07 22:54:17,712 | Train Epoch: 4 [15360/59392 (26%)]	Loss: 0.055698
2020-06-07 22:54:18,172 | Train Epoch: 4 [17920/59392 (30%)]	Loss: 0.034937
2020-06-07 22:54:18,625 | Train Epoch: 4 [20480/59392 (34%)]	Loss: 0.037282
2020-06-07 22:54:19,085 | Train Epoch: 4 [23040/59392 (39%)]	Loss: 0.050616
2020-06-07 22:54:19,533 | Train Epoch: 4 [25600/59392 (43%)]	Loss: 0.092488
2020-06-07 22:54:19,980 | Train Epoch: 4 [28160/59392 (47%)]	Loss: 0.034791
2020-06-07 22:54:20,434 | Train Epoch: 4 [30720/59392 (52%)]	Loss: 0.055630
2020-06-07 22:54:20,881 | Train Epoch: 4 [33280/59392 (56%)]	Loss: 0.068503
2020-06-07 22:54:21,329 | Train Epoch: 4 [35840/59392 (60%)]	Loss: 0.048662
2020-06-07 22:54:21,787 | Train Epoch: 4 [38400/59392 (65%)]	Loss: 0.036375
2020-06-07 22:54:22,258 | Train Epoch: 4 [40960/59392 (69%)]	Loss: 0.073518
2020-06-07 22:54:22,703 | Train Epoch: 4 [43520/59392 (73%)]	Loss: 0.052727
2020-06-07 22:54:23,176 | Train Epoch: 4 [46080/59392 (78%)]	Loss: 0.035656
2020-06-07 22:54:23,687 | Train Epoch: 4 [48640/59392 (82%)]	Loss: 0.036871
2020-06-07 22:54:24,149 | Train Epoch: 4 [51200/59392 (86%)]	Loss: 0.030027
2020-06-07 22:54:24,619 | Train Epoch: 4 [53760/59392 (91%)]	Loss: 0.045786
2020-06-07 22:54:25,078 | Train Epoch: 4 [56320/59392 (95%)]	Loss: 0.036584
2020-06-07 22:54:25,532 | Train Epoch: 4 [13915/59392 (99%)]	Loss: 0.089719
2020-06-07 22:54:25,690 | ================================================================================
2020-06-07 22:54:37,902 | TRAIN: Clean loss: 0.2205, Clean accuracy: 55160/59001 (93.49%), PGD clean accuracy: 229/256 (89.45%), Robust accuracy 29/256 (11.33%)
2020-06-07 22:54:41,964 | TEST: Clean loss: 0.2462, Clean accuracy: 8375/9001 (93.05%), PGD clean accuracy: 237/256 (92.58%), Robust accuracy 26/256 (10.16%)
2020-06-07 22:54:41,975 | ================================================================================
2020-06-07 22:54:41,985 | Setting learning rate to 0.0991965
2020-06-07 22:54:42,494 | Train Epoch: 5 [0/59392 (0%)]	Loss: 0.038771
2020-06-07 22:54:42,986 | Train Epoch: 5 [2560/59392 (4%)]	Loss: 0.038486
2020-06-07 22:58:10,298 | Robust self-training
2020-06-07 22:58:10,299 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 22:58:10,648 | Training set
2020-06-07 22:58:10,648 | Number of training samples: 59001
2020-06-07 22:58:10,648 | Number of supervised samples: 59001
2020-06-07 22:58:10,648 | Number of unsup samples: 0
2020-06-07 22:58:10,656 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:58:10,656 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:58:10,681 | Test set
2020-06-07 22:58:10,682 | Number of samples: 9001
2020-06-07 22:58:10,683 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 22:58:10,683 | Shape of data: (9001, 3, 32, 32)
2020-06-07 22:58:10,862 | Training set
2020-06-07 22:58:10,862 | Number of training samples: 59001
2020-06-07 22:58:10,862 | Number of supervised samples: 59001
2020-06-07 22:58:10,862 | Number of unsup samples: 0
2020-06-07 22:58:10,869 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 22:58:10,869 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 22:58:13,275 | Setting learning rate to 0.1
2020-06-07 23:00:19,201 | Robust self-training
2020-06-07 23:00:19,201 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=1, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:00:19,515 | Training set
2020-06-07 23:00:19,515 | Number of training samples: 59001
2020-06-07 23:00:19,515 | Number of supervised samples: 59001
2020-06-07 23:00:19,515 | Number of unsup samples: 0
2020-06-07 23:00:19,522 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:00:19,522 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:00:19,546 | Test set
2020-06-07 23:00:19,546 | Number of samples: 9001
2020-06-07 23:00:19,547 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:00:19,547 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:00:19,701 | Training set
2020-06-07 23:00:19,701 | Number of training samples: 59001
2020-06-07 23:00:19,701 | Number of supervised samples: 59001
2020-06-07 23:00:19,702 | Number of unsup samples: 0
2020-06-07 23:00:19,709 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:00:19,710 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:00:22,148 | Setting learning rate to 0.1
2020-06-07 23:00:32,007 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:00:35,891 | Robust self-training
2020-06-07 23:00:35,891 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=1, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:00:36,161 | Training set
2020-06-07 23:00:36,161 | Number of training samples: 59001
2020-06-07 23:00:36,161 | Number of supervised samples: 59001
2020-06-07 23:00:36,161 | Number of unsup samples: 0
2020-06-07 23:00:36,168 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:00:36,168 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:00:36,192 | Test set
2020-06-07 23:00:36,192 | Number of samples: 9001
2020-06-07 23:00:36,193 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:00:36,193 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:00:36,350 | Training set
2020-06-07 23:00:36,350 | Number of training samples: 59001
2020-06-07 23:00:36,350 | Number of supervised samples: 59001
2020-06-07 23:00:36,350 | Number of unsup samples: 0
2020-06-07 23:00:36,357 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:00:36,357 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:00:38,750 | Setting learning rate to 0.1
2020-06-07 23:00:46,654 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:00:46,852 | Train Epoch: 1 [512/59392 (1%)]	Loss: 2.306454
2020-06-07 23:00:46,942 | Train Epoch: 1 [1024/59392 (2%)]	Loss: 2.300607
2020-06-07 23:00:47,036 | Train Epoch: 1 [1536/59392 (3%)]	Loss: 2.305988
2020-06-07 23:00:47,132 | Train Epoch: 1 [2048/59392 (3%)]	Loss: 2.307961
2020-06-07 23:00:47,224 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.301603
2020-06-07 23:00:47,318 | Train Epoch: 1 [3072/59392 (5%)]	Loss: 2.300726
2020-06-07 23:00:47,414 | Train Epoch: 1 [3584/59392 (6%)]	Loss: 2.283310
2020-06-07 23:00:47,508 | Train Epoch: 1 [4096/59392 (7%)]	Loss: 2.300181
2020-06-07 23:00:47,601 | Train Epoch: 1 [4608/59392 (8%)]	Loss: 2.283688
2020-06-07 23:00:47,696 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.293721
2020-06-07 23:00:47,791 | Train Epoch: 1 [5632/59392 (9%)]	Loss: 2.276481
2020-06-07 23:00:47,886 | Train Epoch: 1 [6144/59392 (10%)]	Loss: 2.267066
2020-06-07 23:00:47,978 | Train Epoch: 1 [6656/59392 (11%)]	Loss: 2.272550
2020-06-07 23:00:48,070 | Train Epoch: 1 [7168/59392 (12%)]	Loss: 2.245646
2020-06-07 23:00:48,162 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.218565
2020-06-07 23:00:48,254 | Train Epoch: 1 [8192/59392 (14%)]	Loss: 2.201517
2020-06-07 23:00:48,348 | Train Epoch: 1 [8704/59392 (15%)]	Loss: 2.182321
2020-06-07 23:00:48,441 | Train Epoch: 1 [9216/59392 (16%)]	Loss: 2.166839
2020-06-07 23:00:48,533 | Train Epoch: 1 [9728/59392 (16%)]	Loss: 2.197045
2020-06-07 23:00:48,627 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.101134
2020-06-07 23:00:48,720 | Train Epoch: 1 [10752/59392 (18%)]	Loss: 2.100027
2020-06-07 23:00:48,825 | Train Epoch: 1 [11264/59392 (19%)]	Loss: 2.055834
2020-06-07 23:00:48,917 | Train Epoch: 1 [11776/59392 (20%)]	Loss: 2.003493
2020-06-07 23:00:49,010 | Train Epoch: 1 [12288/59392 (21%)]	Loss: 1.955101
2020-06-07 23:00:49,105 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.919082
2020-06-07 23:00:49,209 | Train Epoch: 1 [13312/59392 (22%)]	Loss: 1.883729
2020-06-07 23:00:49,303 | Train Epoch: 1 [13824/59392 (23%)]	Loss: 1.896348
2020-06-07 23:00:49,394 | Train Epoch: 1 [14336/59392 (24%)]	Loss: 1.976845
2020-06-07 23:00:49,485 | Train Epoch: 1 [14848/59392 (25%)]	Loss: 1.796874
2020-06-07 23:00:49,587 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.721189
2020-06-07 23:00:49,690 | Train Epoch: 1 [15872/59392 (27%)]	Loss: 1.703694
2020-06-07 23:00:49,795 | Train Epoch: 1 [16384/59392 (28%)]	Loss: 1.602722
2020-06-07 23:00:49,888 | Train Epoch: 1 [16896/59392 (28%)]	Loss: 1.615807
2020-06-07 23:00:49,983 | Train Epoch: 1 [17408/59392 (29%)]	Loss: 1.670199
2020-06-07 23:00:50,075 | Train Epoch: 1 [17920/59392 (30%)]	Loss: 1.472515
2020-06-07 23:00:50,167 | Train Epoch: 1 [18432/59392 (31%)]	Loss: 1.483381
2020-06-07 23:00:50,258 | Train Epoch: 1 [18944/59392 (32%)]	Loss: 1.447863
2020-06-07 23:00:50,350 | Train Epoch: 1 [19456/59392 (33%)]	Loss: 1.469923
2020-06-07 23:00:50,443 | Train Epoch: 1 [19968/59392 (34%)]	Loss: 1.402967
2020-06-07 23:00:50,536 | Train Epoch: 1 [20480/59392 (34%)]	Loss: 1.330848
2020-06-07 23:00:50,630 | Train Epoch: 1 [20992/59392 (35%)]	Loss: 1.226602
2020-06-07 23:00:50,724 | Train Epoch: 1 [21504/59392 (36%)]	Loss: 1.233251
2020-06-07 23:00:50,824 | Train Epoch: 1 [22016/59392 (37%)]	Loss: 1.156597
2020-06-07 23:00:50,918 | Train Epoch: 1 [22528/59392 (38%)]	Loss: 1.062805
2020-06-07 23:00:51,010 | Train Epoch: 1 [23040/59392 (39%)]	Loss: 1.019626
2020-06-07 23:00:51,103 | Train Epoch: 1 [23552/59392 (40%)]	Loss: 1.027767
2020-06-07 23:00:51,199 | Train Epoch: 1 [24064/59392 (41%)]	Loss: 0.947444
2020-06-07 23:00:51,291 | Train Epoch: 1 [24576/59392 (41%)]	Loss: 0.968354
2020-06-07 23:00:51,382 | Train Epoch: 1 [25088/59392 (42%)]	Loss: 0.880094
2020-06-07 23:00:51,474 | Train Epoch: 1 [25600/59392 (43%)]	Loss: 0.802983
2020-06-07 23:00:51,709 | Train Epoch: 1 [26112/59392 (44%)]	Loss: 0.855820
2020-06-07 23:00:51,812 | Train Epoch: 1 [26624/59392 (45%)]	Loss: 0.842583
2020-06-07 23:00:51,909 | Train Epoch: 1 [27136/59392 (46%)]	Loss: 0.777890
2020-06-07 23:00:52,000 | Train Epoch: 1 [27648/59392 (47%)]	Loss: 0.757069
2020-06-07 23:00:52,097 | Train Epoch: 1 [28160/59392 (47%)]	Loss: 0.653212
2020-06-07 23:00:52,192 | Train Epoch: 1 [28672/59392 (48%)]	Loss: 0.601654
2020-06-07 23:00:52,285 | Train Epoch: 1 [29184/59392 (49%)]	Loss: 0.558266
2020-06-07 23:00:52,377 | Train Epoch: 1 [29696/59392 (50%)]	Loss: 0.571821
2020-06-07 23:00:52,483 | Train Epoch: 1 [30208/59392 (51%)]	Loss: 0.559967
2020-06-07 23:00:52,576 | Train Epoch: 1 [30720/59392 (52%)]	Loss: 0.517244
2020-06-07 23:00:52,667 | Train Epoch: 1 [31232/59392 (53%)]	Loss: 0.498071
2020-06-07 23:00:52,762 | Train Epoch: 1 [31744/59392 (53%)]	Loss: 0.429927
2020-06-07 23:00:52,857 | Train Epoch: 1 [32256/59392 (54%)]	Loss: 0.464453
2020-06-07 23:00:52,963 | Train Epoch: 1 [32768/59392 (55%)]	Loss: 0.447304
2020-06-07 23:00:53,062 | Train Epoch: 1 [33280/59392 (56%)]	Loss: 0.385169
2020-06-07 23:00:53,163 | Train Epoch: 1 [33792/59392 (57%)]	Loss: 0.523541
2020-06-07 23:00:53,265 | Train Epoch: 1 [34304/59392 (58%)]	Loss: 0.456777
2020-06-07 23:00:53,360 | Train Epoch: 1 [34816/59392 (59%)]	Loss: 0.452784
2020-06-07 23:00:53,451 | Train Epoch: 1 [35328/59392 (59%)]	Loss: 0.329400
2020-06-07 23:00:53,545 | Train Epoch: 1 [35840/59392 (60%)]	Loss: 0.398361
2020-06-07 23:00:53,638 | Train Epoch: 1 [36352/59392 (61%)]	Loss: 0.381843
2020-06-07 23:00:53,742 | Train Epoch: 1 [36864/59392 (62%)]	Loss: 0.371931
2020-06-07 23:00:53,832 | Train Epoch: 1 [37376/59392 (63%)]	Loss: 0.325746
2020-06-07 23:00:53,939 | Train Epoch: 1 [37888/59392 (64%)]	Loss: 0.330444
2020-06-07 23:00:54,042 | Train Epoch: 1 [38400/59392 (65%)]	Loss: 0.263685
2020-06-07 23:00:54,153 | Train Epoch: 1 [38912/59392 (66%)]	Loss: 0.294335
2020-06-07 23:00:54,258 | Train Epoch: 1 [39424/59392 (66%)]	Loss: 0.314718
2020-06-07 23:00:54,351 | Train Epoch: 1 [39936/59392 (67%)]	Loss: 0.307566
2020-06-07 23:00:54,449 | Train Epoch: 1 [40448/59392 (68%)]	Loss: 0.283320
2020-06-07 23:00:54,546 | Train Epoch: 1 [40960/59392 (69%)]	Loss: 0.291908
2020-06-07 23:00:54,643 | Train Epoch: 1 [41472/59392 (70%)]	Loss: 0.259208
2020-06-07 23:00:54,734 | Train Epoch: 1 [41984/59392 (71%)]	Loss: 0.277907
2020-06-07 23:00:54,837 | Train Epoch: 1 [42496/59392 (72%)]	Loss: 0.254545
2020-06-07 23:00:54,928 | Train Epoch: 1 [43008/59392 (72%)]	Loss: 0.229039
2020-06-07 23:00:55,020 | Train Epoch: 1 [43520/59392 (73%)]	Loss: 0.301072
2020-06-07 23:00:55,113 | Train Epoch: 1 [44032/59392 (74%)]	Loss: 0.271403
2020-06-07 23:00:55,208 | Train Epoch: 1 [44544/59392 (75%)]	Loss: 0.313486
2020-06-07 23:00:55,303 | Train Epoch: 1 [45056/59392 (76%)]	Loss: 0.274104
2020-06-07 23:00:55,395 | Train Epoch: 1 [45568/59392 (77%)]	Loss: 0.197224
2020-06-07 23:00:55,493 | Train Epoch: 1 [46080/59392 (78%)]	Loss: 0.303300
2020-06-07 23:00:55,584 | Train Epoch: 1 [46592/59392 (78%)]	Loss: 0.274074
2020-06-07 23:00:55,698 | Train Epoch: 1 [47104/59392 (79%)]	Loss: 0.240283
2020-06-07 23:00:55,789 | Train Epoch: 1 [47616/59392 (80%)]	Loss: 0.200211
2020-06-07 23:00:55,882 | Train Epoch: 1 [48128/59392 (81%)]	Loss: 0.234160
2020-06-07 23:00:55,975 | Train Epoch: 1 [48640/59392 (82%)]	Loss: 0.227904
2020-06-07 23:00:56,075 | Train Epoch: 1 [49152/59392 (83%)]	Loss: 0.246755
2020-06-07 23:00:56,174 | Train Epoch: 1 [49664/59392 (84%)]	Loss: 0.230401
2020-06-07 23:00:56,268 | Train Epoch: 1 [50176/59392 (84%)]	Loss: 0.227040
2020-06-07 23:00:56,366 | Train Epoch: 1 [50688/59392 (85%)]	Loss: 0.277929
2020-06-07 23:00:56,469 | Train Epoch: 1 [51200/59392 (86%)]	Loss: 0.193278
2020-06-07 23:00:56,577 | Train Epoch: 1 [51712/59392 (87%)]	Loss: 0.156287
2020-06-07 23:00:56,687 | Train Epoch: 1 [52224/59392 (88%)]	Loss: 0.186371
2020-06-07 23:00:56,792 | Train Epoch: 1 [52736/59392 (89%)]	Loss: 0.201656
2020-06-07 23:00:56,884 | Train Epoch: 1 [53248/59392 (90%)]	Loss: 0.206726
2020-06-07 23:00:56,986 | Train Epoch: 1 [53760/59392 (91%)]	Loss: 0.172317
2020-06-07 23:00:57,083 | Train Epoch: 1 [54272/59392 (91%)]	Loss: 0.227686
2020-06-07 23:00:57,182 | Train Epoch: 1 [54784/59392 (92%)]	Loss: 0.182767
2020-06-07 23:00:57,272 | Train Epoch: 1 [55296/59392 (93%)]	Loss: 0.191540
2020-06-07 23:00:57,371 | Train Epoch: 1 [55808/59392 (94%)]	Loss: 0.152168
2020-06-07 23:00:57,475 | Train Epoch: 1 [56320/59392 (95%)]	Loss: 0.162527
2020-06-07 23:00:57,574 | Train Epoch: 1 [56832/59392 (96%)]	Loss: 0.175132
2020-06-07 23:00:57,664 | Train Epoch: 1 [57344/59392 (97%)]	Loss: 0.197808
2020-06-07 23:00:57,775 | Train Epoch: 1 [57856/59392 (97%)]	Loss: 0.213185
2020-06-07 23:00:57,870 | Train Epoch: 1 [58368/59392 (98%)]	Loss: 0.184801
2020-06-07 23:00:58,319 | Train Epoch: 1 [13915/59392 (99%)]	Loss: 0.149670
2020-06-07 23:00:58,394 | ================================================================================
2020-06-07 23:00:58,403 | Setting learning rate to 0.0999497
2020-06-07 23:00:58,915 | Train Epoch: 2 [0/59392 (0%)]	Loss: 0.169869
2020-06-07 23:00:59,009 | Train Epoch: 2 [512/59392 (1%)]	Loss: 0.147883
2020-06-07 23:00:59,101 | Train Epoch: 2 [1024/59392 (2%)]	Loss: 0.199890
2020-06-07 23:00:59,193 | Train Epoch: 2 [1536/59392 (3%)]	Loss: 0.182388
2020-06-07 23:00:59,286 | Train Epoch: 2 [2048/59392 (3%)]	Loss: 0.132836
2020-06-07 23:00:59,390 | Train Epoch: 2 [2560/59392 (4%)]	Loss: 0.137087
2020-06-07 23:00:59,483 | Train Epoch: 2 [3072/59392 (5%)]	Loss: 0.127575
2020-06-07 23:03:05,102 | Robust self-training
2020-06-07 23:03:05,102 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=1, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:03:05,405 | Training set
2020-06-07 23:03:05,405 | Number of training samples: 59001
2020-06-07 23:03:05,405 | Number of supervised samples: 59001
2020-06-07 23:03:05,405 | Number of unsup samples: 0
2020-06-07 23:03:05,412 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:03:05,413 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:03:05,438 | Test set
2020-06-07 23:03:05,438 | Number of samples: 9001
2020-06-07 23:03:05,439 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:03:05,439 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:03:05,602 | Training set
2020-06-07 23:03:05,602 | Number of training samples: 59001
2020-06-07 23:03:05,602 | Number of supervised samples: 59001
2020-06-07 23:03:05,602 | Number of unsup samples: 0
2020-06-07 23:03:05,610 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:03:05,610 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:03:07,951 | Setting learning rate to 0.1
2020-06-07 23:03:15,695 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:03:15,873 | Train Epoch: 1 [512/59392 (1%)]	Loss: 2.306443
2020-06-07 23:03:15,967 | Train Epoch: 1 [1024/59392 (2%)]	Loss: 2.299851
2020-06-07 23:03:16,060 | Train Epoch: 1 [1536/59392 (3%)]	Loss: 2.303766
2020-06-07 23:03:16,154 | Train Epoch: 1 [2048/59392 (3%)]	Loss: 2.303133
2020-06-07 23:03:16,245 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.302070
2020-06-07 23:03:16,342 | Train Epoch: 1 [3072/59392 (5%)]	Loss: 2.299423
2020-06-07 23:03:16,434 | Train Epoch: 1 [3584/59392 (6%)]	Loss: 2.274154
2020-06-07 23:03:16,524 | Train Epoch: 1 [4096/59392 (7%)]	Loss: 2.295966
2020-06-07 23:03:16,615 | Train Epoch: 1 [4608/59392 (8%)]	Loss: 2.277584
2020-06-07 23:03:16,706 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.283311
2020-06-07 23:03:16,796 | Train Epoch: 1 [5632/59392 (9%)]	Loss: 2.256814
2020-06-07 23:03:16,887 | Train Epoch: 1 [6144/59392 (10%)]	Loss: 2.247999
2020-06-07 23:03:16,981 | Train Epoch: 1 [6656/59392 (11%)]	Loss: 2.238869
2020-06-07 23:03:17,070 | Train Epoch: 1 [7168/59392 (12%)]	Loss: 2.235950
2020-06-07 23:03:17,159 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.186033
2020-06-07 23:03:17,249 | Train Epoch: 1 [8192/59392 (14%)]	Loss: 2.173147
2020-06-07 23:03:17,342 | Train Epoch: 1 [8704/59392 (15%)]	Loss: 2.142786
2020-06-07 23:03:17,436 | Train Epoch: 1 [9216/59392 (16%)]	Loss: 2.090777
2020-06-07 23:03:17,527 | Train Epoch: 1 [9728/59392 (16%)]	Loss: 2.132032
2020-06-07 23:03:17,617 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.057386
2020-06-07 23:03:17,710 | Train Epoch: 1 [10752/59392 (18%)]	Loss: 2.039365
2020-06-07 23:03:17,801 | Train Epoch: 1 [11264/59392 (19%)]	Loss: 1.998824
2020-06-07 23:03:17,895 | Train Epoch: 1 [11776/59392 (20%)]	Loss: 2.016321
2020-06-07 23:03:17,985 | Train Epoch: 1 [12288/59392 (21%)]	Loss: 2.052228
2020-06-07 23:03:18,077 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.877851
2020-06-07 23:03:18,166 | Train Epoch: 1 [13312/59392 (22%)]	Loss: 1.835448
2020-06-07 23:03:18,258 | Train Epoch: 1 [13824/59392 (23%)]	Loss: 1.800690
2020-06-07 23:03:18,349 | Train Epoch: 1 [14336/59392 (24%)]	Loss: 1.772423
2020-06-07 23:03:18,439 | Train Epoch: 1 [14848/59392 (25%)]	Loss: 1.694748
2020-06-07 23:03:18,529 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.595159
2020-06-07 23:03:18,619 | Train Epoch: 1 [15872/59392 (27%)]	Loss: 1.597756
2020-06-07 23:03:18,717 | Train Epoch: 1 [16384/59392 (28%)]	Loss: 1.498878
2020-06-07 23:03:18,810 | Train Epoch: 1 [16896/59392 (28%)]	Loss: 1.541053
2020-06-07 23:03:18,908 | Train Epoch: 1 [17408/59392 (29%)]	Loss: 1.591331
2020-06-07 23:03:18,997 | Train Epoch: 1 [17920/59392 (30%)]	Loss: 1.404823
2020-06-07 23:03:19,090 | Train Epoch: 1 [18432/59392 (31%)]	Loss: 1.371984
2020-06-07 23:03:19,179 | Train Epoch: 1 [18944/59392 (32%)]	Loss: 1.361307
2020-06-07 23:03:19,269 | Train Epoch: 1 [19456/59392 (33%)]	Loss: 1.275856
2020-06-07 23:03:19,364 | Train Epoch: 1 [19968/59392 (34%)]	Loss: 1.194817
2020-06-07 23:03:19,454 | Train Epoch: 1 [20480/59392 (34%)]	Loss: 1.191058
2020-06-07 23:03:19,546 | Train Epoch: 1 [20992/59392 (35%)]	Loss: 1.135666
2020-06-07 23:03:19,638 | Train Epoch: 1 [21504/59392 (36%)]	Loss: 1.135252
2020-06-07 23:03:19,730 | Train Epoch: 1 [22016/59392 (37%)]	Loss: 1.167755
2020-06-07 23:03:19,825 | Train Epoch: 1 [22528/59392 (38%)]	Loss: 1.098765
2020-06-07 23:03:19,918 | Train Epoch: 1 [23040/59392 (39%)]	Loss: 1.012978
2020-06-07 23:03:20,009 | Train Epoch: 1 [23552/59392 (40%)]	Loss: 0.965492
2020-06-07 23:03:20,100 | Train Epoch: 1 [24064/59392 (41%)]	Loss: 0.919103
2020-06-07 23:03:20,194 | Train Epoch: 1 [24576/59392 (41%)]	Loss: 0.872946
2020-06-07 23:03:20,283 | Train Epoch: 1 [25088/59392 (42%)]	Loss: 0.815073
2020-06-07 23:03:20,372 | Train Epoch: 1 [25600/59392 (43%)]	Loss: 0.717998
2020-06-07 23:03:20,540 | Train Epoch: 1 [26112/59392 (44%)]	Loss: 0.701628
2020-06-07 23:03:20,634 | Train Epoch: 1 [26624/59392 (45%)]	Loss: 0.708642
2020-06-07 23:03:20,723 | Train Epoch: 1 [27136/59392 (46%)]	Loss: 0.735912
2020-06-07 23:03:20,813 | Train Epoch: 1 [27648/59392 (47%)]	Loss: 0.796965
2020-06-07 23:03:20,904 | Train Epoch: 1 [28160/59392 (47%)]	Loss: 0.692267
2020-06-07 23:03:20,994 | Train Epoch: 1 [28672/59392 (48%)]	Loss: 0.645204
2020-06-07 23:03:21,083 | Train Epoch: 1 [29184/59392 (49%)]	Loss: 0.545614
2020-06-07 23:03:21,173 | Train Epoch: 1 [29696/59392 (50%)]	Loss: 0.543128
2020-06-07 23:03:21,263 | Train Epoch: 1 [30208/59392 (51%)]	Loss: 0.585990
2020-06-07 23:03:21,355 | Train Epoch: 1 [30720/59392 (52%)]	Loss: 0.514498
2020-06-07 23:03:21,445 | Train Epoch: 1 [31232/59392 (53%)]	Loss: 0.470596
2020-06-07 23:03:21,536 | Train Epoch: 1 [31744/59392 (53%)]	Loss: 0.371621
2020-06-07 23:03:21,627 | Train Epoch: 1 [32256/59392 (54%)]	Loss: 0.440840
2020-06-07 23:03:21,719 | Train Epoch: 1 [32768/59392 (55%)]	Loss: 0.373372
2020-06-07 23:03:21,811 | Train Epoch: 1 [33280/59392 (56%)]	Loss: 0.384617
2020-06-07 23:03:21,902 | Train Epoch: 1 [33792/59392 (57%)]	Loss: 0.502115
2020-06-07 23:03:21,998 | Train Epoch: 1 [34304/59392 (58%)]	Loss: 0.415101
2020-06-07 23:03:22,089 | Train Epoch: 1 [34816/59392 (59%)]	Loss: 0.410312
2020-06-07 23:03:22,182 | Train Epoch: 1 [35328/59392 (59%)]	Loss: 0.332329
2020-06-07 23:03:22,277 | Train Epoch: 1 [35840/59392 (60%)]	Loss: 0.392005
2020-06-07 23:03:22,368 | Train Epoch: 1 [36352/59392 (61%)]	Loss: 0.404690
2020-06-07 23:03:22,462 | Train Epoch: 1 [36864/59392 (62%)]	Loss: 0.355696
2020-06-07 23:03:22,555 | Train Epoch: 1 [37376/59392 (63%)]	Loss: 0.305078
2020-06-07 23:03:22,649 | Train Epoch: 1 [37888/59392 (64%)]	Loss: 0.312413
2020-06-07 23:03:22,737 | Train Epoch: 1 [38400/59392 (65%)]	Loss: 0.275272
2020-06-07 23:03:22,833 | Train Epoch: 1 [38912/59392 (66%)]	Loss: 0.282946
2020-06-07 23:03:22,938 | Train Epoch: 1 [39424/59392 (66%)]	Loss: 0.297041
2020-06-07 23:03:23,029 | Train Epoch: 1 [39936/59392 (67%)]	Loss: 0.317852
2020-06-07 23:03:23,121 | Train Epoch: 1 [40448/59392 (68%)]	Loss: 0.301689
2020-06-07 23:03:23,215 | Train Epoch: 1 [40960/59392 (69%)]	Loss: 0.266608
2020-06-07 23:03:23,319 | Train Epoch: 1 [41472/59392 (70%)]	Loss: 0.256245
2020-06-07 23:03:23,411 | Train Epoch: 1 [41984/59392 (71%)]	Loss: 0.307252
2020-06-07 23:03:23,513 | Train Epoch: 1 [42496/59392 (72%)]	Loss: 0.283173
2020-06-07 23:03:23,609 | Train Epoch: 1 [43008/59392 (72%)]	Loss: 0.257990
2020-06-07 23:03:23,698 | Train Epoch: 1 [43520/59392 (73%)]	Loss: 0.285272
2020-06-07 23:03:23,795 | Train Epoch: 1 [44032/59392 (74%)]	Loss: 0.254831
2020-06-07 23:03:23,896 | Train Epoch: 1 [44544/59392 (75%)]	Loss: 0.326667
2020-06-07 23:03:23,997 | Train Epoch: 1 [45056/59392 (76%)]	Loss: 0.250803
2020-06-07 23:03:24,096 | Train Epoch: 1 [45568/59392 (77%)]	Loss: 0.194552
2020-06-07 23:03:24,185 | Train Epoch: 1 [46080/59392 (78%)]	Loss: 0.260496
2020-06-07 23:03:24,287 | Train Epoch: 1 [46592/59392 (78%)]	Loss: 0.280929
2020-06-07 23:03:24,380 | Train Epoch: 1 [47104/59392 (79%)]	Loss: 0.260427
2020-06-07 23:03:24,484 | Train Epoch: 1 [47616/59392 (80%)]	Loss: 0.236305
2020-06-07 23:03:24,582 | Train Epoch: 1 [48128/59392 (81%)]	Loss: 0.264399
2020-06-07 23:03:24,679 | Train Epoch: 1 [48640/59392 (82%)]	Loss: 0.225271
2020-06-07 23:03:24,785 | Train Epoch: 1 [49152/59392 (83%)]	Loss: 0.242128
2020-06-07 23:03:24,879 | Train Epoch: 1 [49664/59392 (84%)]	Loss: 0.253617
2020-06-07 23:03:24,969 | Train Epoch: 1 [50176/59392 (84%)]	Loss: 0.217021
2020-06-07 23:03:25,072 | Train Epoch: 1 [50688/59392 (85%)]	Loss: 0.291888
2020-06-07 23:03:25,161 | Train Epoch: 1 [51200/59392 (86%)]	Loss: 0.183106
2020-06-07 23:03:25,254 | Train Epoch: 1 [51712/59392 (87%)]	Loss: 0.164783
2020-06-07 23:03:25,346 | Train Epoch: 1 [52224/59392 (88%)]	Loss: 0.192891
2020-06-07 23:03:25,443 | Train Epoch: 1 [52736/59392 (89%)]	Loss: 0.179092
2020-06-07 23:03:25,554 | Train Epoch: 1 [53248/59392 (90%)]	Loss: 0.182338
2020-06-07 23:03:25,642 | Train Epoch: 1 [53760/59392 (91%)]	Loss: 0.188075
2020-06-07 23:03:25,735 | Train Epoch: 1 [54272/59392 (91%)]	Loss: 0.190142
2020-06-07 23:03:25,829 | Train Epoch: 1 [54784/59392 (92%)]	Loss: 0.178130
2020-06-07 23:03:25,920 | Train Epoch: 1 [55296/59392 (93%)]	Loss: 0.176882
2020-06-07 23:03:26,024 | Train Epoch: 1 [55808/59392 (94%)]	Loss: 0.175136
2020-06-07 23:03:26,116 | Train Epoch: 1 [56320/59392 (95%)]	Loss: 0.140608
2020-06-07 23:03:26,209 | Train Epoch: 1 [56832/59392 (96%)]	Loss: 0.180903
2020-06-07 23:03:26,303 | Train Epoch: 1 [57344/59392 (97%)]	Loss: 0.208971
2020-06-07 23:03:26,413 | Train Epoch: 1 [57856/59392 (97%)]	Loss: 0.158163
2020-06-07 23:03:36,007 | Train Epoch: 1 [58368/59392 (98%)]	Loss: 0.169244
2020-06-07 23:04:43,947 | Robust self-training
2020-06-07 23:04:43,948 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=1, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:04:44,280 | Training set
2020-06-07 23:04:44,280 | Number of training samples: 59001
2020-06-07 23:04:44,280 | Number of supervised samples: 59001
2020-06-07 23:04:44,280 | Number of unsup samples: 0
2020-06-07 23:04:44,288 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:04:44,288 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:04:44,312 | Test set
2020-06-07 23:04:44,312 | Number of samples: 9001
2020-06-07 23:04:44,313 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:04:44,314 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:04:44,495 | Training set
2020-06-07 23:04:44,495 | Number of training samples: 59001
2020-06-07 23:04:44,496 | Number of supervised samples: 59001
2020-06-07 23:04:44,496 | Number of unsup samples: 0
2020-06-07 23:04:44,503 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:04:44,504 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:04:46,974 | Setting learning rate to 0.1
2020-06-07 23:04:54,799 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:04:54,975 | Train Epoch: 1 [512/59392 (1%)]	Loss: 2.306454
2020-06-07 23:04:55,076 | Train Epoch: 1 [1024/59392 (2%)]	Loss: 2.300462
2020-06-07 23:04:55,168 | Train Epoch: 1 [1536/59392 (3%)]	Loss: 2.304583
2020-06-07 23:04:55,266 | Train Epoch: 1 [2048/59392 (3%)]	Loss: 2.306813
2020-06-07 23:04:55,357 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.304659
2020-06-07 23:04:55,445 | Train Epoch: 1 [3072/59392 (5%)]	Loss: 2.301457
2020-06-07 23:04:55,537 | Train Epoch: 1 [3584/59392 (6%)]	Loss: 2.276533
2020-06-07 23:04:55,626 | Train Epoch: 1 [4096/59392 (7%)]	Loss: 2.299925
2020-06-07 23:04:55,716 | Train Epoch: 1 [4608/59392 (8%)]	Loss: 2.292305
2020-06-07 23:04:55,808 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.291454
2020-06-07 23:04:55,894 | Train Epoch: 1 [5632/59392 (9%)]	Loss: 2.278302
2020-06-07 23:04:55,981 | Train Epoch: 1 [6144/59392 (10%)]	Loss: 2.271218
2020-06-07 23:04:56,077 | Train Epoch: 1 [6656/59392 (11%)]	Loss: 2.275932
2020-06-07 23:04:56,174 | Train Epoch: 1 [7168/59392 (12%)]	Loss: 2.252095
2020-06-07 23:04:56,261 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.222765
2020-06-07 23:04:56,346 | Train Epoch: 1 [8192/59392 (14%)]	Loss: 2.205889
2020-06-07 23:04:56,433 | Train Epoch: 1 [8704/59392 (15%)]	Loss: 2.191115
2020-06-07 23:04:56,519 | Train Epoch: 1 [9216/59392 (16%)]	Loss: 2.150340
2020-06-07 23:04:56,604 | Train Epoch: 1 [9728/59392 (16%)]	Loss: 2.157129
2020-06-07 23:04:56,690 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.092802
2020-06-07 23:04:56,775 | Train Epoch: 1 [10752/59392 (18%)]	Loss: 2.088150
2020-06-07 23:04:56,862 | Train Epoch: 1 [11264/59392 (19%)]	Loss: 2.058360
2020-06-07 23:04:56,947 | Train Epoch: 1 [11776/59392 (20%)]	Loss: 1.973129
2020-06-07 23:04:57,037 | Train Epoch: 1 [12288/59392 (21%)]	Loss: 1.919537
2020-06-07 23:04:57,123 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.887911
2020-06-07 23:04:57,209 | Train Epoch: 1 [13312/59392 (22%)]	Loss: 1.825493
2020-06-07 23:04:57,298 | Train Epoch: 1 [13824/59392 (23%)]	Loss: 1.796211
2020-06-07 23:04:57,385 | Train Epoch: 1 [14336/59392 (24%)]	Loss: 1.853614
2020-06-07 23:04:57,472 | Train Epoch: 1 [14848/59392 (25%)]	Loss: 1.840908
2020-06-07 23:04:57,557 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.710974
2020-06-07 23:04:57,643 | Train Epoch: 1 [15872/59392 (27%)]	Loss: 1.644392
2020-06-07 23:04:57,729 | Train Epoch: 1 [16384/59392 (28%)]	Loss: 1.564330
2020-06-07 23:04:57,815 | Train Epoch: 1 [16896/59392 (28%)]	Loss: 1.552356
2020-06-07 23:04:57,902 | Train Epoch: 1 [17408/59392 (29%)]	Loss: 1.589493
2020-06-07 23:04:58,001 | Train Epoch: 1 [17920/59392 (30%)]	Loss: 1.463682
2020-06-07 23:04:58,090 | Train Epoch: 1 [18432/59392 (31%)]	Loss: 1.432072
2020-06-07 23:04:58,184 | Train Epoch: 1 [18944/59392 (32%)]	Loss: 1.511703
2020-06-07 23:04:58,272 | Train Epoch: 1 [19456/59392 (33%)]	Loss: 1.431798
2020-06-07 23:04:58,360 | Train Epoch: 1 [19968/59392 (34%)]	Loss: 1.260138
2020-06-07 23:04:58,447 | Train Epoch: 1 [20480/59392 (34%)]	Loss: 1.273302
2020-06-07 23:04:58,535 | Train Epoch: 1 [20992/59392 (35%)]	Loss: 1.162503
2020-06-07 23:04:58,620 | Train Epoch: 1 [21504/59392 (36%)]	Loss: 1.156776
2020-06-07 23:04:58,708 | Train Epoch: 1 [22016/59392 (37%)]	Loss: 1.094670
2020-06-07 23:04:58,796 | Train Epoch: 1 [22528/59392 (38%)]	Loss: 1.027416
2020-06-07 23:04:58,887 | Train Epoch: 1 [23040/59392 (39%)]	Loss: 0.994197
2020-06-07 23:04:58,974 | Train Epoch: 1 [23552/59392 (40%)]	Loss: 0.991031
2020-06-07 23:04:59,062 | Train Epoch: 1 [24064/59392 (41%)]	Loss: 0.917196
2020-06-07 23:04:59,151 | Train Epoch: 1 [24576/59392 (41%)]	Loss: 0.936797
2020-06-07 23:04:59,239 | Train Epoch: 1 [25088/59392 (42%)]	Loss: 0.832758
2020-06-07 23:04:59,325 | Train Epoch: 1 [25600/59392 (43%)]	Loss: 0.732610
2020-06-07 23:04:59,486 | Train Epoch: 1 [26112/59392 (44%)]	Loss: 0.740611
2020-06-07 23:04:59,573 | Train Epoch: 1 [26624/59392 (45%)]	Loss: 0.684918
2020-06-07 23:04:59,664 | Train Epoch: 1 [27136/59392 (46%)]	Loss: 0.778045
2020-06-07 23:04:59,751 | Train Epoch: 1 [27648/59392 (47%)]	Loss: 0.823238
2020-06-07 23:04:59,838 | Train Epoch: 1 [28160/59392 (47%)]	Loss: 0.732328
2020-06-07 23:04:59,934 | Train Epoch: 1 [28672/59392 (48%)]	Loss: 0.675106
2020-06-07 23:05:00,019 | Train Epoch: 1 [29184/59392 (49%)]	Loss: 0.559646
2020-06-07 23:05:00,105 | Train Epoch: 1 [29696/59392 (50%)]	Loss: 0.544521
2020-06-07 23:05:00,199 | Train Epoch: 1 [30208/59392 (51%)]	Loss: 0.628370
2020-06-07 23:05:00,289 | Train Epoch: 1 [30720/59392 (52%)]	Loss: 0.570728
2020-06-07 23:05:00,375 | Train Epoch: 1 [31232/59392 (53%)]	Loss: 0.507605
2020-06-07 23:05:00,463 | Train Epoch: 1 [31744/59392 (53%)]	Loss: 0.436068
2020-06-07 23:05:00,549 | Train Epoch: 1 [32256/59392 (54%)]	Loss: 0.479453
2020-06-07 23:05:00,640 | Train Epoch: 1 [32768/59392 (55%)]	Loss: 0.412141
2020-06-07 23:05:00,729 | Train Epoch: 1 [33280/59392 (56%)]	Loss: 0.417601
2020-06-07 23:05:00,815 | Train Epoch: 1 [33792/59392 (57%)]	Loss: 0.470798
2020-06-07 23:05:00,907 | Train Epoch: 1 [34304/59392 (58%)]	Loss: 0.475361
2020-06-07 23:05:00,996 | Train Epoch: 1 [34816/59392 (59%)]	Loss: 0.447938
2020-06-07 23:05:01,085 | Train Epoch: 1 [35328/59392 (59%)]	Loss: 0.342092
2020-06-07 23:05:01,175 | Train Epoch: 1 [35840/59392 (60%)]	Loss: 0.407890
2020-06-07 23:05:01,271 | Train Epoch: 1 [36352/59392 (61%)]	Loss: 0.393378
2020-06-07 23:05:01,361 | Train Epoch: 1 [36864/59392 (62%)]	Loss: 0.378281
2020-06-07 23:05:01,449 | Train Epoch: 1 [37376/59392 (63%)]	Loss: 0.316232
2020-06-07 23:05:01,537 | Train Epoch: 1 [37888/59392 (64%)]	Loss: 0.290877
2020-06-07 23:05:01,625 | Train Epoch: 1 [38400/59392 (65%)]	Loss: 0.273760
2020-06-07 23:05:01,710 | Train Epoch: 1 [38912/59392 (66%)]	Loss: 0.280833
2020-06-07 23:05:01,796 | Train Epoch: 1 [39424/59392 (66%)]	Loss: 0.314929
2020-06-07 23:05:01,886 | Train Epoch: 1 [39936/59392 (67%)]	Loss: 0.306315
2020-06-07 23:05:01,974 | Train Epoch: 1 [40448/59392 (68%)]	Loss: 0.294154
2020-06-07 23:05:02,062 | Train Epoch: 1 [40960/59392 (69%)]	Loss: 0.283720
2020-06-07 23:05:02,155 | Train Epoch: 1 [41472/59392 (70%)]	Loss: 0.254443
2020-06-07 23:05:02,242 | Train Epoch: 1 [41984/59392 (71%)]	Loss: 0.267505
2020-06-07 23:05:02,330 | Train Epoch: 1 [42496/59392 (72%)]	Loss: 0.268807
2020-06-07 23:05:02,416 | Train Epoch: 1 [43008/59392 (72%)]	Loss: 0.220822
2020-06-07 23:05:02,502 | Train Epoch: 1 [43520/59392 (73%)]	Loss: 0.297658
2020-06-07 23:05:02,587 | Train Epoch: 1 [44032/59392 (74%)]	Loss: 0.251239
2020-06-07 23:05:02,673 | Train Epoch: 1 [44544/59392 (75%)]	Loss: 0.328849
2020-06-07 23:05:02,760 | Train Epoch: 1 [45056/59392 (76%)]	Loss: 0.264462
2020-06-07 23:05:02,850 | Train Epoch: 1 [45568/59392 (77%)]	Loss: 0.201659
2020-06-07 23:05:02,946 | Train Epoch: 1 [46080/59392 (78%)]	Loss: 0.243926
2020-06-07 23:05:03,039 | Train Epoch: 1 [46592/59392 (78%)]	Loss: 0.219397
2020-06-07 23:05:03,130 | Train Epoch: 1 [47104/59392 (79%)]	Loss: 0.234531
2020-06-07 23:05:03,220 | Train Epoch: 1 [47616/59392 (80%)]	Loss: 0.218722
2020-06-07 23:05:03,309 | Train Epoch: 1 [48128/59392 (81%)]	Loss: 0.261159
2020-06-07 23:05:03,401 | Train Epoch: 1 [48640/59392 (82%)]	Loss: 0.242911
2020-06-07 23:05:03,491 | Train Epoch: 1 [49152/59392 (83%)]	Loss: 0.264830
2020-06-07 23:05:03,581 | Train Epoch: 1 [49664/59392 (84%)]	Loss: 0.227489
2020-06-07 23:05:03,673 | Train Epoch: 1 [50176/59392 (84%)]	Loss: 0.226378
2020-06-07 23:05:03,764 | Train Epoch: 1 [50688/59392 (85%)]	Loss: 0.258122
2020-06-07 23:05:03,856 | Train Epoch: 1 [51200/59392 (86%)]	Loss: 0.183363
2020-06-07 23:05:03,945 | Train Epoch: 1 [51712/59392 (87%)]	Loss: 0.175075
2020-06-07 23:05:04,038 | Train Epoch: 1 [52224/59392 (88%)]	Loss: 0.198858
2020-06-07 23:05:04,130 | Train Epoch: 1 [52736/59392 (89%)]	Loss: 0.190440
2020-06-07 23:05:04,225 | Train Epoch: 1 [53248/59392 (90%)]	Loss: 0.196835
2020-06-07 23:05:04,318 | Train Epoch: 1 [53760/59392 (91%)]	Loss: 0.183688
2020-06-07 23:05:04,432 | Train Epoch: 1 [54272/59392 (91%)]	Loss: 0.213364
2020-06-07 23:05:04,525 | Train Epoch: 1 [54784/59392 (92%)]	Loss: 0.178290
2020-06-07 23:05:04,619 | Train Epoch: 1 [55296/59392 (93%)]	Loss: 0.212599
2020-06-07 23:05:04,711 | Train Epoch: 1 [55808/59392 (94%)]	Loss: 0.163581
2020-06-07 23:05:04,800 | Train Epoch: 1 [56320/59392 (95%)]	Loss: 0.182362
2020-06-07 23:05:04,893 | Train Epoch: 1 [56832/59392 (96%)]	Loss: 0.182458
2020-06-07 23:05:04,984 | Train Epoch: 1 [57344/59392 (97%)]	Loss: 0.212081
2020-06-07 23:05:05,077 | Train Epoch: 1 [57856/59392 (97%)]	Loss: 0.191591
2020-06-07 23:07:29,738 | Robust self-training
2020-06-07 23:07:29,739 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=1, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:07:30,055 | Training set
2020-06-07 23:07:30,055 | Number of training samples: 59001
2020-06-07 23:07:30,055 | Number of supervised samples: 59001
2020-06-07 23:07:30,055 | Number of unsup samples: 0
2020-06-07 23:07:30,062 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:07:30,062 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:07:30,085 | Test set
2020-06-07 23:07:30,085 | Number of samples: 9001
2020-06-07 23:07:30,087 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:07:30,087 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:07:30,249 | Training set
2020-06-07 23:07:30,250 | Number of training samples: 59001
2020-06-07 23:07:30,250 | Number of supervised samples: 59001
2020-06-07 23:07:30,250 | Number of unsup samples: 0
2020-06-07 23:07:30,257 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:07:30,258 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:07:32,687 | Setting learning rate to 0.1
2020-06-07 23:07:40,430 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:07:40,605 | Train Epoch: 1 [512/59392 (1%)]	Loss: 2.306454
2020-06-07 23:07:40,702 | Train Epoch: 1 [1024/59392 (2%)]	Loss: 2.300526
2020-06-07 23:07:40,803 | Train Epoch: 1 [1536/59392 (3%)]	Loss: 2.303479
2020-06-07 23:07:40,895 | Train Epoch: 1 [2048/59392 (3%)]	Loss: 2.305492
2020-06-07 23:07:40,989 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.300603
2020-06-07 23:07:41,079 | Train Epoch: 1 [3072/59392 (5%)]	Loss: 2.301317
2020-06-07 23:07:41,169 | Train Epoch: 1 [3584/59392 (6%)]	Loss: 2.278778
2020-06-07 23:07:41,259 | Train Epoch: 1 [4096/59392 (7%)]	Loss: 2.301869
2020-06-07 23:07:41,349 | Train Epoch: 1 [4608/59392 (8%)]	Loss: 2.285228
2020-06-07 23:07:41,441 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.295053
2020-06-07 23:07:41,530 | Train Epoch: 1 [5632/59392 (9%)]	Loss: 2.274806
2020-06-07 23:07:41,621 | Train Epoch: 1 [6144/59392 (10%)]	Loss: 2.268492
2020-06-07 23:07:41,710 | Train Epoch: 1 [6656/59392 (11%)]	Loss: 2.267536
2020-06-07 23:07:41,801 | Train Epoch: 1 [7168/59392 (12%)]	Loss: 2.244659
2020-06-07 23:07:41,896 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.222404
2020-06-07 23:07:41,995 | Train Epoch: 1 [8192/59392 (14%)]	Loss: 2.204924
2020-06-07 23:07:42,086 | Train Epoch: 1 [8704/59392 (15%)]	Loss: 2.185387
2020-06-07 23:07:42,175 | Train Epoch: 1 [9216/59392 (16%)]	Loss: 2.153388
2020-06-07 23:07:42,266 | Train Epoch: 1 [9728/59392 (16%)]	Loss: 2.165311
2020-06-07 23:07:42,358 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.097780
2020-06-07 23:07:42,448 | Train Epoch: 1 [10752/59392 (18%)]	Loss: 2.083964
2020-06-07 23:07:42,541 | Train Epoch: 1 [11264/59392 (19%)]	Loss: 2.048158
2020-06-07 23:07:42,635 | Train Epoch: 1 [11776/59392 (20%)]	Loss: 1.978153
2020-06-07 23:07:42,727 | Train Epoch: 1 [12288/59392 (21%)]	Loss: 1.934617
2020-06-07 23:07:42,820 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.894365
2020-06-07 23:07:42,918 | Train Epoch: 1 [13312/59392 (22%)]	Loss: 1.871015
2020-06-07 23:07:43,007 | Train Epoch: 1 [13824/59392 (23%)]	Loss: 1.901616
2020-06-07 23:07:43,098 | Train Epoch: 1 [14336/59392 (24%)]	Loss: 1.896610
2020-06-07 23:07:43,193 | Train Epoch: 1 [14848/59392 (25%)]	Loss: 1.761009
2020-06-07 23:07:43,289 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.662786
2020-06-07 23:07:43,379 | Train Epoch: 1 [15872/59392 (27%)]	Loss: 1.681602
2020-06-07 23:07:53,518 | Robust self-training
2020-06-07 23:07:53,518 | Args: Namespace(autoaugment=False, aux_data_filename=None, aux_take_amount=None, batch_size=512, beta=0.0, cutout=False, data_dir='/newfoundland/tarun/datasets/Digits/mnist_m/', dataset='mnist_m', distance='l_inf', entropy_weight=0.0, epochs=70, epsilon=0.031, eval_attack_batches=1, eval_freq=4, log_interval=5, loss='trades', lr=0.1, lr_schedule='cosine', model='wrn-40-2', model_dir='MNIST_only', momentum=0.9, nesterov=True, normalize_input=False, overwrite=False, pgd_num_steps=10, pgd_step_size=0.007, remove_pseudo_labels=False, save_freq=25, seed=1, svhn_extra=False, test_batch_size=256, train_eval_batches=None, unsup_fraction=0.5, weight_decay=0.0005)
2020-06-07 23:07:53,833 | Training set
2020-06-07 23:07:53,833 | Number of training samples: 59001
2020-06-07 23:07:53,833 | Number of supervised samples: 59001
2020-06-07 23:07:53,833 | Number of unsup samples: 0
2020-06-07 23:07:53,841 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:07:53,841 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:07:53,866 | Test set
2020-06-07 23:07:53,866 | Number of samples: 9001
2020-06-07 23:07:53,868 | Label histogram: ((0, 878), (1, 1016), (2, 933), (3, 908), (4, 890), (5, 807), (6, 856), (7, 914), (8, 880), (9, 919))
2020-06-07 23:07:53,868 | Shape of data: (9001, 3, 32, 32)
2020-06-07 23:07:54,005 | Training set
2020-06-07 23:07:54,005 | Number of training samples: 59001
2020-06-07 23:07:54,005 | Number of supervised samples: 59001
2020-06-07 23:07:54,005 | Number of unsup samples: 0
2020-06-07 23:07:54,012 | Label (and pseudo-label) histogram: ((0, 5825), (1, 6640), (2, 5853), (3, 6028), (4, 5746), (5, 5331), (6, 5812), (7, 6158), (8, 5757), (9, 5851))
2020-06-07 23:07:54,012 | Shape of training data: (59001, 3, 32, 32)
2020-06-07 23:07:56,497 | Setting learning rate to 0.1
2020-06-07 23:08:04,278 | Train Epoch: 1 [0/59392 (0%)]	Loss: 2.341399
2020-06-07 23:08:04,835 | Train Epoch: 1 [2560/59392 (4%)]	Loss: 2.301723
2020-06-07 23:08:05,303 | Train Epoch: 1 [5120/59392 (9%)]	Loss: 2.288766
2020-06-07 23:08:05,765 | Train Epoch: 1 [7680/59392 (13%)]	Loss: 2.223274
2020-06-07 23:08:06,226 | Train Epoch: 1 [10240/59392 (17%)]	Loss: 2.102414
2020-06-07 23:08:06,700 | Train Epoch: 1 [12800/59392 (22%)]	Loss: 1.904521
2020-06-07 23:08:07,185 | Train Epoch: 1 [15360/59392 (26%)]	Loss: 1.914458
2020-06-07 23:08:07,646 | Train Epoch: 1 [17920/59392 (30%)]	Loss: 1.438527
2020-06-07 23:08:08,105 | Train Epoch: 1 [20480/59392 (34%)]	Loss: 1.219174
2020-06-07 23:08:08,585 | Train Epoch: 1 [23040/59392 (39%)]	Loss: 1.268387
2020-06-07 23:08:09,048 | Train Epoch: 1 [25600/59392 (43%)]	Loss: 0.768509
2020-06-07 23:08:09,656 | Train Epoch: 1 [28160/59392 (47%)]	Loss: 0.685537
2020-06-07 23:08:10,132 | Train Epoch: 1 [30720/59392 (52%)]	Loss: 0.523127
2020-06-07 23:08:10,599 | Train Epoch: 1 [33280/59392 (56%)]	Loss: 0.372415
2020-06-07 23:08:11,059 | Train Epoch: 1 [35840/59392 (60%)]	Loss: 0.398375
2020-06-07 23:08:11,526 | Train Epoch: 1 [38400/59392 (65%)]	Loss: 0.263155
2020-06-07 23:08:11,992 | Train Epoch: 1 [40960/59392 (69%)]	Loss: 0.258659
2020-06-07 23:08:12,480 | Train Epoch: 1 [43520/59392 (73%)]	Loss: 0.260511
2020-06-07 23:08:12,938 | Train Epoch: 1 [46080/59392 (78%)]	Loss: 0.274307
2020-06-07 23:08:13,400 | Train Epoch: 1 [48640/59392 (82%)]	Loss: 0.221140
2020-06-07 23:08:13,869 | Train Epoch: 1 [51200/59392 (86%)]	Loss: 0.161565
2020-06-07 23:08:14,342 | Train Epoch: 1 [53760/59392 (91%)]	Loss: 0.153893
2020-06-07 23:08:14,818 | Train Epoch: 1 [56320/59392 (95%)]	Loss: 0.172651
2020-06-07 23:08:15,693 | Train Epoch: 1 [58880/59392 (99%)]	Loss: 0.129245
2020-06-07 23:08:15,761 | ================================================================================
2020-06-07 23:08:15,770 | Setting learning rate to 0.0999497
2020-06-07 23:08:16,257 | Train Epoch: 2 [0/59392 (0%)]	Loss: 0.179935
2020-06-07 23:08:16,724 | Train Epoch: 2 [2560/59392 (4%)]	Loss: 0.134131
2020-06-07 23:08:17,255 | Train Epoch: 2 [5120/59392 (9%)]	Loss: 0.167977
2020-06-07 23:08:17,729 | Train Epoch: 2 [7680/59392 (13%)]	Loss: 0.115907
2020-06-07 23:08:18,194 | Train Epoch: 2 [10240/59392 (17%)]	Loss: 0.149039
2020-06-07 23:08:18,650 | Train Epoch: 2 [12800/59392 (22%)]	Loss: 0.085542
2020-06-07 23:08:19,118 | Train Epoch: 2 [15360/59392 (26%)]	Loss: 0.116354
2020-06-07 23:08:19,587 | Train Epoch: 2 [17920/59392 (30%)]	Loss: 0.130569
2020-06-07 23:08:20,054 | Train Epoch: 2 [20480/59392 (34%)]	Loss: 0.135262
2020-06-07 23:08:20,521 | Train Epoch: 2 [23040/59392 (39%)]	Loss: 0.129785
2020-06-07 23:08:20,992 | Train Epoch: 2 [25600/59392 (43%)]	Loss: 0.121881
2020-06-07 23:08:21,459 | Train Epoch: 2 [28160/59392 (47%)]	Loss: 0.134866
2020-06-07 23:08:21,929 | Train Epoch: 2 [30720/59392 (52%)]	Loss: 0.144865
2020-06-07 23:08:22,399 | Train Epoch: 2 [33280/59392 (56%)]	Loss: 0.096080
2020-06-07 23:08:22,864 | Train Epoch: 2 [35840/59392 (60%)]	Loss: 0.111021
2020-06-07 23:08:23,393 | Train Epoch: 2 [38400/59392 (65%)]	Loss: 0.084462
2020-06-07 23:08:23,855 | Train Epoch: 2 [40960/59392 (69%)]	Loss: 0.116365
2020-06-07 23:08:24,331 | Train Epoch: 2 [43520/59392 (73%)]	Loss: 0.070893
2020-06-07 23:08:24,819 | Train Epoch: 2 [46080/59392 (78%)]	Loss: 0.071210
2020-06-07 23:08:25,291 | Train Epoch: 2 [48640/59392 (82%)]	Loss: 0.134977
2020-06-07 23:08:25,757 | Train Epoch: 2 [51200/59392 (86%)]	Loss: 0.100687
2020-06-07 23:08:26,223 | Train Epoch: 2 [53760/59392 (91%)]	Loss: 0.071136
2020-06-07 23:08:26,687 | Train Epoch: 2 [56320/59392 (95%)]	Loss: 0.076091
2020-06-07 23:08:27,153 | Train Epoch: 2 [58880/59392 (99%)]	Loss: 0.073429
2020-06-07 23:08:27,326 | ================================================================================
2020-06-07 23:08:27,333 | Setting learning rate to 0.0997987
2020-06-07 23:08:27,728 | Train Epoch: 3 [0/59392 (0%)]	Loss: 0.108061
2020-06-07 23:08:28,193 | Train Epoch: 3 [2560/59392 (4%)]	Loss: 0.065076
2020-06-07 23:08:28,728 | Train Epoch: 3 [5120/59392 (9%)]	Loss: 0.086126
2020-06-07 23:08:29,212 | Train Epoch: 3 [7680/59392 (13%)]	Loss: 0.065993
2020-06-07 23:08:29,691 | Train Epoch: 3 [10240/59392 (17%)]	Loss: 0.053978
2020-06-07 23:08:30,169 | Train Epoch: 3 [12800/59392 (22%)]	Loss: 0.082035
2020-06-07 23:08:30,656 | Train Epoch: 3 [15360/59392 (26%)]	Loss: 0.101223
2020-06-07 23:08:31,156 | Train Epoch: 3 [17920/59392 (30%)]	Loss: 0.057205
2020-06-07 23:08:31,670 | Train Epoch: 3 [20480/59392 (34%)]	Loss: 0.080526
2020-06-07 23:08:32,169 | Train Epoch: 3 [23040/59392 (39%)]	Loss: 0.062571
2020-06-07 23:08:32,658 | Train Epoch: 3 [25600/59392 (43%)]	Loss: 0.067013
2020-06-07 23:08:33,179 | Train Epoch: 3 [28160/59392 (47%)]	Loss: 0.097462
2020-06-07 23:08:33,676 | Train Epoch: 3 [30720/59392 (52%)]	Loss: 0.083248
2020-06-07 23:08:34,176 | Train Epoch: 3 [33280/59392 (56%)]	Loss: 0.084472
2020-06-07 23:08:34,639 | Train Epoch: 3 [35840/59392 (60%)]	Loss: 0.068628
2020-06-07 23:08:35,101 | Train Epoch: 3 [38400/59392 (65%)]	Loss: 0.065943
2020-06-07 23:08:35,576 | Train Epoch: 3 [40960/59392 (69%)]	Loss: 0.102725
2020-06-07 23:08:36,034 | Train Epoch: 3 [43520/59392 (73%)]	Loss: 0.072004
2020-06-07 23:08:36,504 | Train Epoch: 3 [46080/59392 (78%)]	Loss: 0.064584
2020-06-07 23:08:36,964 | Train Epoch: 3 [48640/59392 (82%)]	Loss: 0.062685
2020-06-07 23:08:37,421 | Train Epoch: 3 [51200/59392 (86%)]	Loss: 0.066862
2020-06-07 23:08:37,886 | Train Epoch: 3 [53760/59392 (91%)]	Loss: 0.040836
2020-06-07 23:08:38,354 | Train Epoch: 3 [56320/59392 (95%)]	Loss: 0.051349
2020-06-07 23:08:38,789 | Train Epoch: 3 [58880/59392 (99%)]	Loss: 0.056581
2020-06-07 23:08:38,945 | ================================================================================
2020-06-07 23:08:38,952 | Setting learning rate to 0.0995475
2020-06-07 23:08:39,369 | Train Epoch: 4 [0/59392 (0%)]	Loss: 0.060588
2020-06-07 23:08:39,836 | Train Epoch: 4 [2560/59392 (4%)]	Loss: 0.063967
2020-06-07 23:08:40,312 | Train Epoch: 4 [5120/59392 (9%)]	Loss: 0.054265
2020-06-07 23:08:40,774 | Train Epoch: 4 [7680/59392 (13%)]	Loss: 0.065029
2020-06-07 23:08:41,250 | Train Epoch: 4 [10240/59392 (17%)]	Loss: 0.040715
2020-06-07 23:08:41,796 | Train Epoch: 4 [12800/59392 (22%)]	Loss: 0.030452
2020-06-07 23:08:42,261 | Train Epoch: 4 [15360/59392 (26%)]	Loss: 0.064025
2020-06-07 23:08:42,733 | Train Epoch: 4 [17920/59392 (30%)]	Loss: 0.033826
2020-06-07 23:08:43,205 | Train Epoch: 4 [20480/59392 (34%)]	Loss: 0.046095
2020-06-07 23:08:43,678 | Train Epoch: 4 [23040/59392 (39%)]	Loss: 0.048459
2020-06-07 23:08:44,165 | Train Epoch: 4 [25600/59392 (43%)]	Loss: 0.077311
2020-06-07 23:08:44,636 | Train Epoch: 4 [28160/59392 (47%)]	Loss: 0.026290
2020-06-07 23:08:45,144 | Train Epoch: 4 [30720/59392 (52%)]	Loss: 0.057857
2020-06-07 23:08:45,612 | Train Epoch: 4 [33280/59392 (56%)]	Loss: 0.072628
2020-06-07 23:08:46,096 | Train Epoch: 4 [35840/59392 (60%)]	Loss: 0.057196
2020-06-07 23:08:46,559 | Train Epoch: 4 [38400/59392 (65%)]	Loss: 0.026156
2020-06-07 23:08:47,040 | Train Epoch: 4 [40960/59392 (69%)]	Loss: 0.048628
2020-06-07 23:08:47,504 | Train Epoch: 4 [43520/59392 (73%)]	Loss: 0.063695
2020-06-07 23:08:47,992 | Train Epoch: 4 [46080/59392 (78%)]	Loss: 0.038968
2020-06-07 23:08:48,550 | Train Epoch: 4 [48640/59392 (82%)]	Loss: 0.053395
2020-06-07 23:08:49,030 | Train Epoch: 4 [51200/59392 (86%)]	Loss: 0.023701
2020-06-07 23:08:49,503 | Train Epoch: 4 [53760/59392 (91%)]	Loss: 0.047111
2020-06-07 23:08:49,997 | Train Epoch: 4 [56320/59392 (95%)]	Loss: 0.035021
2020-06-07 23:08:50,446 | Train Epoch: 4 [58880/59392 (99%)]	Loss: 0.084325
2020-06-07 23:08:50,611 | ================================================================================
2020-06-07 23:09:02,656 | TRAIN: Clean loss: 0.2124, Clean accuracy: 55072/59001 (93.34%), PGD clean accuracy: 229/256 (89.45%), Robust accuracy 14/256 (5.47%)
2020-06-07 23:09:06,636 | TEST: Clean loss: 0.2266, Clean accuracy: 8359/9001 (92.87%), PGD clean accuracy: 238/256 (92.97%), Robust accuracy 15/256 (5.86%)
2020-06-07 23:09:06,647 | ================================================================================
2020-06-07 23:09:06,657 | Setting learning rate to 0.0991965
2020-06-07 23:09:07,159 | Train Epoch: 5 [0/59392 (0%)]	Loss: 0.031422
2020-06-07 23:09:07,641 | Train Epoch: 5 [2560/59392 (4%)]	Loss: 0.031237
2020-06-07 23:09:08,104 | Train Epoch: 5 [5120/59392 (9%)]	Loss: 0.028716
2020-06-07 23:09:08,567 | Train Epoch: 5 [7680/59392 (13%)]	Loss: 0.034666
2020-06-07 23:09:09,031 | Train Epoch: 5 [10240/59392 (17%)]	Loss: 0.059900
2020-06-07 23:09:09,493 | Train Epoch: 5 [12800/59392 (22%)]	Loss: 0.047817
2020-06-07 23:09:09,953 | Train Epoch: 5 [15360/59392 (26%)]	Loss: 0.023740
2020-06-07 23:09:10,418 | Train Epoch: 5 [17920/59392 (30%)]	Loss: 0.029116
2020-06-07 23:09:10,876 | Train Epoch: 5 [20480/59392 (34%)]	Loss: 0.029826
2020-06-07 23:09:11,350 | Train Epoch: 5 [23040/59392 (39%)]	Loss: 0.028987
2020-06-07 23:09:11,817 | Train Epoch: 5 [25600/59392 (43%)]	Loss: 0.020707
2020-06-07 23:09:12,295 | Train Epoch: 5 [28160/59392 (47%)]	Loss: 0.029560
2020-06-07 23:09:12,753 | Train Epoch: 5 [30720/59392 (52%)]	Loss: 0.018239
2020-06-07 23:09:13,305 | Train Epoch: 5 [33280/59392 (56%)]	Loss: 0.029476
2020-06-07 23:09:13,774 | Train Epoch: 5 [35840/59392 (60%)]	Loss: 0.045521
2020-06-07 23:09:14,260 | Train Epoch: 5 [38400/59392 (65%)]	Loss: 0.053632
2020-06-07 23:09:14,720 | Train Epoch: 5 [40960/59392 (69%)]	Loss: 0.020325
2020-06-07 23:09:15,176 | Train Epoch: 5 [43520/59392 (73%)]	Loss: 0.045143
2020-06-07 23:09:15,640 | Train Epoch: 5 [46080/59392 (78%)]	Loss: 0.037975
2020-06-07 23:09:16,114 | Train Epoch: 5 [48640/59392 (82%)]	Loss: 0.057302
2020-06-07 23:09:16,574 | Train Epoch: 5 [51200/59392 (86%)]	Loss: 0.027553
2020-06-07 23:09:17,028 | Train Epoch: 5 [53760/59392 (91%)]	Loss: 0.033434
2020-06-07 23:09:17,493 | Train Epoch: 5 [56320/59392 (95%)]	Loss: 0.048795
2020-06-07 23:09:17,938 | Train Epoch: 5 [58880/59392 (99%)]	Loss: 0.073331
2020-06-07 23:09:18,096 | ================================================================================
2020-06-07 23:09:18,109 | Setting learning rate to 0.0987464
2020-06-07 23:09:18,509 | Train Epoch: 6 [0/59392 (0%)]	Loss: 0.053673
2020-06-07 23:09:18,979 | Train Epoch: 6 [2560/59392 (4%)]	Loss: 0.049753
2020-06-07 23:09:19,447 | Train Epoch: 6 [5120/59392 (9%)]	Loss: 0.034783
2020-06-07 23:09:19,995 | Train Epoch: 6 [7680/59392 (13%)]	Loss: 0.035852
2020-06-07 23:09:20,461 | Train Epoch: 6 [10240/59392 (17%)]	Loss: 0.042436
2020-06-07 23:09:20,927 | Train Epoch: 6 [12800/59392 (22%)]	Loss: 0.026702
2020-06-07 23:09:21,396 | Train Epoch: 6 [15360/59392 (26%)]	Loss: 0.036601
2020-06-07 23:09:21,861 | Train Epoch: 6 [17920/59392 (30%)]	Loss: 0.025880
2020-06-07 23:09:22,340 | Train Epoch: 6 [20480/59392 (34%)]	Loss: 0.020906
2020-06-07 23:09:22,808 | Train Epoch: 6 [23040/59392 (39%)]	Loss: 0.037506
2020-06-07 23:09:23,280 | Train Epoch: 6 [25600/59392 (43%)]	Loss: 0.023357
2020-06-07 23:09:23,744 | Train Epoch: 6 [28160/59392 (47%)]	Loss: 0.036488
2020-06-07 23:09:24,219 | Train Epoch: 6 [30720/59392 (52%)]	Loss: 0.057085
2020-06-07 23:09:24,730 | Train Epoch: 6 [33280/59392 (56%)]	Loss: 0.040161
2020-06-07 23:09:25,199 | Train Epoch: 6 [35840/59392 (60%)]	Loss: 0.034504
2020-06-07 23:09:25,668 | Train Epoch: 6 [38400/59392 (65%)]	Loss: 0.057370
2020-06-07 23:09:26,131 | Train Epoch: 6 [40960/59392 (69%)]	Loss: 0.034773
2020-06-07 23:09:26,588 | Train Epoch: 6 [43520/59392 (73%)]	Loss: 0.051399
2020-06-07 23:09:27,072 | Train Epoch: 6 [46080/59392 (78%)]	Loss: 0.021328
2020-06-07 23:09:27,530 | Train Epoch: 6 [48640/59392 (82%)]	Loss: 0.027318
2020-06-07 23:09:27,997 | Train Epoch: 6 [51200/59392 (86%)]	Loss: 0.019514
2020-06-07 23:09:28,460 | Train Epoch: 6 [53760/59392 (91%)]	Loss: 0.038827
2020-06-07 23:09:28,926 | Train Epoch: 6 [56320/59392 (95%)]	Loss: 0.026777
2020-06-07 23:09:29,356 | Train Epoch: 6 [58880/59392 (99%)]	Loss: 0.007007
2020-06-07 23:09:29,509 | ================================================================================
2020-06-07 23:09:29,524 | Setting learning rate to 0.0981981
2020-06-07 23:09:29,950 | Train Epoch: 7 [0/59392 (0%)]	Loss: 0.029399
2020-06-07 23:09:30,419 | Train Epoch: 7 [2560/59392 (4%)]	Loss: 0.032129
2020-06-07 23:09:30,884 | Train Epoch: 7 [5120/59392 (9%)]	Loss: 0.012143
2020-06-07 23:09:31,345 | Train Epoch: 7 [7680/59392 (13%)]	Loss: 0.024421
2020-06-07 23:09:31,805 | Train Epoch: 7 [10240/59392 (17%)]	Loss: 0.016397
2020-06-07 23:09:32,295 | Train Epoch: 7 [12800/59392 (22%)]	Loss: 0.025200
2020-06-07 23:09:32,766 | Train Epoch: 7 [15360/59392 (26%)]	Loss: 0.039801
2020-06-07 23:09:33,242 | Train Epoch: 7 [17920/59392 (30%)]	Loss: 0.027911
2020-06-07 23:09:33,692 | Train Epoch: 7 [20480/59392 (34%)]	Loss: 0.020480
2020-06-07 23:09:34,179 | Train Epoch: 7 [23040/59392 (39%)]	Loss: 0.016474
2020-06-07 23:09:34,657 | Train Epoch: 7 [25600/59392 (43%)]	Loss: 0.026453
2020-06-07 23:09:35,124 | Train Epoch: 7 [28160/59392 (47%)]	Loss: 0.024882
2020-06-07 23:09:35,580 | Train Epoch: 7 [30720/59392 (52%)]	Loss: 0.027207
2020-06-07 23:09:36,056 | Train Epoch: 7 [33280/59392 (56%)]	Loss: 0.037922
2020-06-07 23:09:36,513 | Train Epoch: 7 [35840/59392 (60%)]	Loss: 0.039446
2020-06-07 23:09:36,973 | Train Epoch: 7 [38400/59392 (65%)]	Loss: 0.016544
2020-06-07 23:09:37,518 | Train Epoch: 7 [40960/59392 (69%)]	Loss: 0.037794
2020-06-07 23:09:37,989 | Train Epoch: 7 [43520/59392 (73%)]	Loss: 0.039501
2020-06-07 23:09:38,463 | Train Epoch: 7 [46080/59392 (78%)]	Loss: 0.008794
2020-06-07 23:09:38,927 | Train Epoch: 7 [48640/59392 (82%)]	Loss: 0.028765
2020-06-07 23:09:39,408 | Train Epoch: 7 [51200/59392 (86%)]	Loss: 0.022413
2020-06-07 23:09:39,883 | Train Epoch: 7 [53760/59392 (91%)]	Loss: 0.039799
2020-06-07 23:09:40,344 | Train Epoch: 7 [56320/59392 (95%)]	Loss: 0.024803
2020-06-07 23:09:40,797 | Train Epoch: 7 [58880/59392 (99%)]	Loss: 0.123551
2020-06-07 23:09:40,957 | ================================================================================
2020-06-07 23:09:40,972 | Setting learning rate to 0.0975528
2020-06-07 23:09:41,360 | Train Epoch: 8 [0/59392 (0%)]	Loss: 0.027494
2020-06-07 23:09:41,835 | Train Epoch: 8 [2560/59392 (4%)]	Loss: 0.034767
2020-06-07 23:09:42,297 | Train Epoch: 8 [5120/59392 (9%)]	Loss: 0.032488
2020-06-07 23:09:42,757 | Train Epoch: 8 [7680/59392 (13%)]	Loss: 0.036685
2020-06-07 23:09:43,245 | Train Epoch: 8 [10240/59392 (17%)]	Loss: 0.020443
2020-06-07 23:09:43,702 | Train Epoch: 8 [12800/59392 (22%)]	Loss: 0.056454
2020-06-07 23:09:44,240 | Train Epoch: 8 [15360/59392 (26%)]	Loss: 0.040043
2020-06-07 23:09:44,696 | Train Epoch: 8 [17920/59392 (30%)]	Loss: 0.038512
2020-06-07 23:09:45,180 | Train Epoch: 8 [20480/59392 (34%)]	Loss: 0.020202
2020-06-07 23:09:45,644 | Train Epoch: 8 [23040/59392 (39%)]	Loss: 0.048786
2020-06-07 23:09:46,117 | Train Epoch: 8 [25600/59392 (43%)]	Loss: 0.024326
2020-06-07 23:09:46,570 | Train Epoch: 8 [28160/59392 (47%)]	Loss: 0.026625
2020-06-07 23:09:47,037 | Train Epoch: 8 [30720/59392 (52%)]	Loss: 0.032104
2020-06-07 23:09:47,500 | Train Epoch: 8 [33280/59392 (56%)]	Loss: 0.029808
2020-06-07 23:09:47,970 | Train Epoch: 8 [35840/59392 (60%)]	Loss: 0.014053
2020-06-07 23:09:48,428 | Train Epoch: 8 [38400/59392 (65%)]	Loss: 0.040284
2020-06-07 23:09:48,954 | Train Epoch: 8 [40960/59392 (69%)]	Loss: 0.035044
2020-06-07 23:09:49,415 | Train Epoch: 8 [43520/59392 (73%)]	Loss: 0.049287
2020-06-07 23:09:49,880 | Train Epoch: 8 [46080/59392 (78%)]	Loss: 0.030957
2020-06-07 23:09:50,345 | Train Epoch: 8 [48640/59392 (82%)]	Loss: 0.027152
2020-06-07 23:09:50,812 | Train Epoch: 8 [51200/59392 (86%)]	Loss: 0.037658
2020-06-07 23:09:51,275 | Train Epoch: 8 [53760/59392 (91%)]	Loss: 0.019013
2020-06-07 23:09:51,728 | Train Epoch: 8 [56320/59392 (95%)]	Loss: 0.026252
2020-06-07 23:09:52,199 | Train Epoch: 8 [58880/59392 (99%)]	Loss: 0.020338
2020-06-07 23:09:52,350 | ================================================================================
2020-06-07 23:10:03,842 | TRAIN: Clean loss: 0.0478, Clean accuracy: 58094/59001 (98.46%), PGD clean accuracy: 253/256 (98.83%), Robust accuracy 16/256 (6.25%)
2020-06-07 23:10:07,560 | TEST: Clean loss: 0.0726, Clean accuracy: 8799/9001 (97.76%), PGD clean accuracy: 250/256 (97.66%), Robust accuracy 19/256 (7.42%)
2020-06-07 23:10:07,569 | ================================================================================
2020-06-07 23:10:07,585 | Setting learning rate to 0.0968117
2020-06-07 23:10:08,028 | Train Epoch: 9 [0/59392 (0%)]	Loss: 0.010387
2020-06-07 23:10:08,510 | Train Epoch: 9 [2560/59392 (4%)]	Loss: 0.026244
2020-06-07 23:10:09,004 | Train Epoch: 9 [5120/59392 (9%)]	Loss: 0.031162
2020-06-07 23:10:09,475 | Train Epoch: 9 [7680/59392 (13%)]	Loss: 0.020781
2020-06-07 23:10:09,949 | Train Epoch: 9 [10240/59392 (17%)]	Loss: 0.011597
2020-06-07 23:10:10,430 | Train Epoch: 9 [12800/59392 (22%)]	Loss: 0.022402
2020-06-07 23:10:10,904 | Train Epoch: 9 [15360/59392 (26%)]	Loss: 0.036959
2020-06-07 23:10:11,380 | Train Epoch: 9 [17920/59392 (30%)]	Loss: 0.023545
2020-06-07 23:10:11,858 | Train Epoch: 9 [20480/59392 (34%)]	Loss: 0.026350
2020-06-07 23:10:12,332 | Train Epoch: 9 [23040/59392 (39%)]	Loss: 0.014779
2020-06-07 23:10:12,811 | Train Epoch: 9 [25600/59392 (43%)]	Loss: 0.014390
2020-06-07 23:10:13,287 | Train Epoch: 9 [28160/59392 (47%)]	Loss: 0.041483
2020-06-07 23:10:13,781 | Train Epoch: 9 [30720/59392 (52%)]	Loss: 0.034192
2020-06-07 23:10:14,244 | Train Epoch: 9 [33280/59392 (56%)]	Loss: 0.015013
2020-06-07 23:10:14,789 | Train Epoch: 9 [35840/59392 (60%)]	Loss: 0.012633
2020-06-07 23:10:15,274 | Train Epoch: 9 [38400/59392 (65%)]	Loss: 0.011686
2020-06-07 23:10:15,734 | Train Epoch: 9 [40960/59392 (69%)]	Loss: 0.034295
2020-06-07 23:10:16,198 | Train Epoch: 9 [43520/59392 (73%)]	Loss: 0.016744
2020-06-07 23:10:16,675 | Train Epoch: 9 [46080/59392 (78%)]	Loss: 0.015566
2020-06-07 23:10:17,139 | Train Epoch: 9 [48640/59392 (82%)]	Loss: 0.011025
2020-06-07 23:10:17,617 | Train Epoch: 9 [51200/59392 (86%)]	Loss: 0.025773
2020-06-07 23:10:18,088 | Train Epoch: 9 [53760/59392 (91%)]	Loss: 0.039231
2020-06-07 23:10:18,566 | Train Epoch: 9 [56320/59392 (95%)]	Loss: 0.030002
2020-06-07 23:10:19,031 | Train Epoch: 9 [58880/59392 (99%)]	Loss: 0.050825
2020-06-07 23:10:19,187 | ================================================================================
2020-06-07 23:10:19,204 | Setting learning rate to 0.0959764
2020-06-07 23:10:19,712 | Train Epoch: 10 [0/59392 (0%)]	Loss: 0.031071
2020-06-07 23:10:20,196 | Train Epoch: 10 [2560/59392 (4%)]	Loss: 0.021591
2020-06-07 23:10:20,676 | Train Epoch: 10 [5120/59392 (9%)]	Loss: 0.025288
2020-06-07 23:10:21,134 | Train Epoch: 10 [7680/59392 (13%)]	Loss: 0.037322
2020-06-07 23:10:21,593 | Train Epoch: 10 [10240/59392 (17%)]	Loss: 0.032224
2020-06-07 23:10:22,060 | Train Epoch: 10 [12800/59392 (22%)]	Loss: 0.017771
2020-06-07 23:10:22,540 | Train Epoch: 10 [15360/59392 (26%)]	Loss: 0.013981
2020-06-07 23:10:23,006 | Train Epoch: 10 [17920/59392 (30%)]	Loss: 0.009730
2020-06-07 23:10:23,473 | Train Epoch: 10 [20480/59392 (34%)]	Loss: 0.010905
2020-06-07 23:10:23,947 | Train Epoch: 10 [23040/59392 (39%)]	Loss: 0.048958
2020-06-07 23:10:24,418 | Train Epoch: 10 [25600/59392 (43%)]	Loss: 0.038669
2020-06-07 23:10:24,879 | Train Epoch: 10 [28160/59392 (47%)]	Loss: 0.008223
2020-06-07 23:10:25,345 | Train Epoch: 10 [30720/59392 (52%)]	Loss: 0.005198
2020-06-07 23:10:25,808 | Train Epoch: 10 [33280/59392 (56%)]	Loss: 0.025123
2020-06-07 23:10:26,274 | Train Epoch: 10 [35840/59392 (60%)]	Loss: 0.016352
2020-06-07 23:10:26,737 | Train Epoch: 10 [38400/59392 (65%)]	Loss: 0.004436
2020-06-07 23:10:27,205 | Train Epoch: 10 [40960/59392 (69%)]	Loss: 0.010309
2020-06-07 23:10:27,666 | Train Epoch: 10 [43520/59392 (73%)]	Loss: 0.011028
2020-06-07 23:10:28,131 | Train Epoch: 10 [46080/59392 (78%)]	Loss: 0.014235
2020-06-07 23:10:28,600 | Train Epoch: 10 [48640/59392 (82%)]	Loss: 0.014294
2020-06-07 23:10:29,078 | Train Epoch: 10 [51200/59392 (86%)]	Loss: 0.026797
2020-06-07 23:10:29,544 | Train Epoch: 10 [53760/59392 (91%)]	Loss: 0.008244
2020-06-07 23:10:30,022 | Train Epoch: 10 [56320/59392 (95%)]	Loss: 0.028055
2020-06-07 23:10:30,469 | Train Epoch: 10 [58880/59392 (99%)]	Loss: 0.049259
2020-06-07 23:10:30,629 | ================================================================================
2020-06-07 23:10:30,645 | Setting learning rate to 0.0950484
2020-06-07 23:10:31,052 | Train Epoch: 11 [0/59392 (0%)]	Loss: 0.053647
2020-06-07 23:10:31,522 | Train Epoch: 11 [2560/59392 (4%)]	Loss: 0.047213
2020-06-07 23:10:31,986 | Train Epoch: 11 [5120/59392 (9%)]	Loss: 0.019288
2020-06-07 23:10:32,453 | Train Epoch: 11 [7680/59392 (13%)]	Loss: 0.015154
2020-06-07 23:10:33,039 | Train Epoch: 11 [10240/59392 (17%)]	Loss: 0.020042
2020-06-07 23:10:33,507 | Train Epoch: 11 [12800/59392 (22%)]	Loss: 0.020924
2020-06-07 23:10:33,970 | Train Epoch: 11 [15360/59392 (26%)]	Loss: 0.013493
2020-06-07 23:10:34,434 | Train Epoch: 11 [17920/59392 (30%)]	Loss: 0.019771
2020-06-07 23:10:34,904 | Train Epoch: 11 [20480/59392 (34%)]	Loss: 0.017657
2020-06-07 23:10:35,370 | Train Epoch: 11 [23040/59392 (39%)]	Loss: 0.023886
2020-06-07 23:10:35,834 | Train Epoch: 11 [25600/59392 (43%)]	Loss: 0.022238
2020-06-07 23:10:36,301 | Train Epoch: 11 [28160/59392 (47%)]	Loss: 0.009283
2020-06-07 23:10:36,760 | Train Epoch: 11 [30720/59392 (52%)]	Loss: 0.018296
2020-06-07 23:10:37,222 | Train Epoch: 11 [33280/59392 (56%)]	Loss: 0.025364
2020-06-07 23:10:37,678 | Train Epoch: 11 [35840/59392 (60%)]	Loss: 0.007765
2020-06-07 23:10:38,165 | Train Epoch: 11 [38400/59392 (65%)]	Loss: 0.030604
2020-06-07 23:10:38,629 | Train Epoch: 11 [40960/59392 (69%)]	Loss: 0.012900
2020-06-07 23:10:39,160 | Train Epoch: 11 [43520/59392 (73%)]	Loss: 0.021804
2020-06-07 23:10:39,634 | Train Epoch: 11 [46080/59392 (78%)]	Loss: 0.021068
2020-06-07 23:10:40,116 | Train Epoch: 11 [48640/59392 (82%)]	Loss: 0.023604
2020-06-07 23:10:40,592 | Train Epoch: 11 [51200/59392 (86%)]	Loss: 0.023629
2020-06-07 23:10:41,064 | Train Epoch: 11 [53760/59392 (91%)]	Loss: 0.027551
2020-06-07 23:10:41,531 | Train Epoch: 11 [56320/59392 (95%)]	Loss: 0.032923
2020-06-07 23:10:41,991 | Train Epoch: 11 [58880/59392 (99%)]	Loss: 0.028712
2020-06-07 23:10:42,141 | ================================================================================
2020-06-07 23:10:42,159 | Setting learning rate to 0.0940298
2020-06-07 23:10:42,533 | Train Epoch: 12 [0/59392 (0%)]	Loss: 0.040939
2020-06-07 23:10:43,022 | Train Epoch: 12 [2560/59392 (4%)]	Loss: 0.034462
2020-06-07 23:10:43,515 | Train Epoch: 12 [5120/59392 (9%)]	Loss: 0.023185
2020-06-07 23:10:43,998 | Train Epoch: 12 [7680/59392 (13%)]	Loss: 0.024838
2020-06-07 23:10:44,522 | Train Epoch: 12 [10240/59392 (17%)]	Loss: 0.019475
2020-06-07 23:10:44,992 | Train Epoch: 12 [12800/59392 (22%)]	Loss: 0.013436
2020-06-07 23:10:45,467 | Train Epoch: 12 [15360/59392 (26%)]	Loss: 0.019360
2020-06-07 23:10:45,952 | Train Epoch: 12 [17920/59392 (30%)]	Loss: 0.020231
2020-06-07 23:10:46,460 | Train Epoch: 12 [20480/59392 (34%)]	Loss: 0.016617
2020-06-07 23:10:46,972 | Train Epoch: 12 [23040/59392 (39%)]	Loss: 0.013178
2020-06-07 23:10:47,496 | Train Epoch: 12 [25600/59392 (43%)]	Loss: 0.029915
2020-06-07 23:10:47,964 | Train Epoch: 12 [28160/59392 (47%)]	Loss: 0.015372
2020-06-07 23:10:48,437 | Train Epoch: 12 [30720/59392 (52%)]	Loss: 0.014188
2020-06-07 23:10:48,937 | Train Epoch: 12 [33280/59392 (56%)]	Loss: 0.019092
2020-06-07 23:10:49,421 | Train Epoch: 12 [35840/59392 (60%)]	Loss: 0.012646
2020-06-07 23:10:49,901 | Train Epoch: 12 [38400/59392 (65%)]	Loss: 0.012926
2020-06-07 23:10:50,369 | Train Epoch: 12 [40960/59392 (69%)]	Loss: 0.016488
2020-06-07 23:10:50,838 | Train Epoch: 12 [43520/59392 (73%)]	Loss: 0.027787
2020-06-07 23:10:51,307 | Train Epoch: 12 [46080/59392 (78%)]	Loss: 0.011811
2020-06-07 23:10:51,765 | Train Epoch: 12 [48640/59392 (82%)]	Loss: 0.022697
2020-06-07 23:10:52,255 | Train Epoch: 12 [51200/59392 (86%)]	Loss: 0.028068
2020-06-07 23:10:52,738 | Train Epoch: 12 [53760/59392 (91%)]	Loss: 0.022727
2020-06-07 23:10:53,241 | Train Epoch: 12 [56320/59392 (95%)]	Loss: 0.018097
2020-06-07 23:10:53,709 | Train Epoch: 12 [58880/59392 (99%)]	Loss: 0.022078
2020-06-07 23:10:53,866 | ================================================================================
2020-06-07 23:11:05,259 | TRAIN: Clean loss: 0.0458, Clean accuracy: 58194/59001 (98.63%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 13/256 (5.08%)
2020-06-07 23:11:09,099 | TEST: Clean loss: 0.0875, Clean accuracy: 8796/9001 (97.72%), PGD clean accuracy: 252/256 (98.44%), Robust accuracy 14/256 (5.47%)
2020-06-07 23:11:09,111 | ================================================================================
2020-06-07 23:11:09,129 | Setting learning rate to 0.0929224
2020-06-07 23:11:09,581 | Train Epoch: 13 [0/59392 (0%)]	Loss: 0.013162
2020-06-07 23:11:10,066 | Train Epoch: 13 [2560/59392 (4%)]	Loss: 0.023249
2020-06-07 23:11:10,610 | Train Epoch: 13 [5120/59392 (9%)]	Loss: 0.042709
2020-06-07 23:11:11,071 | Train Epoch: 13 [7680/59392 (13%)]	Loss: 0.029494
2020-06-07 23:11:11,545 | Train Epoch: 13 [10240/59392 (17%)]	Loss: 0.029145
2020-06-07 23:11:12,006 | Train Epoch: 13 [12800/59392 (22%)]	Loss: 0.027362
2020-06-07 23:11:12,490 | Train Epoch: 13 [15360/59392 (26%)]	Loss: 0.012958
2020-06-07 23:11:12,950 | Train Epoch: 13 [17920/59392 (30%)]	Loss: 0.016192
2020-06-07 23:11:13,424 | Train Epoch: 13 [20480/59392 (34%)]	Loss: 0.020017
2020-06-07 23:11:13,889 | Train Epoch: 13 [23040/59392 (39%)]	Loss: 0.032880
2020-06-07 23:11:14,359 | Train Epoch: 13 [25600/59392 (43%)]	Loss: 0.020825
2020-06-07 23:11:14,851 | Train Epoch: 13 [28160/59392 (47%)]	Loss: 0.019343
2020-06-07 23:11:15,379 | Train Epoch: 13 [30720/59392 (52%)]	Loss: 0.014178
2020-06-07 23:11:15,847 | Train Epoch: 13 [33280/59392 (56%)]	Loss: 0.015225
2020-06-07 23:11:16,311 | Train Epoch: 13 [35840/59392 (60%)]	Loss: 0.016642
2020-06-07 23:11:16,793 | Train Epoch: 13 [38400/59392 (65%)]	Loss: 0.009455
2020-06-07 23:11:17,293 | Train Epoch: 13 [40960/59392 (69%)]	Loss: 0.016739
2020-06-07 23:11:17,761 | Train Epoch: 13 [43520/59392 (73%)]	Loss: 0.014494
2020-06-07 23:11:18,238 | Train Epoch: 13 [46080/59392 (78%)]	Loss: 0.016225
2020-06-07 23:11:18,703 | Train Epoch: 13 [48640/59392 (82%)]	Loss: 0.020766
2020-06-07 23:11:19,172 | Train Epoch: 13 [51200/59392 (86%)]	Loss: 0.014322
2020-06-07 23:11:19,636 | Train Epoch: 13 [53760/59392 (91%)]	Loss: 0.018697
2020-06-07 23:11:20,104 | Train Epoch: 13 [56320/59392 (95%)]	Loss: 0.013471
2020-06-07 23:11:20,569 | Train Epoch: 13 [58880/59392 (99%)]	Loss: 0.014989
2020-06-07 23:11:20,720 | ================================================================================
2020-06-07 23:11:20,741 | Setting learning rate to 0.0917287
2020-06-07 23:11:21,135 | Train Epoch: 14 [0/59392 (0%)]	Loss: 0.024762
2020-06-07 23:11:21,610 | Train Epoch: 14 [2560/59392 (4%)]	Loss: 0.017448
2020-06-07 23:11:22,073 | Train Epoch: 14 [5120/59392 (9%)]	Loss: 0.007126
2020-06-07 23:11:22,551 | Train Epoch: 14 [7680/59392 (13%)]	Loss: 0.018713
2020-06-07 23:11:23,019 | Train Epoch: 14 [10240/59392 (17%)]	Loss: 0.013743
2020-06-07 23:11:23,494 | Train Epoch: 14 [12800/59392 (22%)]	Loss: 0.014295
2020-06-07 23:11:23,962 | Train Epoch: 14 [15360/59392 (26%)]	Loss: 0.010591
2020-06-07 23:11:24,432 | Train Epoch: 14 [17920/59392 (30%)]	Loss: 0.006491
2020-06-07 23:11:24,896 | Train Epoch: 14 [20480/59392 (34%)]	Loss: 0.012658
2020-06-07 23:11:25,371 | Train Epoch: 14 [23040/59392 (39%)]	Loss: 0.005174
2020-06-07 23:11:25,840 | Train Epoch: 14 [25600/59392 (43%)]	Loss: 0.022025
2020-06-07 23:11:26,329 | Train Epoch: 14 [28160/59392 (47%)]	Loss: 0.009857
2020-06-07 23:11:26,795 | Train Epoch: 14 [30720/59392 (52%)]	Loss: 0.004548
2020-06-07 23:11:27,265 | Train Epoch: 14 [33280/59392 (56%)]	Loss: 0.020895
2020-06-07 23:11:27,732 | Train Epoch: 14 [35840/59392 (60%)]	Loss: 0.020542
2020-06-07 23:11:28,276 | Train Epoch: 14 [38400/59392 (65%)]	Loss: 0.006589
2020-06-07 23:11:28,739 | Train Epoch: 14 [40960/59392 (69%)]	Loss: 0.024267
2020-06-07 23:11:29,210 | Train Epoch: 14 [43520/59392 (73%)]	Loss: 0.021115
2020-06-07 23:11:29,685 | Train Epoch: 14 [46080/59392 (78%)]	Loss: 0.013594
2020-06-07 23:11:30,147 | Train Epoch: 14 [48640/59392 (82%)]	Loss: 0.018656
2020-06-07 23:11:30,611 | Train Epoch: 14 [51200/59392 (86%)]	Loss: 0.013572
2020-06-07 23:11:31,095 | Train Epoch: 14 [53760/59392 (91%)]	Loss: 0.018758
2020-06-07 23:11:31,560 | Train Epoch: 14 [56320/59392 (95%)]	Loss: 0.036867
2020-06-07 23:11:32,025 | Train Epoch: 14 [58880/59392 (99%)]	Loss: 0.076645
2020-06-07 23:11:32,175 | ================================================================================
2020-06-07 23:11:32,197 | Setting learning rate to 0.0904508
2020-06-07 23:11:32,587 | Train Epoch: 15 [0/59392 (0%)]	Loss: 0.046247
2020-06-07 23:11:33,059 | Train Epoch: 15 [2560/59392 (4%)]	Loss: 0.009170
2020-06-07 23:11:33,526 | Train Epoch: 15 [5120/59392 (9%)]	Loss: 0.028602
2020-06-07 23:11:34,015 | Train Epoch: 15 [7680/59392 (13%)]	Loss: 0.034287
2020-06-07 23:11:34,488 | Train Epoch: 15 [10240/59392 (17%)]	Loss: 0.023277
2020-06-07 23:11:34,969 | Train Epoch: 15 [12800/59392 (22%)]	Loss: 0.018448
2020-06-07 23:11:35,494 | Train Epoch: 15 [15360/59392 (26%)]	Loss: 0.014722
2020-06-07 23:11:35,956 | Train Epoch: 15 [17920/59392 (30%)]	Loss: 0.012611
2020-06-07 23:11:36,419 | Train Epoch: 15 [20480/59392 (34%)]	Loss: 0.016345
2020-06-07 23:11:36,895 | Train Epoch: 15 [23040/59392 (39%)]	Loss: 0.011949
2020-06-07 23:11:37,366 | Train Epoch: 15 [25600/59392 (43%)]	Loss: 0.017728
2020-06-07 23:11:37,849 | Train Epoch: 15 [28160/59392 (47%)]	Loss: 0.012613
2020-06-07 23:11:38,304 | Train Epoch: 15 [30720/59392 (52%)]	Loss: 0.010554
2020-06-07 23:11:38,776 | Train Epoch: 15 [33280/59392 (56%)]	Loss: 0.006799
2020-06-07 23:11:39,258 | Train Epoch: 15 [35840/59392 (60%)]	Loss: 0.015657
2020-06-07 23:11:39,782 | Train Epoch: 15 [38400/59392 (65%)]	Loss: 0.015467
2020-06-07 23:11:40,239 | Train Epoch: 15 [40960/59392 (69%)]	Loss: 0.013458
2020-06-07 23:11:40,708 | Train Epoch: 15 [43520/59392 (73%)]	Loss: 0.031915
2020-06-07 23:11:41,181 | Train Epoch: 15 [46080/59392 (78%)]	Loss: 0.013975
2020-06-07 23:11:41,649 | Train Epoch: 15 [48640/59392 (82%)]	Loss: 0.045382
2020-06-07 23:11:42,118 | Train Epoch: 15 [51200/59392 (86%)]	Loss: 0.024976
2020-06-07 23:11:42,596 | Train Epoch: 15 [53760/59392 (91%)]	Loss: 0.027653
2020-06-07 23:11:43,083 | Train Epoch: 15 [56320/59392 (95%)]	Loss: 0.010276
2020-06-07 23:11:43,527 | Train Epoch: 15 [58880/59392 (99%)]	Loss: 0.048507
2020-06-07 23:11:43,677 | ================================================================================
2020-06-07 23:11:43,703 | Setting learning rate to 0.0890916
2020-06-07 23:11:44,135 | Train Epoch: 16 [0/59392 (0%)]	Loss: 0.015790
2020-06-07 23:11:44,607 | Train Epoch: 16 [2560/59392 (4%)]	Loss: 0.036808
2020-06-07 23:11:45,074 | Train Epoch: 16 [5120/59392 (9%)]	Loss: 0.027830
2020-06-07 23:11:45,543 | Train Epoch: 16 [7680/59392 (13%)]	Loss: 0.020041
2020-06-07 23:11:46,012 | Train Epoch: 16 [10240/59392 (17%)]	Loss: 0.018475
2020-06-07 23:11:46,487 | Train Epoch: 16 [12800/59392 (22%)]	Loss: 0.025207
2020-06-07 23:11:46,959 | Train Epoch: 16 [15360/59392 (26%)]	Loss: 0.020508
2020-06-07 23:11:47,419 | Train Epoch: 16 [17920/59392 (30%)]	Loss: 0.008978
2020-06-07 23:11:47,891 | Train Epoch: 16 [20480/59392 (34%)]	Loss: 0.014603
2020-06-07 23:11:48,363 | Train Epoch: 16 [23040/59392 (39%)]	Loss: 0.024123
2020-06-07 23:11:48,837 | Train Epoch: 16 [25600/59392 (43%)]	Loss: 0.009168
2020-06-07 23:11:49,325 | Train Epoch: 16 [28160/59392 (47%)]	Loss: 0.010957
2020-06-07 23:11:49,796 | Train Epoch: 16 [30720/59392 (52%)]	Loss: 0.008054
2020-06-07 23:11:50,268 | Train Epoch: 16 [33280/59392 (56%)]	Loss: 0.004214
2020-06-07 23:11:50,727 | Train Epoch: 16 [35840/59392 (60%)]	Loss: 0.018963
2020-06-07 23:11:51,192 | Train Epoch: 16 [38400/59392 (65%)]	Loss: 0.019262
2020-06-07 23:11:51,677 | Train Epoch: 16 [40960/59392 (69%)]	Loss: 0.021858
2020-06-07 23:11:52,151 | Train Epoch: 16 [43520/59392 (73%)]	Loss: 0.012398
2020-06-07 23:11:52,632 | Train Epoch: 16 [46080/59392 (78%)]	Loss: 0.024255
2020-06-07 23:11:53,166 | Train Epoch: 16 [48640/59392 (82%)]	Loss: 0.024187
2020-06-07 23:11:53,633 | Train Epoch: 16 [51200/59392 (86%)]	Loss: 0.017107
2020-06-07 23:11:54,115 | Train Epoch: 16 [53760/59392 (91%)]	Loss: 0.007706
2020-06-07 23:11:54,575 | Train Epoch: 16 [56320/59392 (95%)]	Loss: 0.014526
2020-06-07 23:11:55,026 | Train Epoch: 16 [58880/59392 (99%)]	Loss: 0.012616
2020-06-07 23:11:55,179 | ================================================================================
2020-06-07 23:12:06,712 | TRAIN: Clean loss: 0.0463, Clean accuracy: 58129/59001 (98.52%), PGD clean accuracy: 255/256 (99.61%), Robust accuracy 6/256 (2.34%)
2020-06-07 23:12:10,360 | TEST: Clean loss: 0.0915, Clean accuracy: 8756/9001 (97.28%), PGD clean accuracy: 248/256 (96.88%), Robust accuracy 9/256 (3.52%)
2020-06-07 23:12:10,369 | ================================================================================
2020-06-07 23:12:10,393 | Setting learning rate to 0.0876536
2020-06-07 23:12:10,957 | Train Epoch: 17 [0/59392 (0%)]	Loss: 0.009429
2020-06-07 23:12:11,438 | Train Epoch: 17 [2560/59392 (4%)]	Loss: 0.013207
2020-06-07 23:12:11,908 | Train Epoch: 17 [5120/59392 (9%)]	Loss: 0.009346
2020-06-07 23:12:12,368 | Train Epoch: 17 [7680/59392 (13%)]	Loss: 0.011091
2020-06-07 23:12:12,834 | Train Epoch: 17 [10240/59392 (17%)]	Loss: 0.011772
2020-06-07 23:12:13,295 | Train Epoch: 17 [12800/59392 (22%)]	Loss: 0.007212
2020-06-07 23:12:13,761 | Train Epoch: 17 [15360/59392 (26%)]	Loss: 0.014589
2020-06-07 23:12:14,219 | Train Epoch: 17 [17920/59392 (30%)]	Loss: 0.020762
2020-06-07 23:12:14,688 | Train Epoch: 17 [20480/59392 (34%)]	Loss: 0.014354
2020-06-07 23:12:15,149 | Train Epoch: 17 [23040/59392 (39%)]	Loss: 0.025329
2020-06-07 23:12:15,611 | Train Epoch: 17 [25600/59392 (43%)]	Loss: 0.011609
2020-06-07 23:12:16,072 | Train Epoch: 17 [28160/59392 (47%)]	Loss: 0.005780
2020-06-07 23:12:16,533 | Train Epoch: 17 [30720/59392 (52%)]	Loss: 0.013344
2020-06-07 23:12:17,001 | Train Epoch: 17 [33280/59392 (56%)]	Loss: 0.007490
2020-06-07 23:12:17,486 | Train Epoch: 17 [35840/59392 (60%)]	Loss: 0.019910
2020-06-07 23:12:17,953 | Train Epoch: 17 [38400/59392 (65%)]	Loss: 0.004297
2020-06-07 23:12:18,435 | Train Epoch: 17 [40960/59392 (69%)]	Loss: 0.009278
2020-06-07 23:12:18,900 | Train Epoch: 17 [43520/59392 (73%)]	Loss: 0.007730
2020-06-07 23:12:19,386 | Train Epoch: 17 [46080/59392 (78%)]	Loss: 0.015212
2020-06-07 23:12:19,860 | Train Epoch: 17 [48640/59392 (82%)]	Loss: 0.005603
2020-06-07 23:12:20,327 | Train Epoch: 17 [51200/59392 (86%)]	Loss: 0.010541
2020-06-07 23:12:20,796 | Train Epoch: 17 [53760/59392 (91%)]	Loss: 0.015514
2020-06-07 23:12:21,259 | Train Epoch: 17 [56320/59392 (95%)]	Loss: 0.021758
2020-06-07 23:12:21,713 | Train Epoch: 17 [58880/59392 (99%)]	Loss: 0.022174
2020-06-07 23:12:21,861 | ================================================================================
2020-06-07 23:12:21,882 | Setting learning rate to 0.0861397
2020-06-07 23:12:22,268 | Train Epoch: 18 [0/59392 (0%)]	Loss: 0.009218
2020-06-07 23:12:22,743 | Train Epoch: 18 [2560/59392 (4%)]	Loss: 0.009095
2020-06-07 23:12:23,219 | Train Epoch: 18 [5120/59392 (9%)]	Loss: 0.008087
2020-06-07 23:12:23,687 | Train Epoch: 18 [7680/59392 (13%)]	Loss: 0.005157
2020-06-07 23:12:24,207 | Train Epoch: 18 [10240/59392 (17%)]	Loss: 0.012155
2020-06-07 23:12:24,675 | Train Epoch: 18 [12800/59392 (22%)]	Loss: 0.006428
2020-06-07 23:12:25,139 | Train Epoch: 18 [15360/59392 (26%)]	Loss: 0.012934
2020-06-07 23:12:25,601 | Train Epoch: 18 [17920/59392 (30%)]	Loss: 0.016855
2020-06-07 23:12:26,060 | Train Epoch: 18 [20480/59392 (34%)]	Loss: 0.003252
2020-06-07 23:12:26,529 | Train Epoch: 18 [23040/59392 (39%)]	Loss: 0.003351
2020-06-07 23:12:26,995 | Train Epoch: 18 [25600/59392 (43%)]	Loss: 0.007793
2020-06-07 23:12:27,463 | Train Epoch: 18 [28160/59392 (47%)]	Loss: 0.019805
2020-06-07 23:12:27,926 | Train Epoch: 18 [30720/59392 (52%)]	Loss: 0.003802
2020-06-07 23:12:28,401 | Train Epoch: 18 [33280/59392 (56%)]	Loss: 0.015158
2020-06-07 23:12:28,866 | Train Epoch: 18 [35840/59392 (60%)]	Loss: 0.009479
2020-06-07 23:12:29,342 | Train Epoch: 18 [38400/59392 (65%)]	Loss: 0.010091
2020-06-07 23:12:29,840 | Train Epoch: 18 [40960/59392 (69%)]	Loss: 0.007670
2020-06-07 23:12:30,369 | Train Epoch: 18 [43520/59392 (73%)]	Loss: 0.008995
2020-06-07 23:12:30,842 | Train Epoch: 18 [46080/59392 (78%)]	Loss: 0.009294
2020-06-07 23:12:31,321 | Train Epoch: 18 [48640/59392 (82%)]	Loss: 0.022437
2020-06-07 23:12:31,782 | Train Epoch: 18 [51200/59392 (86%)]	Loss: 0.007488
2020-06-07 23:12:32,253 | Train Epoch: 18 [53760/59392 (91%)]	Loss: 0.012656
2020-06-07 23:12:32,739 | Train Epoch: 18 [56320/59392 (95%)]	Loss: 0.010930
2020-06-07 23:12:33,189 | Train Epoch: 18 [58880/59392 (99%)]	Loss: 0.013125
2020-06-07 23:12:33,354 | ================================================================================
2020-06-07 23:12:33,380 | Setting learning rate to 0.0845531
2020-06-07 23:12:33,765 | Train Epoch: 19 [0/59392 (0%)]	Loss: 0.015711
2020-06-07 23:12:34,241 | Train Epoch: 19 [2560/59392 (4%)]	Loss: 0.009472
2020-06-07 23:12:34,712 | Train Epoch: 19 [5120/59392 (9%)]	Loss: 0.004609
2020-06-07 23:12:35,203 | Train Epoch: 19 [7680/59392 (13%)]	Loss: 0.012369
2020-06-07 23:12:35,739 | Train Epoch: 19 [10240/59392 (17%)]	Loss: 0.006485
2020-06-07 23:12:36,222 | Train Epoch: 19 [12800/59392 (22%)]	Loss: 0.008432
2020-06-07 23:12:36,689 | Train Epoch: 19 [15360/59392 (26%)]	Loss: 0.014350
2020-06-07 23:12:37,164 | Train Epoch: 19 [17920/59392 (30%)]	Loss: 0.015832
2020-06-07 23:12:37,628 | Train Epoch: 19 [20480/59392 (34%)]	Loss: 0.006479
2020-06-07 23:12:38,096 | Train Epoch: 19 [23040/59392 (39%)]	Loss: 0.013234
2020-06-07 23:12:38,556 | Train Epoch: 19 [25600/59392 (43%)]	Loss: 0.016344
2020-06-07 23:12:39,024 | Train Epoch: 19 [28160/59392 (47%)]	Loss: 0.004807
2020-06-07 23:12:39,493 | Train Epoch: 19 [30720/59392 (52%)]	Loss: 0.012095
2020-06-07 23:12:39,971 | Train Epoch: 19 [33280/59392 (56%)]	Loss: 0.006093
2020-06-07 23:12:40,458 | Train Epoch: 19 [35840/59392 (60%)]	Loss: 0.017798
2020-06-07 23:12:40,937 | Train Epoch: 19 [38400/59392 (65%)]	Loss: 0.017742
2020-06-07 23:12:41,399 | Train Epoch: 19 [40960/59392 (69%)]	Loss: 0.023038
2020-06-07 23:12:41,866 | Train Epoch: 19 [43520/59392 (73%)]	Loss: 0.022265
2020-06-07 23:12:42,345 | Train Epoch: 19 [46080/59392 (78%)]	Loss: 0.011174
2020-06-07 23:12:42,805 | Train Epoch: 19 [48640/59392 (82%)]	Loss: 0.010193
2020-06-07 23:12:43,280 | Train Epoch: 19 [51200/59392 (86%)]	Loss: 0.005138
2020-06-07 23:12:43,747 | Train Epoch: 19 [53760/59392 (91%)]	Loss: 0.009873
2020-06-07 23:12:44,224 | Train Epoch: 19 [56320/59392 (95%)]	Loss: 0.018441
2020-06-07 23:12:44,673 | Train Epoch: 19 [58880/59392 (99%)]	Loss: 0.012799
2020-06-07 23:12:44,830 | ================================================================================
2020-06-07 23:12:44,866 | Setting learning rate to 0.0828969
2020-06-07 23:12:45,260 | Train Epoch: 20 [0/59392 (0%)]	Loss: 0.009617
2020-06-07 23:12:45,775 | Train Epoch: 20 [2560/59392 (4%)]	Loss: 0.007454
2020-06-07 23:12:46,243 | Train Epoch: 20 [5120/59392 (9%)]	Loss: 0.007654
2020-06-07 23:12:46,731 | Train Epoch: 20 [7680/59392 (13%)]	Loss: 0.006178
2020-06-07 23:12:47,208 | Train Epoch: 20 [10240/59392 (17%)]	Loss: 0.007666
2020-06-07 23:12:47,678 | Train Epoch: 20 [12800/59392 (22%)]	Loss: 0.012947
2020-06-07 23:12:48,150 | Train Epoch: 20 [15360/59392 (26%)]	Loss: 0.003605
2020-06-07 23:12:48,687 | Train Epoch: 20 [17920/59392 (30%)]	Loss: 0.024544
2020-06-07 23:12:49,150 | Train Epoch: 20 [20480/59392 (34%)]	Loss: 0.005238
2020-06-07 23:12:49,613 | Train Epoch: 20 [23040/59392 (39%)]	Loss: 0.010684
2020-06-07 23:12:50,086 | Train Epoch: 20 [25600/59392 (43%)]	Loss: 0.006988
2020-06-07 23:12:50,554 | Train Epoch: 20 [28160/59392 (47%)]	Loss: 0.011289
2020-06-07 23:12:51,020 | Train Epoch: 20 [30720/59392 (52%)]	Loss: 0.011539
2020-06-07 23:12:51,515 | Train Epoch: 20 [33280/59392 (56%)]	Loss: 0.008855
2020-06-07 23:12:51,986 | Train Epoch: 20 [35840/59392 (60%)]	Loss: 0.003581
2020-06-07 23:12:52,477 | Train Epoch: 20 [38400/59392 (65%)]	Loss: 0.006139
2020-06-07 23:12:52,950 | Train Epoch: 20 [40960/59392 (69%)]	Loss: 0.006458
2020-06-07 23:12:53,417 | Train Epoch: 20 [43520/59392 (73%)]	Loss: 0.009360
2020-06-07 23:12:53,891 | Train Epoch: 20 [46080/59392 (78%)]	Loss: 0.010365
2020-06-07 23:12:54,373 | Train Epoch: 20 [48640/59392 (82%)]	Loss: 0.021531
2020-06-07 23:12:54,838 | Train Epoch: 20 [51200/59392 (86%)]	Loss: 0.006168
2020-06-07 23:12:55,383 | Train Epoch: 20 [53760/59392 (91%)]	Loss: 0.014033
2020-06-07 23:12:55,846 | Train Epoch: 20 [56320/59392 (95%)]	Loss: 0.021902
2020-06-07 23:12:56,308 | Train Epoch: 20 [58880/59392 (99%)]	Loss: 0.020891
2020-06-07 23:12:56,457 | ================================================================================
2020-06-07 23:13:08,089 | TRAIN: Clean loss: 0.0850, Clean accuracy: 57471/59001 (97.41%), PGD clean accuracy: 245/256 (95.70%), Robust accuracy 3/256 (1.17%)
2020-06-07 23:13:11,897 | TEST: Clean loss: 0.1403, Clean accuracy: 8640/9001 (95.99%), PGD clean accuracy: 246/256 (96.09%), Robust accuracy 7/256 (2.73%)
2020-06-07 23:13:11,906 | ================================================================================
2020-06-07 23:13:11,935 | Setting learning rate to 0.0811745
2020-06-07 23:13:12,325 | Train Epoch: 21 [0/59392 (0%)]	Loss: 0.024405
2020-06-07 23:13:12,810 | Train Epoch: 21 [2560/59392 (4%)]	Loss: 0.015740
2020-06-07 23:13:13,286 | Train Epoch: 21 [5120/59392 (9%)]	Loss: 0.023342
2020-06-07 23:13:13,756 | Train Epoch: 21 [7680/59392 (13%)]	Loss: 0.013291
2020-06-07 23:13:14,228 | Train Epoch: 21 [10240/59392 (17%)]	Loss: 0.029568
2020-06-07 23:13:14,699 | Train Epoch: 21 [12800/59392 (22%)]	Loss: 0.020699
2020-06-07 23:13:15,191 | Train Epoch: 21 [15360/59392 (26%)]	Loss: 0.015685
2020-06-07 23:13:15,666 | Train Epoch: 21 [17920/59392 (30%)]	Loss: 0.017863
2020-06-07 23:13:16,156 | Train Epoch: 21 [20480/59392 (34%)]	Loss: 0.013779
2020-06-07 23:13:16,635 | Train Epoch: 21 [23040/59392 (39%)]	Loss: 0.016859
2020-06-07 23:13:17,110 | Train Epoch: 21 [25600/59392 (43%)]	Loss: 0.011349
2020-06-07 23:13:17,578 | Train Epoch: 21 [28160/59392 (47%)]	Loss: 0.013180
2020-06-07 23:13:18,050 | Train Epoch: 21 [30720/59392 (52%)]	Loss: 0.021826
2020-06-07 23:13:18,516 | Train Epoch: 21 [33280/59392 (56%)]	Loss: 0.017585
2020-06-07 23:13:19,064 | Train Epoch: 21 [35840/59392 (60%)]	Loss: 0.015014
2020-06-07 23:13:19,534 | Train Epoch: 21 [38400/59392 (65%)]	Loss: 0.025984
2020-06-07 23:13:20,013 | Train Epoch: 21 [40960/59392 (69%)]	Loss: 0.010443
2020-06-07 23:13:20,483 | Train Epoch: 21 [43520/59392 (73%)]	Loss: 0.010605
2020-06-07 23:13:20,961 | Train Epoch: 21 [46080/59392 (78%)]	Loss: 0.011686
2020-06-07 23:13:21,427 | Train Epoch: 21 [48640/59392 (82%)]	Loss: 0.018699
2020-06-07 23:13:21,897 | Train Epoch: 21 [51200/59392 (86%)]	Loss: 0.025801
2020-06-07 23:13:22,357 | Train Epoch: 21 [53760/59392 (91%)]	Loss: 0.022652
2020-06-07 23:13:22,838 | Train Epoch: 21 [56320/59392 (95%)]	Loss: 0.021460
2020-06-07 23:13:23,285 | Train Epoch: 21 [58880/59392 (99%)]	Loss: 0.007722
2020-06-07 23:13:23,432 | ================================================================================
2020-06-07 23:13:23,450 | Setting learning rate to 0.0793893
2020-06-07 23:13:23,855 | Train Epoch: 22 [0/59392 (0%)]	Loss: 0.024349
2020-06-07 23:13:24,332 | Train Epoch: 22 [2560/59392 (4%)]	Loss: 0.010397
2020-06-07 23:13:24,824 | Train Epoch: 22 [5120/59392 (9%)]	Loss: 0.013029
2020-06-07 23:13:25,291 | Train Epoch: 22 [7680/59392 (13%)]	Loss: 0.012819
2020-06-07 23:13:25,770 | Train Epoch: 22 [10240/59392 (17%)]	Loss: 0.014810
2020-06-07 23:13:26,304 | Train Epoch: 22 [12800/59392 (22%)]	Loss: 0.018040
2020-06-07 23:13:26,776 | Train Epoch: 22 [15360/59392 (26%)]	Loss: 0.005608
2020-06-07 23:13:27,247 | Train Epoch: 22 [17920/59392 (30%)]	Loss: 0.017607
2020-06-07 23:13:27,713 | Train Epoch: 22 [20480/59392 (34%)]	Loss: 0.006028
2020-06-07 23:13:28,176 | Train Epoch: 22 [23040/59392 (39%)]	Loss: 0.002775
2020-06-07 23:13:28,647 | Train Epoch: 22 [25600/59392 (43%)]	Loss: 0.004157
2020-06-07 23:13:29,111 | Train Epoch: 22 [28160/59392 (47%)]	Loss: 0.020661
2020-06-07 23:13:29,590 | Train Epoch: 22 [30720/59392 (52%)]	Loss: 0.012872
2020-06-07 23:13:30,062 | Train Epoch: 22 [33280/59392 (56%)]	Loss: 0.018740
2020-06-07 23:13:30,547 | Train Epoch: 22 [35840/59392 (60%)]	Loss: 0.003477
2020-06-07 23:13:31,070 | Train Epoch: 22 [38400/59392 (65%)]	Loss: 0.020746
2020-06-07 23:13:31,548 | Train Epoch: 22 [40960/59392 (69%)]	Loss: 0.012168
2020-06-07 23:13:32,018 | Train Epoch: 22 [43520/59392 (73%)]	Loss: 0.012237
2020-06-07 23:13:32,500 | Train Epoch: 22 [46080/59392 (78%)]	Loss: 0.004190
2020-06-07 23:13:32,975 | Train Epoch: 22 [48640/59392 (82%)]	Loss: 0.026230
2020-06-07 23:13:33,446 | Train Epoch: 22 [51200/59392 (86%)]	Loss: 0.013743
2020-06-07 23:13:33,918 | Train Epoch: 22 [53760/59392 (91%)]	Loss: 0.009496
2020-06-07 23:13:34,383 | Train Epoch: 22 [56320/59392 (95%)]	Loss: 0.021440
2020-06-07 23:13:34,839 | Train Epoch: 22 [58880/59392 (99%)]	Loss: 0.060933
2020-06-07 23:13:34,993 | ================================================================================
2020-06-07 23:13:35,020 | Setting learning rate to 0.0775448
2020-06-07 23:13:35,439 | Train Epoch: 23 [0/59392 (0%)]	Loss: 0.023587
2020-06-07 23:13:35,933 | Train Epoch: 23 [2560/59392 (4%)]	Loss: 0.013143
2020-06-07 23:13:36,408 | Train Epoch: 23 [5120/59392 (9%)]	Loss: 0.021511
2020-06-07 23:13:36,883 | Train Epoch: 23 [7680/59392 (13%)]	Loss: 0.025210
2020-06-07 23:13:37,354 | Train Epoch: 23 [10240/59392 (17%)]	Loss: 0.034299
2020-06-07 23:13:37,819 | Train Epoch: 23 [12800/59392 (22%)]	Loss: 0.042735
2020-06-07 23:13:38,284 | Train Epoch: 23 [15360/59392 (26%)]	Loss: 0.011710
2020-06-07 23:13:38,769 | Train Epoch: 23 [17920/59392 (30%)]	Loss: 0.019780
2020-06-07 23:13:39,228 | Train Epoch: 23 [20480/59392 (34%)]	Loss: 0.026134
2020-06-07 23:13:39,703 | Train Epoch: 23 [23040/59392 (39%)]	Loss: 0.016509
2020-06-07 23:13:40,161 | Train Epoch: 23 [25600/59392 (43%)]	Loss: 0.021095
2020-06-07 23:13:40,647 | Train Epoch: 23 [28160/59392 (47%)]	Loss: 0.006851
2020-06-07 23:13:41,109 | Train Epoch: 23 [30720/59392 (52%)]	Loss: 0.018115
2020-06-07 23:13:41,586 | Train Epoch: 23 [33280/59392 (56%)]	Loss: 0.020258
2020-06-07 23:13:42,053 | Train Epoch: 23 [35840/59392 (60%)]	Loss: 0.034665
2020-06-07 23:13:42,522 | Train Epoch: 23 [38400/59392 (65%)]	Loss: 0.009454
2020-06-07 23:13:42,990 | Train Epoch: 23 [40960/59392 (69%)]	Loss: 0.024568
2020-06-07 23:13:43,466 | Train Epoch: 23 [43520/59392 (73%)]	Loss: 0.027994
2020-06-07 23:13:43,993 | Train Epoch: 23 [46080/59392 (78%)]	Loss: 0.011626
2020-06-07 23:13:44,455 | Train Epoch: 23 [48640/59392 (82%)]	Loss: 0.033056
2020-06-07 23:13:44,912 | Train Epoch: 23 [51200/59392 (86%)]	Loss: 0.022142
2020-06-07 23:13:45,381 | Train Epoch: 23 [53760/59392 (91%)]	Loss: 0.029503
2020-06-07 23:13:45,852 | Train Epoch: 23 [56320/59392 (95%)]	Loss: 0.019694
2020-06-07 23:13:46,306 | Train Epoch: 23 [58880/59392 (99%)]	Loss: 0.009746
2020-06-07 23:13:46,473 | ================================================================================
2020-06-07 23:13:46,503 | Setting learning rate to 0.075645
2020-06-07 23:13:46,886 | Train Epoch: 24 [0/59392 (0%)]	Loss: 0.009537
2020-06-07 23:13:47,360 | Train Epoch: 24 [2560/59392 (4%)]	Loss: 0.008969
2020-06-07 23:13:47,838 | Train Epoch: 24 [5120/59392 (9%)]	Loss: 0.016507
2020-06-07 23:13:48,317 | Train Epoch: 24 [7680/59392 (13%)]	Loss: 0.010526
2020-06-07 23:13:48,775 | Train Epoch: 24 [10240/59392 (17%)]	Loss: 0.005501
2020-06-07 23:13:49,236 | Train Epoch: 24 [12800/59392 (22%)]	Loss: 0.012234
2020-06-07 23:13:49,695 | Train Epoch: 24 [15360/59392 (26%)]	Loss: 0.011252
2020-06-07 23:13:50,160 | Train Epoch: 24 [17920/59392 (30%)]	Loss: 0.008018
2020-06-07 23:13:50,693 | Train Epoch: 24 [20480/59392 (34%)]	Loss: 0.007419
2020-06-07 23:13:51,163 | Train Epoch: 24 [23040/59392 (39%)]	Loss: 0.016198
2020-06-07 23:13:51,622 | Train Epoch: 24 [25600/59392 (43%)]	Loss: 0.008739
2020-06-07 23:13:52,090 | Train Epoch: 24 [28160/59392 (47%)]	Loss: 0.016030
2020-06-07 23:13:52,558 | Train Epoch: 24 [30720/59392 (52%)]	Loss: 0.007708
2020-06-07 23:13:53,018 | Train Epoch: 24 [33280/59392 (56%)]	Loss: 0.006628
2020-06-07 23:13:53,482 | Train Epoch: 24 [35840/59392 (60%)]	Loss: 0.013940
2020-06-07 23:13:53,945 | Train Epoch: 24 [38400/59392 (65%)]	Loss: 0.005621
2020-06-07 23:13:54,408 | Train Epoch: 24 [40960/59392 (69%)]	Loss: 0.012783
2020-06-07 23:13:54,872 | Train Epoch: 24 [43520/59392 (73%)]	Loss: 0.020655
2020-06-07 23:13:55,384 | Train Epoch: 24 [46080/59392 (78%)]	Loss: 0.017731
2020-06-07 23:13:55,853 | Train Epoch: 24 [48640/59392 (82%)]	Loss: 0.014585
2020-06-07 23:13:56,345 | Train Epoch: 24 [51200/59392 (86%)]	Loss: 0.014858
2020-06-07 23:13:56,810 | Train Epoch: 24 [53760/59392 (91%)]	Loss: 0.014065
2020-06-07 23:13:57,285 | Train Epoch: 24 [56320/59392 (95%)]	Loss: 0.010710
2020-06-07 23:13:57,741 | Train Epoch: 24 [58880/59392 (99%)]	Loss: 0.036887
2020-06-07 23:13:57,919 | ================================================================================
2020-06-07 23:14:09,358 | TRAIN: Clean loss: 0.0835, Clean accuracy: 57701/59001 (97.80%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 7/256 (2.73%)
2020-06-07 23:14:13,112 | TEST: Clean loss: 0.1466, Clean accuracy: 8666/9001 (96.28%), PGD clean accuracy: 243/256 (94.92%), Robust accuracy 12/256 (4.69%)
2020-06-07 23:14:13,123 | ================================================================================
2020-06-07 23:14:13,164 | Setting learning rate to 0.0736934
2020-06-07 23:14:13,557 | Train Epoch: 25 [0/59392 (0%)]	Loss: 0.013973
2020-06-07 23:14:14,063 | Train Epoch: 25 [2560/59392 (4%)]	Loss: 0.033737
2020-06-07 23:14:14,578 | Train Epoch: 25 [5120/59392 (9%)]	Loss: 0.035527
2020-06-07 23:14:15,055 | Train Epoch: 25 [7680/59392 (13%)]	Loss: 0.017985
2020-06-07 23:14:15,514 | Train Epoch: 25 [10240/59392 (17%)]	Loss: 0.012196
2020-06-07 23:14:15,990 | Train Epoch: 25 [12800/59392 (22%)]	Loss: 0.014927
2020-06-07 23:14:16,449 | Train Epoch: 25 [15360/59392 (26%)]	Loss: 0.012176
2020-06-07 23:14:16,913 | Train Epoch: 25 [17920/59392 (30%)]	Loss: 0.009384
2020-06-07 23:14:17,375 | Train Epoch: 25 [20480/59392 (34%)]	Loss: 0.012084
2020-06-07 23:14:17,847 | Train Epoch: 25 [23040/59392 (39%)]	Loss: 0.015988
2020-06-07 23:14:18,315 | Train Epoch: 25 [25600/59392 (43%)]	Loss: 0.010021
2020-06-07 23:14:18,807 | Train Epoch: 25 [28160/59392 (47%)]	Loss: 0.024034
2020-06-07 23:14:19,270 | Train Epoch: 25 [30720/59392 (52%)]	Loss: 0.028016
2020-06-07 23:14:19,748 | Train Epoch: 25 [33280/59392 (56%)]	Loss: 0.013391
2020-06-07 23:14:20,208 | Train Epoch: 25 [35840/59392 (60%)]	Loss: 0.019907
2020-06-07 23:14:20,676 | Train Epoch: 25 [38400/59392 (65%)]	Loss: 0.006716
2020-06-07 23:14:21,201 | Train Epoch: 25 [40960/59392 (69%)]	Loss: 0.012442
2020-06-07 23:14:21,672 | Train Epoch: 25 [43520/59392 (73%)]	Loss: 0.005780
2020-06-07 23:14:22,137 | Train Epoch: 25 [46080/59392 (78%)]	Loss: 0.011019
2020-06-07 23:14:22,602 | Train Epoch: 25 [48640/59392 (82%)]	Loss: 0.005299
2020-06-07 23:14:23,071 | Train Epoch: 25 [51200/59392 (86%)]	Loss: 0.014376
2020-06-07 23:14:23,536 | Train Epoch: 25 [53760/59392 (91%)]	Loss: 0.016797
2020-06-07 23:14:24,017 | Train Epoch: 25 [56320/59392 (95%)]	Loss: 0.017357
2020-06-07 23:14:24,472 | Train Epoch: 25 [58880/59392 (99%)]	Loss: 0.038939
2020-06-07 23:14:24,630 | ================================================================================
2020-06-07 23:14:24,699 | Setting learning rate to 0.0716942
2020-06-07 23:14:25,091 | Train Epoch: 26 [0/59392 (0%)]	Loss: 0.025238
2020-06-07 23:14:25,572 | Train Epoch: 26 [2560/59392 (4%)]	Loss: 0.046568
2020-06-07 23:14:26,049 | Train Epoch: 26 [5120/59392 (9%)]	Loss: 0.017223
2020-06-07 23:14:26,573 | Train Epoch: 26 [7680/59392 (13%)]	Loss: 0.013857
2020-06-07 23:14:27,052 | Train Epoch: 26 [10240/59392 (17%)]	Loss: 0.031382
2020-06-07 23:14:27,524 | Train Epoch: 26 [12800/59392 (22%)]	Loss: 0.045385
2020-06-07 23:14:28,009 | Train Epoch: 26 [15360/59392 (26%)]	Loss: 0.027877
2020-06-07 23:14:28,482 | Train Epoch: 26 [17920/59392 (30%)]	Loss: 0.010192
2020-06-07 23:14:28,967 | Train Epoch: 26 [20480/59392 (34%)]	Loss: 0.008612
2020-06-07 23:14:29,448 | Train Epoch: 26 [23040/59392 (39%)]	Loss: 0.005321
2020-06-07 23:14:29,929 | Train Epoch: 26 [25600/59392 (43%)]	Loss: 0.013356
2020-06-07 23:14:30,418 | Train Epoch: 26 [28160/59392 (47%)]	Loss: 0.015932
2020-06-07 23:14:30,907 | Train Epoch: 26 [30720/59392 (52%)]	Loss: 0.027401
2020-06-07 23:14:31,378 | Train Epoch: 26 [33280/59392 (56%)]	Loss: 0.006550
2020-06-07 23:14:31,857 | Train Epoch: 26 [35840/59392 (60%)]	Loss: 0.007268
2020-06-07 23:14:32,338 | Train Epoch: 26 [38400/59392 (65%)]	Loss: 0.009527
2020-06-07 23:14:32,822 | Train Epoch: 26 [40960/59392 (69%)]	Loss: 0.014084
2020-06-07 23:14:33,295 | Train Epoch: 26 [43520/59392 (73%)]	Loss: 0.005003
2020-06-07 23:14:33,772 | Train Epoch: 26 [46080/59392 (78%)]	Loss: 0.016980
2020-06-07 23:14:34,247 | Train Epoch: 26 [48640/59392 (82%)]	Loss: 0.011294
2020-06-07 23:14:34,721 | Train Epoch: 26 [51200/59392 (86%)]	Loss: 0.014728
2020-06-07 23:14:35,187 | Train Epoch: 26 [53760/59392 (91%)]	Loss: 0.007270
2020-06-07 23:14:35,665 | Train Epoch: 26 [56320/59392 (95%)]	Loss: 0.014866
2020-06-07 23:14:36,130 | Train Epoch: 26 [58880/59392 (99%)]	Loss: 0.018189
2020-06-07 23:14:36,290 | ================================================================================
2020-06-07 23:14:36,320 | Setting learning rate to 0.0696513
2020-06-07 23:14:36,723 | Train Epoch: 27 [0/59392 (0%)]	Loss: 0.004704
2020-06-07 23:14:37,219 | Train Epoch: 27 [2560/59392 (4%)]	Loss: 0.005393
2020-06-07 23:14:37,696 | Train Epoch: 27 [5120/59392 (9%)]	Loss: 0.014358
2020-06-07 23:14:38,178 | Train Epoch: 27 [7680/59392 (13%)]	Loss: 0.004675
2020-06-07 23:14:38,663 | Train Epoch: 27 [10240/59392 (17%)]	Loss: 0.010222
2020-06-07 23:14:39,134 | Train Epoch: 27 [12800/59392 (22%)]	Loss: 0.009443
2020-06-07 23:14:39,699 | Train Epoch: 27 [15360/59392 (26%)]	Loss: 0.007649
2020-06-07 23:14:40,167 | Train Epoch: 27 [17920/59392 (30%)]	Loss: 0.009226
2020-06-07 23:14:40,648 | Train Epoch: 27 [20480/59392 (34%)]	Loss: 0.003896
2020-06-07 23:14:41,120 | Train Epoch: 27 [23040/59392 (39%)]	Loss: 0.004755
2020-06-07 23:14:41,600 | Train Epoch: 27 [25600/59392 (43%)]	Loss: 0.024150
2020-06-07 23:14:42,084 | Train Epoch: 27 [28160/59392 (47%)]	Loss: 0.011466
2020-06-07 23:14:42,568 | Train Epoch: 27 [30720/59392 (52%)]	Loss: 0.004550
2020-06-07 23:14:43,046 | Train Epoch: 27 [33280/59392 (56%)]	Loss: 0.004015
2020-06-07 23:14:43,525 | Train Epoch: 27 [35840/59392 (60%)]	Loss: 0.025315
2020-06-07 23:14:43,993 | Train Epoch: 27 [38400/59392 (65%)]	Loss: 0.005489
2020-06-07 23:14:44,466 | Train Epoch: 27 [40960/59392 (69%)]	Loss: 0.015099
2020-06-07 23:14:44,937 | Train Epoch: 27 [43520/59392 (73%)]	Loss: 0.011523
2020-06-07 23:14:45,414 | Train Epoch: 27 [46080/59392 (78%)]	Loss: 0.018097
2020-06-07 23:14:45,889 | Train Epoch: 27 [48640/59392 (82%)]	Loss: 0.006261
2020-06-07 23:14:46,439 | Train Epoch: 27 [51200/59392 (86%)]	Loss: 0.015387
2020-06-07 23:14:46,919 | Train Epoch: 27 [53760/59392 (91%)]	Loss: 0.005477
2020-06-07 23:14:47,394 | Train Epoch: 27 [56320/59392 (95%)]	Loss: 0.007036
2020-06-07 23:14:47,849 | Train Epoch: 27 [58880/59392 (99%)]	Loss: 0.005880
2020-06-07 23:14:48,001 | ================================================================================
2020-06-07 23:14:48,033 | Setting learning rate to 0.0675687
2020-06-07 23:14:48,428 | Train Epoch: 28 [0/59392 (0%)]	Loss: 0.016093
2020-06-07 23:14:48,934 | Train Epoch: 28 [2560/59392 (4%)]	Loss: 0.022818
2020-06-07 23:14:49,409 | Train Epoch: 28 [5120/59392 (9%)]	Loss: 0.013014
2020-06-07 23:14:49,892 | Train Epoch: 28 [7680/59392 (13%)]	Loss: 0.016363
2020-06-07 23:14:50,387 | Train Epoch: 28 [10240/59392 (17%)]	Loss: 0.007695
2020-06-07 23:14:50,877 | Train Epoch: 28 [12800/59392 (22%)]	Loss: 0.005418
2020-06-07 23:14:51,423 | Train Epoch: 28 [15360/59392 (26%)]	Loss: 0.008419
2020-06-07 23:14:51,921 | Train Epoch: 28 [17920/59392 (30%)]	Loss: 0.003065
2020-06-07 23:14:52,403 | Train Epoch: 28 [20480/59392 (34%)]	Loss: 0.005986
2020-06-07 23:14:52,882 | Train Epoch: 28 [23040/59392 (39%)]	Loss: 0.007498
2020-06-07 23:14:53,352 | Train Epoch: 28 [25600/59392 (43%)]	Loss: 0.008428
2020-06-07 23:14:53,822 | Train Epoch: 28 [28160/59392 (47%)]	Loss: 0.005503
2020-06-07 23:14:54,313 | Train Epoch: 28 [30720/59392 (52%)]	Loss: 0.011464
2020-06-07 23:14:54,831 | Train Epoch: 28 [33280/59392 (56%)]	Loss: 0.009009
2020-06-07 23:14:55,324 | Train Epoch: 28 [35840/59392 (60%)]	Loss: 0.014570
2020-06-07 23:14:55,797 | Train Epoch: 28 [38400/59392 (65%)]	Loss: 0.004239
2020-06-07 23:14:56,271 | Train Epoch: 28 [40960/59392 (69%)]	Loss: 0.014245
2020-06-07 23:14:56,729 | Train Epoch: 28 [43520/59392 (73%)]	Loss: 0.009736
2020-06-07 23:14:57,203 | Train Epoch: 28 [46080/59392 (78%)]	Loss: 0.003809
2020-06-07 23:14:57,683 | Train Epoch: 28 [48640/59392 (82%)]	Loss: 0.007599
2020-06-07 23:14:58,160 | Train Epoch: 28 [51200/59392 (86%)]	Loss: 0.004496
2020-06-07 23:14:58,637 | Train Epoch: 28 [53760/59392 (91%)]	Loss: 0.011544
2020-06-07 23:14:59,120 | Train Epoch: 28 [56320/59392 (95%)]	Loss: 0.013004
2020-06-07 23:14:59,581 | Train Epoch: 28 [58880/59392 (99%)]	Loss: 0.006388
2020-06-07 23:14:59,734 | ================================================================================
2020-06-07 23:15:11,788 | TRAIN: Clean loss: 0.0100, Clean accuracy: 58883/59001 (99.80%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 22/256 (8.59%)
2020-06-07 23:15:15,750 | TEST: Clean loss: 0.0497, Clean accuracy: 8879/9001 (98.64%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 19/256 (7.42%)
2020-06-07 23:15:15,754 | ================================================================================
2020-06-07 23:15:15,779 | Setting learning rate to 0.0654508
2020-06-07 23:15:16,196 | Train Epoch: 29 [0/59392 (0%)]	Loss: 0.012850
2020-06-07 23:15:16,687 | Train Epoch: 29 [2560/59392 (4%)]	Loss: 0.008104
2020-06-07 23:15:17,173 | Train Epoch: 29 [5120/59392 (9%)]	Loss: 0.010968
2020-06-07 23:15:17,649 | Train Epoch: 29 [7680/59392 (13%)]	Loss: 0.003921
2020-06-07 23:15:18,199 | Train Epoch: 29 [10240/59392 (17%)]	Loss: 0.010652
2020-06-07 23:15:18,681 | Train Epoch: 29 [12800/59392 (22%)]	Loss: 0.035185
2020-06-07 23:15:19,163 | Train Epoch: 29 [15360/59392 (26%)]	Loss: 0.010907
2020-06-07 23:15:19,640 | Train Epoch: 29 [17920/59392 (30%)]	Loss: 0.006663
2020-06-07 23:15:20,137 | Train Epoch: 29 [20480/59392 (34%)]	Loss: 0.011125
2020-06-07 23:15:20,612 | Train Epoch: 29 [23040/59392 (39%)]	Loss: 0.008124
2020-06-07 23:15:21,092 | Train Epoch: 29 [25600/59392 (43%)]	Loss: 0.015509
2020-06-07 23:15:21,561 | Train Epoch: 29 [28160/59392 (47%)]	Loss: 0.005187
2020-06-07 23:15:22,038 | Train Epoch: 29 [30720/59392 (52%)]	Loss: 0.013591
2020-06-07 23:15:22,512 | Train Epoch: 29 [33280/59392 (56%)]	Loss: 0.010676
2020-06-07 23:15:23,019 | Train Epoch: 29 [35840/59392 (60%)]	Loss: 0.015696
2020-06-07 23:15:23,483 | Train Epoch: 29 [38400/59392 (65%)]	Loss: 0.009891
2020-06-07 23:15:23,943 | Train Epoch: 29 [40960/59392 (69%)]	Loss: 0.010970
2020-06-07 23:15:24,420 | Train Epoch: 29 [43520/59392 (73%)]	Loss: 0.006719
2020-06-07 23:15:24,887 | Train Epoch: 29 [46080/59392 (78%)]	Loss: 0.002895
2020-06-07 23:15:25,363 | Train Epoch: 29 [48640/59392 (82%)]	Loss: 0.003649
2020-06-07 23:15:25,830 | Train Epoch: 29 [51200/59392 (86%)]	Loss: 0.003174
2020-06-07 23:15:26,304 | Train Epoch: 29 [53760/59392 (91%)]	Loss: 0.002646
2020-06-07 23:15:26,805 | Train Epoch: 29 [56320/59392 (95%)]	Loss: 0.008115
2020-06-07 23:15:27,258 | Train Epoch: 29 [58880/59392 (99%)]	Loss: 0.036112
2020-06-07 23:15:27,416 | ================================================================================
2020-06-07 23:15:27,465 | Setting learning rate to 0.0633018
2020-06-07 23:15:27,861 | Train Epoch: 30 [0/59392 (0%)]	Loss: 0.006415
2020-06-07 23:15:28,353 | Train Epoch: 30 [2560/59392 (4%)]	Loss: 0.032530
2020-06-07 23:15:28,822 | Train Epoch: 30 [5120/59392 (9%)]	Loss: 0.008550
2020-06-07 23:15:29,299 | Train Epoch: 30 [7680/59392 (13%)]	Loss: 0.013171
2020-06-07 23:15:29,776 | Train Epoch: 30 [10240/59392 (17%)]	Loss: 0.021721
2020-06-07 23:15:30,258 | Train Epoch: 30 [12800/59392 (22%)]	Loss: 0.002926
2020-06-07 23:15:30,769 | Train Epoch: 30 [15360/59392 (26%)]	Loss: 0.005672
2020-06-07 23:15:31,242 | Train Epoch: 30 [17920/59392 (30%)]	Loss: 0.021631
2020-06-07 23:15:31,720 | Train Epoch: 30 [20480/59392 (34%)]	Loss: 0.004707
2020-06-07 23:15:32,188 | Train Epoch: 30 [23040/59392 (39%)]	Loss: 0.009203
2020-06-07 23:15:32,673 | Train Epoch: 30 [25600/59392 (43%)]	Loss: 0.004144
2020-06-07 23:15:33,146 | Train Epoch: 30 [28160/59392 (47%)]	Loss: 0.021468
2020-06-07 23:15:33,616 | Train Epoch: 30 [30720/59392 (52%)]	Loss: 0.004912
2020-06-07 23:15:34,079 | Train Epoch: 30 [33280/59392 (56%)]	Loss: 0.008481
2020-06-07 23:15:34,567 | Train Epoch: 30 [35840/59392 (60%)]	Loss: 0.008566
2020-06-07 23:15:35,050 | Train Epoch: 30 [38400/59392 (65%)]	Loss: 0.014939
2020-06-07 23:15:35,557 | Train Epoch: 30 [40960/59392 (69%)]	Loss: 0.005524
2020-06-07 23:15:36,096 | Train Epoch: 30 [43520/59392 (73%)]	Loss: 0.004239
2020-06-07 23:15:36,562 | Train Epoch: 30 [46080/59392 (78%)]	Loss: 0.005847
2020-06-07 23:15:37,024 | Train Epoch: 30 [48640/59392 (82%)]	Loss: 0.003700
2020-06-07 23:15:37,504 | Train Epoch: 30 [51200/59392 (86%)]	Loss: 0.004878
2020-06-07 23:15:37,968 | Train Epoch: 30 [53760/59392 (91%)]	Loss: 0.007268
2020-06-07 23:15:38,439 | Train Epoch: 30 [56320/59392 (95%)]	Loss: 0.003555
2020-06-07 23:15:38,908 | Train Epoch: 30 [58880/59392 (99%)]	Loss: 0.008312
2020-06-07 23:15:39,059 | ================================================================================
2020-06-07 23:15:39,090 | Setting learning rate to 0.061126
2020-06-07 23:15:39,465 | Train Epoch: 31 [0/59392 (0%)]	Loss: 0.003723
2020-06-07 23:15:39,935 | Train Epoch: 31 [2560/59392 (4%)]	Loss: 0.007687
2020-06-07 23:15:40,430 | Train Epoch: 31 [5120/59392 (9%)]	Loss: 0.012593
2020-06-07 23:15:40,888 | Train Epoch: 31 [7680/59392 (13%)]	Loss: 0.004406
2020-06-07 23:15:41,353 | Train Epoch: 31 [10240/59392 (17%)]	Loss: 0.004053
2020-06-07 23:15:41,817 | Train Epoch: 31 [12800/59392 (22%)]	Loss: 0.003274
2020-06-07 23:15:42,276 | Train Epoch: 31 [15360/59392 (26%)]	Loss: 0.005914
2020-06-07 23:15:42,811 | Train Epoch: 31 [17920/59392 (30%)]	Loss: 0.009665
2020-06-07 23:15:43,276 | Train Epoch: 31 [20480/59392 (34%)]	Loss: 0.008551
2020-06-07 23:15:43,731 | Train Epoch: 31 [23040/59392 (39%)]	Loss: 0.013476
2020-06-07 23:15:44,192 | Train Epoch: 31 [25600/59392 (43%)]	Loss: 0.003395
2020-06-07 23:15:44,674 | Train Epoch: 31 [28160/59392 (47%)]	Loss: 0.012973
2020-06-07 23:15:45,144 | Train Epoch: 31 [30720/59392 (52%)]	Loss: 0.005976
2020-06-07 23:15:45,637 | Train Epoch: 31 [33280/59392 (56%)]	Loss: 0.007136
2020-06-07 23:15:46,101 | Train Epoch: 31 [35840/59392 (60%)]	Loss: 0.015522
2020-06-07 23:15:46,585 | Train Epoch: 31 [38400/59392 (65%)]	Loss: 0.007052
2020-06-07 23:15:47,063 | Train Epoch: 31 [40960/59392 (69%)]	Loss: 0.003823
2020-06-07 23:15:47,575 | Train Epoch: 31 [43520/59392 (73%)]	Loss: 0.002407
2020-06-07 23:15:48,040 | Train Epoch: 31 [46080/59392 (78%)]	Loss: 0.003452
2020-06-07 23:15:48,508 | Train Epoch: 31 [48640/59392 (82%)]	Loss: 0.005895
2020-06-07 23:15:48,978 | Train Epoch: 31 [51200/59392 (86%)]	Loss: 0.003960
2020-06-07 23:15:49,439 | Train Epoch: 31 [53760/59392 (91%)]	Loss: 0.001975
2020-06-07 23:15:49,909 | Train Epoch: 31 [56320/59392 (95%)]	Loss: 0.005745
2020-06-07 23:15:50,367 | Train Epoch: 31 [58880/59392 (99%)]	Loss: 0.003488
2020-06-07 23:15:50,527 | ================================================================================
2020-06-07 23:15:50,562 | Setting learning rate to 0.0589278
2020-06-07 23:15:51,019 | Train Epoch: 32 [0/59392 (0%)]	Loss: 0.003075
2020-06-07 23:15:51,491 | Train Epoch: 32 [2560/59392 (4%)]	Loss: 0.006355
2020-06-07 23:15:51,965 | Train Epoch: 32 [5120/59392 (9%)]	Loss: 0.002533
2020-06-07 23:15:52,433 | Train Epoch: 32 [7680/59392 (13%)]	Loss: 0.003171
2020-06-07 23:15:52,904 | Train Epoch: 32 [10240/59392 (17%)]	Loss: 0.017223
2020-06-07 23:15:53,375 | Train Epoch: 32 [12800/59392 (22%)]	Loss: 0.005306
2020-06-07 23:15:53,865 | Train Epoch: 32 [15360/59392 (26%)]	Loss: 0.015144
2020-06-07 23:15:54,336 | Train Epoch: 32 [17920/59392 (30%)]	Loss: 0.010195
2020-06-07 23:15:54,828 | Train Epoch: 32 [20480/59392 (34%)]	Loss: 0.011264
2020-06-07 23:15:55,299 | Train Epoch: 32 [23040/59392 (39%)]	Loss: 0.009025
2020-06-07 23:15:55,762 | Train Epoch: 32 [25600/59392 (43%)]	Loss: 0.002626
2020-06-07 23:15:56,236 | Train Epoch: 32 [28160/59392 (47%)]	Loss: 0.003310
2020-06-07 23:15:56,709 | Train Epoch: 32 [30720/59392 (52%)]	Loss: 0.005465
2020-06-07 23:15:57,185 | Train Epoch: 32 [33280/59392 (56%)]	Loss: 0.003938
2020-06-07 23:15:57,677 | Train Epoch: 32 [35840/59392 (60%)]	Loss: 0.005015
2020-06-07 23:15:58,143 | Train Epoch: 32 [38400/59392 (65%)]	Loss: 0.003293
2020-06-07 23:15:58,648 | Train Epoch: 32 [40960/59392 (69%)]	Loss: 0.005285
2020-06-07 23:15:59,110 | Train Epoch: 32 [43520/59392 (73%)]	Loss: 0.003136
2020-06-07 23:15:59,583 | Train Epoch: 32 [46080/59392 (78%)]	Loss: 0.007901
2020-06-07 23:16:00,068 | Train Epoch: 32 [48640/59392 (82%)]	Loss: 0.003794
2020-06-07 23:16:00,625 | Train Epoch: 32 [51200/59392 (86%)]	Loss: 0.004175
2020-06-07 23:16:01,093 | Train Epoch: 32 [53760/59392 (91%)]	Loss: 0.002252
2020-06-07 23:16:01,562 | Train Epoch: 32 [56320/59392 (95%)]	Loss: 0.012818
2020-06-07 23:16:02,021 | Train Epoch: 32 [58880/59392 (99%)]	Loss: 0.004546
2020-06-07 23:16:02,181 | ================================================================================
2020-06-07 23:16:13,846 | TRAIN: Clean loss: 0.0127, Clean accuracy: 58798/59001 (99.66%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 13/256 (5.08%)
2020-06-07 23:16:17,602 | TEST: Clean loss: 0.0623, Clean accuracy: 8852/9001 (98.34%), PGD clean accuracy: 253/256 (98.83%), Robust accuracy 11/256 (4.30%)
2020-06-07 23:16:17,607 | ================================================================================
2020-06-07 23:16:17,655 | Setting learning rate to 0.0567117
2020-06-07 23:16:18,051 | Train Epoch: 33 [0/59392 (0%)]	Loss: 0.008559
2020-06-07 23:16:18,525 | Train Epoch: 33 [2560/59392 (4%)]	Loss: 0.003173
2020-06-07 23:16:19,048 | Train Epoch: 33 [5120/59392 (9%)]	Loss: 0.006336
2020-06-07 23:16:19,543 | Train Epoch: 33 [7680/59392 (13%)]	Loss: 0.005762
2020-06-07 23:16:20,013 | Train Epoch: 33 [10240/59392 (17%)]	Loss: 0.005294
2020-06-07 23:16:20,487 | Train Epoch: 33 [12800/59392 (22%)]	Loss: 0.007608
2020-06-07 23:16:20,944 | Train Epoch: 33 [15360/59392 (26%)]	Loss: 0.003408
2020-06-07 23:16:21,411 | Train Epoch: 33 [17920/59392 (30%)]	Loss: 0.012490
2020-06-07 23:16:21,880 | Train Epoch: 33 [20480/59392 (34%)]	Loss: 0.004874
2020-06-07 23:16:22,356 | Train Epoch: 33 [23040/59392 (39%)]	Loss: 0.002032
2020-06-07 23:16:22,851 | Train Epoch: 33 [25600/59392 (43%)]	Loss: 0.005816
2020-06-07 23:16:23,324 | Train Epoch: 33 [28160/59392 (47%)]	Loss: 0.005204
2020-06-07 23:16:23,789 | Train Epoch: 33 [30720/59392 (52%)]	Loss: 0.003866
2020-06-07 23:16:24,293 | Train Epoch: 33 [33280/59392 (56%)]	Loss: 0.009926
2020-06-07 23:16:24,775 | Train Epoch: 33 [35840/59392 (60%)]	Loss: 0.002530
2020-06-07 23:16:25,244 | Train Epoch: 33 [38400/59392 (65%)]	Loss: 0.004041
2020-06-07 23:16:25,713 | Train Epoch: 33 [40960/59392 (69%)]	Loss: 0.002713
2020-06-07 23:16:26,197 | Train Epoch: 33 [43520/59392 (73%)]	Loss: 0.015038
2020-06-07 23:16:26,666 | Train Epoch: 33 [46080/59392 (78%)]	Loss: 0.004671
2020-06-07 23:16:27,131 | Train Epoch: 33 [48640/59392 (82%)]	Loss: 0.003627
2020-06-07 23:16:27,603 | Train Epoch: 33 [51200/59392 (86%)]	Loss: 0.003272
2020-06-07 23:16:28,088 | Train Epoch: 33 [53760/59392 (91%)]	Loss: 0.021244
2020-06-07 23:16:28,556 | Train Epoch: 33 [56320/59392 (95%)]	Loss: 0.002479
2020-06-07 23:16:29,011 | Train Epoch: 33 [58880/59392 (99%)]	Loss: 0.036025
2020-06-07 23:16:29,171 | ================================================================================
2020-06-07 23:16:29,209 | Setting learning rate to 0.054482
2020-06-07 23:16:29,612 | Train Epoch: 34 [0/59392 (0%)]	Loss: 0.025694
2020-06-07 23:16:30,085 | Train Epoch: 34 [2560/59392 (4%)]	Loss: 0.038031
2020-06-07 23:16:30,551 | Train Epoch: 34 [5120/59392 (9%)]	Loss: 0.020489
2020-06-07 23:16:31,026 | Train Epoch: 34 [7680/59392 (13%)]	Loss: 0.011390
2020-06-07 23:16:31,519 | Train Epoch: 34 [10240/59392 (17%)]	Loss: 0.031700
2020-06-07 23:16:32,061 | Train Epoch: 34 [12800/59392 (22%)]	Loss: 0.019785
2020-06-07 23:16:32,530 | Train Epoch: 34 [15360/59392 (26%)]	Loss: 0.016094
2020-06-07 23:16:32,989 | Train Epoch: 34 [17920/59392 (30%)]	Loss: 0.021411
2020-06-07 23:16:33,456 | Train Epoch: 34 [20480/59392 (34%)]	Loss: 0.018417
2020-06-07 23:16:33,920 | Train Epoch: 34 [23040/59392 (39%)]	Loss: 0.013499
2020-06-07 23:16:34,391 | Train Epoch: 34 [25600/59392 (43%)]	Loss: 0.007995
2020-06-07 23:16:34,850 | Train Epoch: 34 [28160/59392 (47%)]	Loss: 0.010811
2020-06-07 23:16:35,310 | Train Epoch: 34 [30720/59392 (52%)]	Loss: 0.009874
2020-06-07 23:16:35,773 | Train Epoch: 34 [33280/59392 (56%)]	Loss: 0.023846
2020-06-07 23:16:36,248 | Train Epoch: 34 [35840/59392 (60%)]	Loss: 0.006221
2020-06-07 23:16:36,716 | Train Epoch: 34 [38400/59392 (65%)]	Loss: 0.023675
2020-06-07 23:16:37,186 | Train Epoch: 34 [40960/59392 (69%)]	Loss: 0.014875
2020-06-07 23:16:37,647 | Train Epoch: 34 [43520/59392 (73%)]	Loss: 0.005180
2020-06-07 23:16:38,119 | Train Epoch: 34 [46080/59392 (78%)]	Loss: 0.020786
2020-06-07 23:16:38,622 | Train Epoch: 34 [48640/59392 (82%)]	Loss: 0.013384
2020-06-07 23:16:39,111 | Train Epoch: 34 [51200/59392 (86%)]	Loss: 0.009424
2020-06-07 23:16:39,586 | Train Epoch: 34 [53760/59392 (91%)]	Loss: 0.006752
2020-06-07 23:16:40,052 | Train Epoch: 34 [56320/59392 (95%)]	Loss: 0.021013
2020-06-07 23:16:40,514 | Train Epoch: 34 [58880/59392 (99%)]	Loss: 0.011673
2020-06-07 23:16:40,675 | ================================================================================
2020-06-07 23:16:40,736 | Setting learning rate to 0.0522432
2020-06-07 23:16:41,135 | Train Epoch: 35 [0/59392 (0%)]	Loss: 0.009349
2020-06-07 23:16:41,610 | Train Epoch: 35 [2560/59392 (4%)]	Loss: 0.005764
2020-06-07 23:16:42,101 | Train Epoch: 35 [5120/59392 (9%)]	Loss: 0.006670
2020-06-07 23:16:42,598 | Train Epoch: 35 [7680/59392 (13%)]	Loss: 0.009683
2020-06-07 23:16:43,084 | Train Epoch: 35 [10240/59392 (17%)]	Loss: 0.005693
2020-06-07 23:16:43,655 | Train Epoch: 35 [12800/59392 (22%)]	Loss: 0.004671
2020-06-07 23:16:44,142 | Train Epoch: 35 [15360/59392 (26%)]	Loss: 0.002819
2020-06-07 23:16:44,605 | Train Epoch: 35 [17920/59392 (30%)]	Loss: 0.005959
2020-06-07 23:16:45,099 | Train Epoch: 35 [20480/59392 (34%)]	Loss: 0.006177
2020-06-07 23:16:45,572 | Train Epoch: 35 [23040/59392 (39%)]	Loss: 0.016332
2020-06-07 23:16:46,082 | Train Epoch: 35 [25600/59392 (43%)]	Loss: 0.004073
2020-06-07 23:16:46,588 | Train Epoch: 35 [28160/59392 (47%)]	Loss: 0.003406
2020-06-07 23:16:47,077 | Train Epoch: 35 [30720/59392 (52%)]	Loss: 0.011879
2020-06-07 23:16:47,565 | Train Epoch: 35 [33280/59392 (56%)]	Loss: 0.002464
2020-06-07 23:16:48,073 | Train Epoch: 35 [35840/59392 (60%)]	Loss: 0.005640
2020-06-07 23:16:48,584 | Train Epoch: 35 [38400/59392 (65%)]	Loss: 0.005889
2020-06-07 23:16:49,074 | Train Epoch: 35 [40960/59392 (69%)]	Loss: 0.012085
2020-06-07 23:16:49,556 | Train Epoch: 35 [43520/59392 (73%)]	Loss: 0.010279
2020-06-07 23:16:50,045 | Train Epoch: 35 [46080/59392 (78%)]	Loss: 0.006249
2020-06-07 23:16:50,535 | Train Epoch: 35 [48640/59392 (82%)]	Loss: 0.011997
2020-06-07 23:16:51,043 | Train Epoch: 35 [51200/59392 (86%)]	Loss: 0.007839
2020-06-07 23:16:51,562 | Train Epoch: 35 [53760/59392 (91%)]	Loss: 0.016504
2020-06-07 23:16:52,084 | Train Epoch: 35 [56320/59392 (95%)]	Loss: 0.005782
2020-06-07 23:16:52,566 | Train Epoch: 35 [58880/59392 (99%)]	Loss: 0.007084
2020-06-07 23:16:52,747 | ================================================================================
2020-06-07 23:16:52,784 | Setting learning rate to 0.05
2020-06-07 23:16:53,174 | Train Epoch: 36 [0/59392 (0%)]	Loss: 0.007495
2020-06-07 23:16:53,672 | Train Epoch: 36 [2560/59392 (4%)]	Loss: 0.003646
2020-06-07 23:16:54,163 | Train Epoch: 36 [5120/59392 (9%)]	Loss: 0.003609
2020-06-07 23:16:54,641 | Train Epoch: 36 [7680/59392 (13%)]	Loss: 0.013980
2020-06-07 23:16:55,115 | Train Epoch: 36 [10240/59392 (17%)]	Loss: 0.006294
2020-06-07 23:16:55,598 | Train Epoch: 36 [12800/59392 (22%)]	Loss: 0.021667
2020-06-07 23:16:56,066 | Train Epoch: 36 [15360/59392 (26%)]	Loss: 0.005448
2020-06-07 23:16:56,544 | Train Epoch: 36 [17920/59392 (30%)]	Loss: 0.005100
2020-06-07 23:16:57,035 | Train Epoch: 36 [20480/59392 (34%)]	Loss: 0.002808
2020-06-07 23:16:57,603 | Train Epoch: 36 [23040/59392 (39%)]	Loss: 0.002248
2020-06-07 23:16:58,075 | Train Epoch: 36 [25600/59392 (43%)]	Loss: 0.002328
2020-06-07 23:16:58,539 | Train Epoch: 36 [28160/59392 (47%)]	Loss: 0.005604
2020-06-07 23:16:59,003 | Train Epoch: 36 [30720/59392 (52%)]	Loss: 0.003721
2020-06-07 23:16:59,477 | Train Epoch: 36 [33280/59392 (56%)]	Loss: 0.005690
2020-06-07 23:16:59,956 | Train Epoch: 36 [35840/59392 (60%)]	Loss: 0.025435
2020-06-07 23:17:00,421 | Train Epoch: 36 [38400/59392 (65%)]	Loss: 0.031950
2020-06-07 23:17:00,913 | Train Epoch: 36 [40960/59392 (69%)]	Loss: 0.008120
2020-06-07 23:17:01,384 | Train Epoch: 36 [43520/59392 (73%)]	Loss: 0.009514
2020-06-07 23:17:01,871 | Train Epoch: 36 [46080/59392 (78%)]	Loss: 0.011618
2020-06-07 23:17:02,371 | Train Epoch: 36 [48640/59392 (82%)]	Loss: 0.028735
2020-06-07 23:17:02,849 | Train Epoch: 36 [51200/59392 (86%)]	Loss: 0.005264
2020-06-07 23:17:03,313 | Train Epoch: 36 [53760/59392 (91%)]	Loss: 0.020998
2020-06-07 23:17:03,832 | Train Epoch: 36 [56320/59392 (95%)]	Loss: 0.005231
2020-06-07 23:17:04,275 | Train Epoch: 36 [58880/59392 (99%)]	Loss: 0.009514
2020-06-07 23:17:04,423 | ================================================================================
2020-06-07 23:17:16,135 | TRAIN: Clean loss: 0.0085, Clean accuracy: 58870/59001 (99.78%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 10/256 (3.91%)
2020-06-07 23:17:20,082 | TEST: Clean loss: 0.0498, Clean accuracy: 8869/9001 (98.53%), PGD clean accuracy: 252/256 (98.44%), Robust accuracy 13/256 (5.08%)
2020-06-07 23:17:20,091 | ================================================================================
2020-06-07 23:17:20,126 | Setting learning rate to 0.0477568
2020-06-07 23:17:20,537 | Train Epoch: 37 [0/59392 (0%)]	Loss: 0.006376
2020-06-07 23:17:21,026 | Train Epoch: 37 [2560/59392 (4%)]	Loss: 0.002155
2020-06-07 23:17:21,506 | Train Epoch: 37 [5120/59392 (9%)]	Loss: 0.004382
2020-06-07 23:17:21,973 | Train Epoch: 37 [7680/59392 (13%)]	Loss: 0.005571
2020-06-07 23:17:22,443 | Train Epoch: 37 [10240/59392 (17%)]	Loss: 0.010052
2020-06-07 23:17:22,916 | Train Epoch: 37 [12800/59392 (22%)]	Loss: 0.002138
2020-06-07 23:17:23,378 | Train Epoch: 37 [15360/59392 (26%)]	Loss: 0.002058
2020-06-07 23:17:23,857 | Train Epoch: 37 [17920/59392 (30%)]	Loss: 0.003199
2020-06-07 23:17:24,320 | Train Epoch: 37 [20480/59392 (34%)]	Loss: 0.001964
2020-06-07 23:17:24,798 | Train Epoch: 37 [23040/59392 (39%)]	Loss: 0.011671
2020-06-07 23:17:25,266 | Train Epoch: 37 [25600/59392 (43%)]	Loss: 0.001508
2020-06-07 23:17:25,744 | Train Epoch: 37 [28160/59392 (47%)]	Loss: 0.005302
2020-06-07 23:17:26,216 | Train Epoch: 37 [30720/59392 (52%)]	Loss: 0.002460
2020-06-07 23:17:26,689 | Train Epoch: 37 [33280/59392 (56%)]	Loss: 0.005755
2020-06-07 23:17:27,149 | Train Epoch: 37 [35840/59392 (60%)]	Loss: 0.003963
2020-06-07 23:17:27,628 | Train Epoch: 37 [38400/59392 (65%)]	Loss: 0.005312
2020-06-07 23:17:28,173 | Train Epoch: 37 [40960/59392 (69%)]	Loss: 0.010394
2020-06-07 23:17:28,670 | Train Epoch: 37 [43520/59392 (73%)]	Loss: 0.004717
2020-06-07 23:17:29,135 | Train Epoch: 37 [46080/59392 (78%)]	Loss: 0.002173
2020-06-07 23:17:29,602 | Train Epoch: 37 [48640/59392 (82%)]	Loss: 0.001970
2020-06-07 23:17:30,066 | Train Epoch: 37 [51200/59392 (86%)]	Loss: 0.003922
2020-06-07 23:17:30,536 | Train Epoch: 37 [53760/59392 (91%)]	Loss: 0.003772
2020-06-07 23:17:30,997 | Train Epoch: 37 [56320/59392 (95%)]	Loss: 0.003655
2020-06-07 23:17:31,450 | Train Epoch: 37 [58880/59392 (99%)]	Loss: 0.029916
2020-06-07 23:17:31,593 | ================================================================================
2020-06-07 23:17:31,632 | Setting learning rate to 0.045518
2020-06-07 23:17:32,006 | Train Epoch: 38 [0/59392 (0%)]	Loss: 0.009134
2020-06-07 23:17:32,483 | Train Epoch: 38 [2560/59392 (4%)]	Loss: 0.002298
2020-06-07 23:17:32,950 | Train Epoch: 38 [5120/59392 (9%)]	Loss: 0.006903
2020-06-07 23:17:33,435 | Train Epoch: 38 [7680/59392 (13%)]	Loss: 0.002829
2020-06-07 23:17:33,918 | Train Epoch: 38 [10240/59392 (17%)]	Loss: 0.002531
2020-06-07 23:17:34,413 | Train Epoch: 38 [12800/59392 (22%)]	Loss: 0.002201
2020-06-07 23:17:34,950 | Train Epoch: 38 [15360/59392 (26%)]	Loss: 0.003819
2020-06-07 23:17:35,417 | Train Epoch: 38 [17920/59392 (30%)]	Loss: 0.003853
2020-06-07 23:17:35,889 | Train Epoch: 38 [20480/59392 (34%)]	Loss: 0.002491
2020-06-07 23:17:36,356 | Train Epoch: 38 [23040/59392 (39%)]	Loss: 0.009075
2020-06-07 23:17:36,836 | Train Epoch: 38 [25600/59392 (43%)]	Loss: 0.003776
2020-06-07 23:17:37,308 | Train Epoch: 38 [28160/59392 (47%)]	Loss: 0.007739
2020-06-07 23:17:37,786 | Train Epoch: 38 [30720/59392 (52%)]	Loss: 0.005707
2020-06-07 23:17:38,248 | Train Epoch: 38 [33280/59392 (56%)]	Loss: 0.002243
2020-06-07 23:17:38,713 | Train Epoch: 38 [35840/59392 (60%)]	Loss: 0.002092
2020-06-07 23:17:39,175 | Train Epoch: 38 [38400/59392 (65%)]	Loss: 0.003755
2020-06-07 23:17:39,698 | Train Epoch: 38 [40960/59392 (69%)]	Loss: 0.003121
2020-06-07 23:17:40,156 | Train Epoch: 38 [43520/59392 (73%)]	Loss: 0.003310
2020-06-07 23:17:40,626 | Train Epoch: 38 [46080/59392 (78%)]	Loss: 0.004101
2020-06-07 23:17:41,090 | Train Epoch: 38 [48640/59392 (82%)]	Loss: 0.005274
2020-06-07 23:17:41,556 | Train Epoch: 38 [51200/59392 (86%)]	Loss: 0.018581
2020-06-07 23:17:42,032 | Train Epoch: 38 [53760/59392 (91%)]	Loss: 0.003284
2020-06-07 23:17:42,506 | Train Epoch: 38 [56320/59392 (95%)]	Loss: 0.007068
2020-06-07 23:17:42,954 | Train Epoch: 38 [58880/59392 (99%)]	Loss: 0.009168
2020-06-07 23:17:43,106 | ================================================================================
2020-06-07 23:17:43,145 | Setting learning rate to 0.0432883
2020-06-07 23:17:43,591 | Train Epoch: 39 [0/59392 (0%)]	Loss: 0.002454
2020-06-07 23:17:44,062 | Train Epoch: 39 [2560/59392 (4%)]	Loss: 0.007454
2020-06-07 23:17:44,529 | Train Epoch: 39 [5120/59392 (9%)]	Loss: 0.002076
2020-06-07 23:17:44,992 | Train Epoch: 39 [7680/59392 (13%)]	Loss: 0.003323
2020-06-07 23:17:45,459 | Train Epoch: 39 [10240/59392 (17%)]	Loss: 0.002287
2020-06-07 23:17:45,928 | Train Epoch: 39 [12800/59392 (22%)]	Loss: 0.008999
2020-06-07 23:17:46,399 | Train Epoch: 39 [15360/59392 (26%)]	Loss: 0.002267
2020-06-07 23:17:46,870 | Train Epoch: 39 [17920/59392 (30%)]	Loss: 0.016186
2020-06-07 23:17:47,345 | Train Epoch: 39 [20480/59392 (34%)]	Loss: 0.007314
2020-06-07 23:17:47,830 | Train Epoch: 39 [23040/59392 (39%)]	Loss: 0.003307
2020-06-07 23:17:48,295 | Train Epoch: 39 [25600/59392 (43%)]	Loss: 0.021992
2020-06-07 23:17:48,771 | Train Epoch: 39 [28160/59392 (47%)]	Loss: 0.015731
2020-06-07 23:17:49,243 | Train Epoch: 39 [30720/59392 (52%)]	Loss: 0.003193
2020-06-07 23:17:49,714 | Train Epoch: 39 [33280/59392 (56%)]	Loss: 0.008384
2020-06-07 23:17:50,198 | Train Epoch: 39 [35840/59392 (60%)]	Loss: 0.001880
2020-06-07 23:17:50,690 | Train Epoch: 39 [38400/59392 (65%)]	Loss: 0.006496
2020-06-07 23:17:51,175 | Train Epoch: 39 [40960/59392 (69%)]	Loss: 0.002754
2020-06-07 23:17:51,669 | Train Epoch: 39 [43520/59392 (73%)]	Loss: 0.004467
2020-06-07 23:17:52,157 | Train Epoch: 39 [46080/59392 (78%)]	Loss: 0.002608
2020-06-07 23:17:52,733 | Train Epoch: 39 [48640/59392 (82%)]	Loss: 0.002129
2020-06-07 23:17:53,198 | Train Epoch: 39 [51200/59392 (86%)]	Loss: 0.006255
2020-06-07 23:17:53,677 | Train Epoch: 39 [53760/59392 (91%)]	Loss: 0.001678
2020-06-07 23:17:54,149 | Train Epoch: 39 [56320/59392 (95%)]	Loss: 0.009321
2020-06-07 23:17:54,601 | Train Epoch: 39 [58880/59392 (99%)]	Loss: 0.030910
2020-06-07 23:17:54,754 | ================================================================================
2020-06-07 23:17:54,796 | Setting learning rate to 0.0410722
2020-06-07 23:17:55,164 | Train Epoch: 40 [0/59392 (0%)]	Loss: 0.008420
2020-06-07 23:17:55,665 | Train Epoch: 40 [2560/59392 (4%)]	Loss: 0.005618
2020-06-07 23:17:56,149 | Train Epoch: 40 [5120/59392 (9%)]	Loss: 0.004340
2020-06-07 23:17:56,613 | Train Epoch: 40 [7680/59392 (13%)]	Loss: 0.012607
2020-06-07 23:17:57,077 | Train Epoch: 40 [10240/59392 (17%)]	Loss: 0.021038
2020-06-07 23:17:57,558 | Train Epoch: 40 [12800/59392 (22%)]	Loss: 0.009149
2020-06-07 23:17:58,032 | Train Epoch: 40 [15360/59392 (26%)]	Loss: 0.008142
2020-06-07 23:17:58,495 | Train Epoch: 40 [17920/59392 (30%)]	Loss: 0.005370
2020-06-07 23:17:58,953 | Train Epoch: 40 [20480/59392 (34%)]	Loss: 0.012130
2020-06-07 23:17:59,427 | Train Epoch: 40 [23040/59392 (39%)]	Loss: 0.013828
2020-06-07 23:17:59,964 | Train Epoch: 40 [25600/59392 (43%)]	Loss: 0.018552
2020-06-07 23:18:00,439 | Train Epoch: 40 [28160/59392 (47%)]	Loss: 0.004388
2020-06-07 23:18:00,899 | Train Epoch: 40 [30720/59392 (52%)]	Loss: 0.012348
2020-06-07 23:18:01,376 | Train Epoch: 40 [33280/59392 (56%)]	Loss: 0.021618
2020-06-07 23:18:01,830 | Train Epoch: 40 [35840/59392 (60%)]	Loss: 0.013157
2020-06-07 23:18:02,297 | Train Epoch: 40 [38400/59392 (65%)]	Loss: 0.029960
2020-06-07 23:18:02,769 | Train Epoch: 40 [40960/59392 (69%)]	Loss: 0.006246
2020-06-07 23:18:03,235 | Train Epoch: 40 [43520/59392 (73%)]	Loss: 0.005172
2020-06-07 23:18:03,695 | Train Epoch: 40 [46080/59392 (78%)]	Loss: 0.006130
2020-06-07 23:18:04,172 | Train Epoch: 40 [48640/59392 (82%)]	Loss: 0.015888
2020-06-07 23:18:04,698 | Train Epoch: 40 [51200/59392 (86%)]	Loss: 0.011926
2020-06-07 23:18:05,169 | Train Epoch: 40 [53760/59392 (91%)]	Loss: 0.026310
2020-06-07 23:18:05,641 | Train Epoch: 40 [56320/59392 (95%)]	Loss: 0.007755
2020-06-07 23:18:06,088 | Train Epoch: 40 [58880/59392 (99%)]	Loss: 0.007005
2020-06-07 23:18:06,233 | ================================================================================
2020-06-07 23:18:17,786 | TRAIN: Clean loss: 0.0046, Clean accuracy: 58938/59001 (99.89%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 18/256 (7.03%)
2020-06-07 23:18:21,592 | TEST: Clean loss: 0.0445, Clean accuracy: 8891/9001 (98.78%), PGD clean accuracy: 255/256 (99.61%), Robust accuracy 23/256 (8.98%)
2020-06-07 23:18:21,597 | ================================================================================
2020-06-07 23:18:21,627 | Setting learning rate to 0.038874
2020-06-07 23:18:22,022 | Train Epoch: 41 [0/59392 (0%)]	Loss: 0.002611
2020-06-07 23:18:22,523 | Train Epoch: 41 [2560/59392 (4%)]	Loss: 0.004688
2020-06-07 23:18:23,006 | Train Epoch: 41 [5120/59392 (9%)]	Loss: 0.012563
2020-06-07 23:18:23,485 | Train Epoch: 41 [7680/59392 (13%)]	Loss: 0.006249
2020-06-07 23:18:24,038 | Train Epoch: 41 [10240/59392 (17%)]	Loss: 0.010104
2020-06-07 23:18:24,511 | Train Epoch: 41 [12800/59392 (22%)]	Loss: 0.013657
2020-06-07 23:18:24,995 | Train Epoch: 41 [15360/59392 (26%)]	Loss: 0.002894
2020-06-07 23:18:25,461 | Train Epoch: 41 [17920/59392 (30%)]	Loss: 0.005071
2020-06-07 23:18:25,934 | Train Epoch: 41 [20480/59392 (34%)]	Loss: 0.005538
2020-06-07 23:18:26,397 | Train Epoch: 41 [23040/59392 (39%)]	Loss: 0.003891
2020-06-07 23:18:26,861 | Train Epoch: 41 [25600/59392 (43%)]	Loss: 0.004225
2020-06-07 23:18:27,327 | Train Epoch: 41 [28160/59392 (47%)]	Loss: 0.006618
2020-06-07 23:18:27,809 | Train Epoch: 41 [30720/59392 (52%)]	Loss: 0.003120
2020-06-07 23:18:28,305 | Train Epoch: 41 [33280/59392 (56%)]	Loss: 0.015488
2020-06-07 23:18:28,783 | Train Epoch: 41 [35840/59392 (60%)]	Loss: 0.003814
2020-06-07 23:18:29,275 | Train Epoch: 41 [38400/59392 (65%)]	Loss: 0.015898
2020-06-07 23:18:29,771 | Train Epoch: 41 [40960/59392 (69%)]	Loss: 0.002369
2020-06-07 23:18:30,308 | Train Epoch: 41 [43520/59392 (73%)]	Loss: 0.004601
2020-06-07 23:18:30,783 | Train Epoch: 41 [46080/59392 (78%)]	Loss: 0.003398
2020-06-07 23:18:31,248 | Train Epoch: 41 [48640/59392 (82%)]	Loss: 0.002419
2020-06-07 23:18:31,719 | Train Epoch: 41 [51200/59392 (86%)]	Loss: 0.009117
2020-06-07 23:18:32,188 | Train Epoch: 41 [53760/59392 (91%)]	Loss: 0.004096
2020-06-07 23:18:32,656 | Train Epoch: 41 [56320/59392 (95%)]	Loss: 0.004471
2020-06-07 23:18:33,127 | Train Epoch: 41 [58880/59392 (99%)]	Loss: 0.006194
2020-06-07 23:18:33,280 | ================================================================================
2020-06-07 23:18:33,326 | Setting learning rate to 0.0366982
2020-06-07 23:18:33,703 | Train Epoch: 42 [0/59392 (0%)]	Loss: 0.006150
2020-06-07 23:18:34,201 | Train Epoch: 42 [2560/59392 (4%)]	Loss: 0.002736
2020-06-07 23:18:34,673 | Train Epoch: 42 [5120/59392 (9%)]	Loss: 0.006082
2020-06-07 23:18:35,161 | Train Epoch: 42 [7680/59392 (13%)]	Loss: 0.002842
2020-06-07 23:18:35,715 | Train Epoch: 42 [10240/59392 (17%)]	Loss: 0.010273
2020-06-07 23:18:36,197 | Train Epoch: 42 [12800/59392 (22%)]	Loss: 0.003288
2020-06-07 23:18:36,664 | Train Epoch: 42 [15360/59392 (26%)]	Loss: 0.003284
2020-06-07 23:18:37,148 | Train Epoch: 42 [17920/59392 (30%)]	Loss: 0.004345
2020-06-07 23:18:37,615 | Train Epoch: 42 [20480/59392 (34%)]	Loss: 0.005381
2020-06-07 23:18:38,083 | Train Epoch: 42 [23040/59392 (39%)]	Loss: 0.012701
2020-06-07 23:18:38,544 | Train Epoch: 42 [25600/59392 (43%)]	Loss: 0.004221
2020-06-07 23:18:39,018 | Train Epoch: 42 [28160/59392 (47%)]	Loss: 0.011909
2020-06-07 23:18:39,504 | Train Epoch: 42 [30720/59392 (52%)]	Loss: 0.003606
2020-06-07 23:18:39,993 | Train Epoch: 42 [33280/59392 (56%)]	Loss: 0.005180
2020-06-07 23:18:40,454 | Train Epoch: 42 [35840/59392 (60%)]	Loss: 0.002305
2020-06-07 23:18:40,933 | Train Epoch: 42 [38400/59392 (65%)]	Loss: 0.007210
2020-06-07 23:18:41,419 | Train Epoch: 42 [40960/59392 (69%)]	Loss: 0.008508
2020-06-07 23:18:41,891 | Train Epoch: 42 [43520/59392 (73%)]	Loss: 0.002520
2020-06-07 23:18:42,371 | Train Epoch: 42 [46080/59392 (78%)]	Loss: 0.003108
2020-06-07 23:18:42,832 | Train Epoch: 42 [48640/59392 (82%)]	Loss: 0.005478
2020-06-07 23:18:43,293 | Train Epoch: 42 [51200/59392 (86%)]	Loss: 0.001939
2020-06-07 23:18:43,767 | Train Epoch: 42 [53760/59392 (91%)]	Loss: 0.003185
2020-06-07 23:18:44,260 | Train Epoch: 42 [56320/59392 (95%)]	Loss: 0.002118
2020-06-07 23:18:44,714 | Train Epoch: 42 [58880/59392 (99%)]	Loss: 0.003966
2020-06-07 23:18:44,872 | ================================================================================
2020-06-07 23:18:44,912 | Setting learning rate to 0.0345492
2020-06-07 23:18:45,319 | Train Epoch: 43 [0/59392 (0%)]	Loss: 0.007341
2020-06-07 23:18:45,789 | Train Epoch: 43 [2560/59392 (4%)]	Loss: 0.012116
2020-06-07 23:18:46,250 | Train Epoch: 43 [5120/59392 (9%)]	Loss: 0.005555
2020-06-07 23:18:46,715 | Train Epoch: 43 [7680/59392 (13%)]	Loss: 0.006036
2020-06-07 23:18:47,181 | Train Epoch: 43 [10240/59392 (17%)]	Loss: 0.002293
2020-06-07 23:18:47,640 | Train Epoch: 43 [12800/59392 (22%)]	Loss: 0.003339
2020-06-07 23:18:48,119 | Train Epoch: 43 [15360/59392 (26%)]	Loss: 0.007502
2020-06-07 23:18:48,660 | Train Epoch: 43 [17920/59392 (30%)]	Loss: 0.005177
2020-06-07 23:18:49,149 | Train Epoch: 43 [20480/59392 (34%)]	Loss: 0.002796
2020-06-07 23:18:49,626 | Train Epoch: 43 [23040/59392 (39%)]	Loss: 0.002940
2020-06-07 23:18:50,115 | Train Epoch: 43 [25600/59392 (43%)]	Loss: 0.014880
2020-06-07 23:18:50,604 | Train Epoch: 43 [28160/59392 (47%)]	Loss: 0.007434
2020-06-07 23:18:51,074 | Train Epoch: 43 [30720/59392 (52%)]	Loss: 0.002450
2020-06-07 23:18:51,550 | Train Epoch: 43 [33280/59392 (56%)]	Loss: 0.007758
2020-06-07 23:18:52,012 | Train Epoch: 43 [35840/59392 (60%)]	Loss: 0.003897
2020-06-07 23:18:52,485 | Train Epoch: 43 [38400/59392 (65%)]	Loss: 0.001741
2020-06-07 23:18:52,954 | Train Epoch: 43 [40960/59392 (69%)]	Loss: 0.001657
2020-06-07 23:18:53,428 | Train Epoch: 43 [43520/59392 (73%)]	Loss: 0.001970
2020-06-07 23:18:53,895 | Train Epoch: 43 [46080/59392 (78%)]	Loss: 0.002764
2020-06-07 23:18:54,360 | Train Epoch: 43 [48640/59392 (82%)]	Loss: 0.001422
2020-06-07 23:18:54,849 | Train Epoch: 43 [51200/59392 (86%)]	Loss: 0.001382
2020-06-07 23:18:55,363 | Train Epoch: 43 [53760/59392 (91%)]	Loss: 0.001382
2020-06-07 23:18:55,851 | Train Epoch: 43 [56320/59392 (95%)]	Loss: 0.002027
2020-06-07 23:18:56,311 | Train Epoch: 43 [58880/59392 (99%)]	Loss: 0.011858
2020-06-07 23:18:56,462 | ================================================================================
2020-06-07 23:18:56,499 | Setting learning rate to 0.0324313
2020-06-07 23:18:56,917 | Train Epoch: 44 [0/59392 (0%)]	Loss: 0.001631
2020-06-07 23:18:57,404 | Train Epoch: 44 [2560/59392 (4%)]	Loss: 0.013084
2020-06-07 23:18:57,885 | Train Epoch: 44 [5120/59392 (9%)]	Loss: 0.002794
2020-06-07 23:18:58,346 | Train Epoch: 44 [7680/59392 (13%)]	Loss: 0.001788
2020-06-07 23:18:58,822 | Train Epoch: 44 [10240/59392 (17%)]	Loss: 0.002736
2020-06-07 23:18:59,287 | Train Epoch: 44 [12800/59392 (22%)]	Loss: 0.001899
2020-06-07 23:18:59,755 | Train Epoch: 44 [15360/59392 (26%)]	Loss: 0.002194
2020-06-07 23:19:00,300 | Train Epoch: 44 [17920/59392 (30%)]	Loss: 0.001532
2020-06-07 23:19:00,791 | Train Epoch: 44 [20480/59392 (34%)]	Loss: 0.003009
2020-06-07 23:19:01,253 | Train Epoch: 44 [23040/59392 (39%)]	Loss: 0.001660
2020-06-07 23:19:01,734 | Train Epoch: 44 [25600/59392 (43%)]	Loss: 0.002177
2020-06-07 23:19:02,213 | Train Epoch: 44 [28160/59392 (47%)]	Loss: 0.002408
2020-06-07 23:19:02,696 | Train Epoch: 44 [30720/59392 (52%)]	Loss: 0.002778
2020-06-07 23:19:03,161 | Train Epoch: 44 [33280/59392 (56%)]	Loss: 0.001608
2020-06-07 23:19:03,655 | Train Epoch: 44 [35840/59392 (60%)]	Loss: 0.001768
2020-06-07 23:19:04,132 | Train Epoch: 44 [38400/59392 (65%)]	Loss: 0.001944
2020-06-07 23:19:04,616 | Train Epoch: 44 [40960/59392 (69%)]	Loss: 0.002242
2020-06-07 23:19:05,094 | Train Epoch: 44 [43520/59392 (73%)]	Loss: 0.001915
2020-06-07 23:19:05,577 | Train Epoch: 44 [46080/59392 (78%)]	Loss: 0.001742
2020-06-07 23:19:06,048 | Train Epoch: 44 [48640/59392 (82%)]	Loss: 0.001502
2020-06-07 23:19:06,538 | Train Epoch: 44 [51200/59392 (86%)]	Loss: 0.001679
2020-06-07 23:19:07,021 | Train Epoch: 44 [53760/59392 (91%)]	Loss: 0.001797
2020-06-07 23:19:07,493 | Train Epoch: 44 [56320/59392 (95%)]	Loss: 0.001547
2020-06-07 23:19:07,948 | Train Epoch: 44 [58880/59392 (99%)]	Loss: 0.003357
2020-06-07 23:19:08,129 | ================================================================================
2020-06-07 23:19:19,752 | TRAIN: Clean loss: 0.0020, Clean accuracy: 58983/59001 (99.97%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 26/256 (10.16%)
2020-06-07 23:19:23,579 | TEST: Clean loss: 0.0402, Clean accuracy: 8911/9001 (99.00%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 18/256 (7.03%)
2020-06-07 23:19:23,582 | ================================================================================
2020-06-07 23:19:23,619 | Setting learning rate to 0.0303487
2020-06-07 23:19:24,035 | Train Epoch: 45 [0/59392 (0%)]	Loss: 0.001602
2020-06-07 23:19:24,535 | Train Epoch: 45 [2560/59392 (4%)]	Loss: 0.001576
2020-06-07 23:19:25,015 | Train Epoch: 45 [5120/59392 (9%)]	Loss: 0.002577
2020-06-07 23:19:25,505 | Train Epoch: 45 [7680/59392 (13%)]	Loss: 0.001218
2020-06-07 23:19:25,989 | Train Epoch: 45 [10240/59392 (17%)]	Loss: 0.001259
2020-06-07 23:19:26,516 | Train Epoch: 45 [12800/59392 (22%)]	Loss: 0.001984
2020-06-07 23:19:26,982 | Train Epoch: 45 [15360/59392 (26%)]	Loss: 0.001350
2020-06-07 23:19:27,466 | Train Epoch: 45 [17920/59392 (30%)]	Loss: 0.001982
2020-06-07 23:19:27,936 | Train Epoch: 45 [20480/59392 (34%)]	Loss: 0.004681
2020-06-07 23:19:28,417 | Train Epoch: 45 [23040/59392 (39%)]	Loss: 0.001719
2020-06-07 23:19:28,878 | Train Epoch: 45 [25600/59392 (43%)]	Loss: 0.001499
2020-06-07 23:19:29,354 | Train Epoch: 45 [28160/59392 (47%)]	Loss: 0.001455
2020-06-07 23:19:29,820 | Train Epoch: 45 [30720/59392 (52%)]	Loss: 0.001774
2020-06-07 23:19:30,303 | Train Epoch: 45 [33280/59392 (56%)]	Loss: 0.003594
2020-06-07 23:19:30,763 | Train Epoch: 45 [35840/59392 (60%)]	Loss: 0.001237
2020-06-07 23:19:31,282 | Train Epoch: 45 [38400/59392 (65%)]	Loss: 0.001407
2020-06-07 23:19:31,748 | Train Epoch: 45 [40960/59392 (69%)]	Loss: 0.001419
2020-06-07 23:19:32,220 | Train Epoch: 45 [43520/59392 (73%)]	Loss: 0.015581
2020-06-07 23:19:32,682 | Train Epoch: 45 [46080/59392 (78%)]	Loss: 0.001497
2020-06-07 23:19:33,175 | Train Epoch: 45 [48640/59392 (82%)]	Loss: 0.001642
2020-06-07 23:19:33,641 | Train Epoch: 45 [51200/59392 (86%)]	Loss: 0.002019
2020-06-07 23:19:34,117 | Train Epoch: 45 [53760/59392 (91%)]	Loss: 0.001989
2020-06-07 23:19:34,580 | Train Epoch: 45 [56320/59392 (95%)]	Loss: 0.001556
2020-06-07 23:19:35,049 | Train Epoch: 45 [58880/59392 (99%)]	Loss: 0.015910
2020-06-07 23:19:35,199 | ================================================================================
2020-06-07 23:19:35,250 | Setting learning rate to 0.0283058
2020-06-07 23:19:35,653 | Train Epoch: 46 [0/59392 (0%)]	Loss: 0.013823
2020-06-07 23:19:36,126 | Train Epoch: 46 [2560/59392 (4%)]	Loss: 0.001648
2020-06-07 23:19:36,592 | Train Epoch: 46 [5120/59392 (9%)]	Loss: 0.003013
2020-06-07 23:19:37,067 | Train Epoch: 46 [7680/59392 (13%)]	Loss: 0.001915
2020-06-07 23:19:37,541 | Train Epoch: 46 [10240/59392 (17%)]	Loss: 0.002980
2020-06-07 23:19:38,017 | Train Epoch: 46 [12800/59392 (22%)]	Loss: 0.001662
2020-06-07 23:19:38,484 | Train Epoch: 46 [15360/59392 (26%)]	Loss: 0.013590
2020-06-07 23:19:38,951 | Train Epoch: 46 [17920/59392 (30%)]	Loss: 0.001707
2020-06-07 23:19:39,425 | Train Epoch: 46 [20480/59392 (34%)]	Loss: 0.003252
2020-06-07 23:19:39,921 | Train Epoch: 46 [23040/59392 (39%)]	Loss: 0.001587
2020-06-07 23:19:40,411 | Train Epoch: 46 [25600/59392 (43%)]	Loss: 0.001852
2020-06-07 23:19:40,885 | Train Epoch: 46 [28160/59392 (47%)]	Loss: 0.001883
2020-06-07 23:19:41,346 | Train Epoch: 46 [30720/59392 (52%)]	Loss: 0.007673
2020-06-07 23:19:41,824 | Train Epoch: 46 [33280/59392 (56%)]	Loss: 0.001518
2020-06-07 23:19:42,288 | Train Epoch: 46 [35840/59392 (60%)]	Loss: 0.003774
2020-06-07 23:19:42,765 | Train Epoch: 46 [38400/59392 (65%)]	Loss: 0.003871
2020-06-07 23:19:43,259 | Train Epoch: 46 [40960/59392 (69%)]	Loss: 0.014586
2020-06-07 23:19:43,754 | Train Epoch: 46 [43520/59392 (73%)]	Loss: 0.001668
2020-06-07 23:19:44,314 | Train Epoch: 46 [46080/59392 (78%)]	Loss: 0.005580
2020-06-07 23:19:44,786 | Train Epoch: 46 [48640/59392 (82%)]	Loss: 0.002021
2020-06-07 23:19:45,257 | Train Epoch: 46 [51200/59392 (86%)]	Loss: 0.001531
2020-06-07 23:19:45,741 | Train Epoch: 46 [53760/59392 (91%)]	Loss: 0.004341
2020-06-07 23:19:46,212 | Train Epoch: 46 [56320/59392 (95%)]	Loss: 0.001224
2020-06-07 23:19:46,672 | Train Epoch: 46 [58880/59392 (99%)]	Loss: 0.004646
2020-06-07 23:19:46,823 | ================================================================================
2020-06-07 23:19:46,872 | Setting learning rate to 0.0263066
2020-06-07 23:19:47,252 | Train Epoch: 47 [0/59392 (0%)]	Loss: 0.001924
2020-06-07 23:19:47,746 | Train Epoch: 47 [2560/59392 (4%)]	Loss: 0.001877
2020-06-07 23:19:48,239 | Train Epoch: 47 [5120/59392 (9%)]	Loss: 0.001786
2020-06-07 23:19:48,721 | Train Epoch: 47 [7680/59392 (13%)]	Loss: 0.001702
2020-06-07 23:19:49,202 | Train Epoch: 47 [10240/59392 (17%)]	Loss: 0.001645
2020-06-07 23:19:49,699 | Train Epoch: 47 [12800/59392 (22%)]	Loss: 0.001624
2020-06-07 23:19:50,159 | Train Epoch: 47 [15360/59392 (26%)]	Loss: 0.001613
2020-06-07 23:19:50,644 | Train Epoch: 47 [17920/59392 (30%)]	Loss: 0.002170
2020-06-07 23:19:51,197 | Train Epoch: 47 [20480/59392 (34%)]	Loss: 0.001325
2020-06-07 23:19:51,688 | Train Epoch: 47 [23040/59392 (39%)]	Loss: 0.001491
2020-06-07 23:19:52,199 | Train Epoch: 47 [25600/59392 (43%)]	Loss: 0.001409
2020-06-07 23:19:52,678 | Train Epoch: 47 [28160/59392 (47%)]	Loss: 0.001556
2020-06-07 23:19:53,157 | Train Epoch: 47 [30720/59392 (52%)]	Loss: 0.001500
2020-06-07 23:19:53,646 | Train Epoch: 47 [33280/59392 (56%)]	Loss: 0.001605
2020-06-07 23:19:54,121 | Train Epoch: 47 [35840/59392 (60%)]	Loss: 0.001447
2020-06-07 23:19:54,626 | Train Epoch: 47 [38400/59392 (65%)]	Loss: 0.001802
2020-06-07 23:19:55,097 | Train Epoch: 47 [40960/59392 (69%)]	Loss: 0.001446
2020-06-07 23:19:55,573 | Train Epoch: 47 [43520/59392 (73%)]	Loss: 0.001449
2020-06-07 23:19:56,092 | Train Epoch: 47 [46080/59392 (78%)]	Loss: 0.001403
2020-06-07 23:19:56,560 | Train Epoch: 47 [48640/59392 (82%)]	Loss: 0.001568
2020-06-07 23:19:57,016 | Train Epoch: 47 [51200/59392 (86%)]	Loss: 0.001596
2020-06-07 23:19:57,497 | Train Epoch: 47 [53760/59392 (91%)]	Loss: 0.001767
2020-06-07 23:19:57,960 | Train Epoch: 47 [56320/59392 (95%)]	Loss: 0.002759
2020-06-07 23:19:58,407 | Train Epoch: 47 [58880/59392 (99%)]	Loss: 0.010898
2020-06-07 23:19:58,551 | ================================================================================
2020-06-07 23:19:58,620 | Setting learning rate to 0.024355
2020-06-07 23:19:58,995 | Train Epoch: 48 [0/59392 (0%)]	Loss: 0.001495
2020-06-07 23:19:59,497 | Train Epoch: 48 [2560/59392 (4%)]	Loss: 0.001338
2020-06-07 23:19:59,964 | Train Epoch: 48 [5120/59392 (9%)]	Loss: 0.001622
2020-06-07 23:20:00,444 | Train Epoch: 48 [7680/59392 (13%)]	Loss: 0.001413
2020-06-07 23:20:00,906 | Train Epoch: 48 [10240/59392 (17%)]	Loss: 0.001415
2020-06-07 23:20:01,385 | Train Epoch: 48 [12800/59392 (22%)]	Loss: 0.009175
2020-06-07 23:20:01,845 | Train Epoch: 48 [15360/59392 (26%)]	Loss: 0.001875
2020-06-07 23:20:02,318 | Train Epoch: 48 [17920/59392 (30%)]	Loss: 0.001416
2020-06-07 23:20:02,802 | Train Epoch: 48 [20480/59392 (34%)]	Loss: 0.001772
2020-06-07 23:20:03,283 | Train Epoch: 48 [23040/59392 (39%)]	Loss: 0.001707
2020-06-07 23:20:03,750 | Train Epoch: 48 [25600/59392 (43%)]	Loss: 0.001423
2020-06-07 23:20:04,222 | Train Epoch: 48 [28160/59392 (47%)]	Loss: 0.001597
2020-06-07 23:20:04,687 | Train Epoch: 48 [30720/59392 (52%)]	Loss: 0.001449
2020-06-07 23:20:05,183 | Train Epoch: 48 [33280/59392 (56%)]	Loss: 0.001376
2020-06-07 23:20:05,651 | Train Epoch: 48 [35840/59392 (60%)]	Loss: 0.001533
2020-06-07 23:20:06,117 | Train Epoch: 48 [38400/59392 (65%)]	Loss: 0.001490
2020-06-07 23:20:06,594 | Train Epoch: 48 [40960/59392 (69%)]	Loss: 0.001580
2020-06-07 23:20:07,070 | Train Epoch: 48 [43520/59392 (73%)]	Loss: 0.001474
2020-06-07 23:20:07,533 | Train Epoch: 48 [46080/59392 (78%)]	Loss: 0.001405
2020-06-07 23:20:08,000 | Train Epoch: 48 [48640/59392 (82%)]	Loss: 0.001386
2020-06-07 23:20:08,479 | Train Epoch: 48 [51200/59392 (86%)]	Loss: 0.002711
2020-06-07 23:20:09,024 | Train Epoch: 48 [53760/59392 (91%)]	Loss: 0.001519
2020-06-07 23:20:09,505 | Train Epoch: 48 [56320/59392 (95%)]	Loss: 0.001383
2020-06-07 23:20:09,943 | Train Epoch: 48 [58880/59392 (99%)]	Loss: 0.006142
2020-06-07 23:20:10,131 | ================================================================================
2020-06-07 23:20:21,630 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 48/256 (18.75%)
2020-06-07 23:20:25,519 | TEST: Clean loss: 0.0395, Clean accuracy: 8912/9001 (99.01%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 35/256 (13.67%)
2020-06-07 23:20:25,528 | ================================================================================
2020-06-07 23:20:25,579 | Setting learning rate to 0.0224552
2020-06-07 23:20:25,992 | Train Epoch: 49 [0/59392 (0%)]	Loss: 0.001262
2020-06-07 23:20:26,481 | Train Epoch: 49 [2560/59392 (4%)]	Loss: 0.011186
2020-06-07 23:20:26,953 | Train Epoch: 49 [5120/59392 (9%)]	Loss: 0.001745
2020-06-07 23:20:27,500 | Train Epoch: 49 [7680/59392 (13%)]	Loss: 0.001441
2020-06-07 23:20:27,968 | Train Epoch: 49 [10240/59392 (17%)]	Loss: 0.001691
2020-06-07 23:20:28,448 | Train Epoch: 49 [12800/59392 (22%)]	Loss: 0.001859
2020-06-07 23:20:28,925 | Train Epoch: 49 [15360/59392 (26%)]	Loss: 0.001920
2020-06-07 23:20:29,397 | Train Epoch: 49 [17920/59392 (30%)]	Loss: 0.001645
2020-06-07 23:20:29,864 | Train Epoch: 49 [20480/59392 (34%)]	Loss: 0.001451
2020-06-07 23:20:30,358 | Train Epoch: 49 [23040/59392 (39%)]	Loss: 0.002112
2020-06-07 23:20:30,878 | Train Epoch: 49 [25600/59392 (43%)]	Loss: 0.001771
2020-06-07 23:20:31,372 | Train Epoch: 49 [28160/59392 (47%)]	Loss: 0.001677
2020-06-07 23:20:31,884 | Train Epoch: 49 [30720/59392 (52%)]	Loss: 0.001539
2020-06-07 23:20:32,384 | Train Epoch: 49 [33280/59392 (56%)]	Loss: 0.001736
2020-06-07 23:20:32,890 | Train Epoch: 49 [35840/59392 (60%)]	Loss: 0.001479
2020-06-07 23:20:33,403 | Train Epoch: 49 [38400/59392 (65%)]	Loss: 0.001492
2020-06-07 23:20:33,885 | Train Epoch: 49 [40960/59392 (69%)]	Loss: 0.001494
2020-06-07 23:20:34,392 | Train Epoch: 49 [43520/59392 (73%)]	Loss: 0.001752
2020-06-07 23:20:34,872 | Train Epoch: 49 [46080/59392 (78%)]	Loss: 0.001409
2020-06-07 23:20:35,374 | Train Epoch: 49 [48640/59392 (82%)]	Loss: 0.001715
2020-06-07 23:20:35,862 | Train Epoch: 49 [51200/59392 (86%)]	Loss: 0.001444
2020-06-07 23:20:36,369 | Train Epoch: 49 [53760/59392 (91%)]	Loss: 0.001630
2020-06-07 23:20:36,851 | Train Epoch: 49 [56320/59392 (95%)]	Loss: 0.001452
2020-06-07 23:20:37,331 | Train Epoch: 49 [58880/59392 (99%)]	Loss: 0.001888
2020-06-07 23:20:37,488 | ================================================================================
2020-06-07 23:20:37,535 | Setting learning rate to 0.0206107
2020-06-07 23:20:37,907 | Train Epoch: 50 [0/59392 (0%)]	Loss: 0.002322
2020-06-07 23:20:38,387 | Train Epoch: 50 [2560/59392 (4%)]	Loss: 0.001328
2020-06-07 23:20:38,873 | Train Epoch: 50 [5120/59392 (9%)]	Loss: 0.001582
2020-06-07 23:20:39,340 | Train Epoch: 50 [7680/59392 (13%)]	Loss: 0.001572
2020-06-07 23:20:39,819 | Train Epoch: 50 [10240/59392 (17%)]	Loss: 0.001684
2020-06-07 23:20:40,315 | Train Epoch: 50 [12800/59392 (22%)]	Loss: 0.001359
2020-06-07 23:20:40,851 | Train Epoch: 50 [15360/59392 (26%)]	Loss: 0.001592
2020-06-07 23:20:41,311 | Train Epoch: 50 [17920/59392 (30%)]	Loss: 0.001589
2020-06-07 23:20:41,788 | Train Epoch: 50 [20480/59392 (34%)]	Loss: 0.001530
2020-06-07 23:20:42,254 | Train Epoch: 50 [23040/59392 (39%)]	Loss: 0.001340
2020-06-07 23:20:42,724 | Train Epoch: 50 [25600/59392 (43%)]	Loss: 0.001462
2020-06-07 23:20:43,187 | Train Epoch: 50 [28160/59392 (47%)]	Loss: 0.001484
2020-06-07 23:20:43,652 | Train Epoch: 50 [30720/59392 (52%)]	Loss: 0.001442
2020-06-07 23:20:44,126 | Train Epoch: 50 [33280/59392 (56%)]	Loss: 0.001375
2020-06-07 23:20:44,601 | Train Epoch: 50 [35840/59392 (60%)]	Loss: 0.001507
2020-06-07 23:20:45,066 | Train Epoch: 50 [38400/59392 (65%)]	Loss: 0.001398
2020-06-07 23:20:45,533 | Train Epoch: 50 [40960/59392 (69%)]	Loss: 0.001673
2020-06-07 23:20:46,009 | Train Epoch: 50 [43520/59392 (73%)]	Loss: 0.001603
2020-06-07 23:20:46,476 | Train Epoch: 50 [46080/59392 (78%)]	Loss: 0.001321
2020-06-07 23:20:46,940 | Train Epoch: 50 [48640/59392 (82%)]	Loss: 0.001293
2020-06-07 23:20:47,405 | Train Epoch: 50 [51200/59392 (86%)]	Loss: 0.001381
2020-06-07 23:20:47,939 | Train Epoch: 50 [53760/59392 (91%)]	Loss: 0.001403
2020-06-07 23:20:48,399 | Train Epoch: 50 [56320/59392 (95%)]	Loss: 0.001384
2020-06-07 23:20:48,831 | Train Epoch: 50 [58880/59392 (99%)]	Loss: 0.002672
2020-06-07 23:20:48,978 | ================================================================================
2020-06-07 23:20:49,061 | Setting learning rate to 0.0188255
2020-06-07 23:20:49,452 | Train Epoch: 51 [0/59392 (0%)]	Loss: 0.001336
2020-06-07 23:20:49,920 | Train Epoch: 51 [2560/59392 (4%)]	Loss: 0.001492
2020-06-07 23:20:50,395 | Train Epoch: 51 [5120/59392 (9%)]	Loss: 0.001387
2020-06-07 23:20:50,884 | Train Epoch: 51 [7680/59392 (13%)]	Loss: 0.001667
2020-06-07 23:20:51,358 | Train Epoch: 51 [10240/59392 (17%)]	Loss: 0.001246
2020-06-07 23:20:51,839 | Train Epoch: 51 [12800/59392 (22%)]	Loss: 0.001534
2020-06-07 23:20:52,302 | Train Epoch: 51 [15360/59392 (26%)]	Loss: 0.001388
2020-06-07 23:20:52,835 | Train Epoch: 51 [17920/59392 (30%)]	Loss: 0.001571
2020-06-07 23:20:53,319 | Train Epoch: 51 [20480/59392 (34%)]	Loss: 0.001313
2020-06-07 23:20:53,806 | Train Epoch: 51 [23040/59392 (39%)]	Loss: 0.001309
2020-06-07 23:20:54,264 | Train Epoch: 51 [25600/59392 (43%)]	Loss: 0.001520
2020-06-07 23:20:54,740 | Train Epoch: 51 [28160/59392 (47%)]	Loss: 0.001445
2020-06-07 23:20:55,204 | Train Epoch: 51 [30720/59392 (52%)]	Loss: 0.001404
2020-06-07 23:20:55,687 | Train Epoch: 51 [33280/59392 (56%)]	Loss: 0.001510
2020-06-07 23:20:56,165 | Train Epoch: 51 [35840/59392 (60%)]	Loss: 0.001282
2020-06-07 23:20:56,637 | Train Epoch: 51 [38400/59392 (65%)]	Loss: 0.001487
2020-06-07 23:20:57,099 | Train Epoch: 51 [40960/59392 (69%)]	Loss: 0.001726
2020-06-07 23:20:57,574 | Train Epoch: 51 [43520/59392 (73%)]	Loss: 0.001608
2020-06-07 23:20:58,032 | Train Epoch: 51 [46080/59392 (78%)]	Loss: 0.001491
2020-06-07 23:20:58,503 | Train Epoch: 51 [48640/59392 (82%)]	Loss: 0.001582
2020-06-07 23:20:58,967 | Train Epoch: 51 [51200/59392 (86%)]	Loss: 0.001681
2020-06-07 23:20:59,432 | Train Epoch: 51 [53760/59392 (91%)]	Loss: 0.001321
2020-06-07 23:20:59,902 | Train Epoch: 51 [56320/59392 (95%)]	Loss: 0.001232
2020-06-07 23:21:00,360 | Train Epoch: 51 [58880/59392 (99%)]	Loss: 0.004962
2020-06-07 23:21:00,521 | ================================================================================
2020-06-07 23:21:00,571 | Setting learning rate to 0.0171031
2020-06-07 23:21:00,961 | Train Epoch: 52 [0/59392 (0%)]	Loss: 0.001702
2020-06-07 23:21:01,436 | Train Epoch: 52 [2560/59392 (4%)]	Loss: 0.001446
2020-06-07 23:21:01,907 | Train Epoch: 52 [5120/59392 (9%)]	Loss: 0.001681
2020-06-07 23:21:02,366 | Train Epoch: 52 [7680/59392 (13%)]	Loss: 0.001421
2020-06-07 23:21:02,843 | Train Epoch: 52 [10240/59392 (17%)]	Loss: 0.001408
2020-06-07 23:21:03,312 | Train Epoch: 52 [12800/59392 (22%)]	Loss: 0.001449
2020-06-07 23:21:03,783 | Train Epoch: 52 [15360/59392 (26%)]	Loss: 0.001668
2020-06-07 23:21:04,254 | Train Epoch: 52 [17920/59392 (30%)]	Loss: 0.001384
2020-06-07 23:21:04,727 | Train Epoch: 52 [20480/59392 (34%)]	Loss: 0.001387
2020-06-07 23:21:05,189 | Train Epoch: 52 [23040/59392 (39%)]	Loss: 0.001632
2020-06-07 23:21:05,739 | Train Epoch: 52 [25600/59392 (43%)]	Loss: 0.001808
2020-06-07 23:21:06,212 | Train Epoch: 52 [28160/59392 (47%)]	Loss: 0.001816
2020-06-07 23:21:06,688 | Train Epoch: 52 [30720/59392 (52%)]	Loss: 0.001602
2020-06-07 23:21:07,146 | Train Epoch: 52 [33280/59392 (56%)]	Loss: 0.001526
2020-06-07 23:21:07,621 | Train Epoch: 52 [35840/59392 (60%)]	Loss: 0.001465
2020-06-07 23:21:08,080 | Train Epoch: 52 [38400/59392 (65%)]	Loss: 0.001406
2020-06-07 23:21:08,560 | Train Epoch: 52 [40960/59392 (69%)]	Loss: 0.001445
2020-06-07 23:21:09,016 | Train Epoch: 52 [43520/59392 (73%)]	Loss: 0.001556
2020-06-07 23:21:09,494 | Train Epoch: 52 [46080/59392 (78%)]	Loss: 0.001635
2020-06-07 23:21:09,955 | Train Epoch: 52 [48640/59392 (82%)]	Loss: 0.001613
2020-06-07 23:21:10,429 | Train Epoch: 52 [51200/59392 (86%)]	Loss: 0.001766
2020-06-07 23:21:10,891 | Train Epoch: 52 [53760/59392 (91%)]	Loss: 0.001835
2020-06-07 23:21:11,369 | Train Epoch: 52 [56320/59392 (95%)]	Loss: 0.001535
2020-06-07 23:21:11,805 | Train Epoch: 52 [58880/59392 (99%)]	Loss: 0.001664
2020-06-07 23:21:11,965 | ================================================================================
2020-06-07 23:21:23,527 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 50/256 (19.53%)
2020-06-07 23:21:27,283 | TEST: Clean loss: 0.0363, Clean accuracy: 8926/9001 (99.17%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 36/256 (14.06%)
2020-06-07 23:21:27,289 | ================================================================================
2020-06-07 23:21:27,369 | Setting learning rate to 0.0154469
2020-06-07 23:21:27,772 | Train Epoch: 53 [0/59392 (0%)]	Loss: 0.001349
2020-06-07 23:21:28,276 | Train Epoch: 53 [2560/59392 (4%)]	Loss: 0.001485
2020-06-07 23:21:28,749 | Train Epoch: 53 [5120/59392 (9%)]	Loss: 0.001495
2020-06-07 23:21:29,223 | Train Epoch: 53 [7680/59392 (13%)]	Loss: 0.001470
2020-06-07 23:21:29,689 | Train Epoch: 53 [10240/59392 (17%)]	Loss: 0.001580
2020-06-07 23:21:30,174 | Train Epoch: 53 [12800/59392 (22%)]	Loss: 0.001496
2020-06-07 23:21:30,638 | Train Epoch: 53 [15360/59392 (26%)]	Loss: 0.001319
2020-06-07 23:21:31,098 | Train Epoch: 53 [17920/59392 (30%)]	Loss: 0.001769
2020-06-07 23:21:31,566 | Train Epoch: 53 [20480/59392 (34%)]	Loss: 0.001548
2020-06-07 23:21:32,040 | Train Epoch: 53 [23040/59392 (39%)]	Loss: 0.001471
2020-06-07 23:21:32,511 | Train Epoch: 53 [25600/59392 (43%)]	Loss: 0.001613
2020-06-07 23:21:33,014 | Train Epoch: 53 [28160/59392 (47%)]	Loss: 0.001494
2020-06-07 23:21:33,510 | Train Epoch: 53 [30720/59392 (52%)]	Loss: 0.001564
2020-06-07 23:21:34,016 | Train Epoch: 53 [33280/59392 (56%)]	Loss: 0.001339
2020-06-07 23:21:34,503 | Train Epoch: 53 [35840/59392 (60%)]	Loss: 0.001567
2020-06-07 23:21:34,984 | Train Epoch: 53 [38400/59392 (65%)]	Loss: 0.001546
2020-06-07 23:21:35,455 | Train Epoch: 53 [40960/59392 (69%)]	Loss: 0.001471
2020-06-07 23:21:35,920 | Train Epoch: 53 [43520/59392 (73%)]	Loss: 0.001636
2020-06-07 23:21:36,448 | Train Epoch: 53 [46080/59392 (78%)]	Loss: 0.001365
2020-06-07 23:21:36,913 | Train Epoch: 53 [48640/59392 (82%)]	Loss: 0.001510
2020-06-07 23:21:37,379 | Train Epoch: 53 [51200/59392 (86%)]	Loss: 0.001509
2020-06-07 23:21:37,863 | Train Epoch: 53 [53760/59392 (91%)]	Loss: 0.001602
2020-06-07 23:21:38,326 | Train Epoch: 53 [56320/59392 (95%)]	Loss: 0.001444
2020-06-07 23:21:38,785 | Train Epoch: 53 [58880/59392 (99%)]	Loss: 0.005542
2020-06-07 23:21:38,964 | ================================================================================
2020-06-07 23:21:39,016 | Setting learning rate to 0.0138603
2020-06-07 23:21:39,434 | Train Epoch: 54 [0/59392 (0%)]	Loss: 0.001414
2020-06-07 23:21:39,903 | Train Epoch: 54 [2560/59392 (4%)]	Loss: 0.001468
2020-06-07 23:21:40,369 | Train Epoch: 54 [5120/59392 (9%)]	Loss: 0.001416
2020-06-07 23:21:40,844 | Train Epoch: 54 [7680/59392 (13%)]	Loss: 0.001332
2020-06-07 23:21:41,301 | Train Epoch: 54 [10240/59392 (17%)]	Loss: 0.001387
2020-06-07 23:21:41,779 | Train Epoch: 54 [12800/59392 (22%)]	Loss: 0.001449
2020-06-07 23:21:42,251 | Train Epoch: 54 [15360/59392 (26%)]	Loss: 0.001392
2020-06-07 23:21:42,713 | Train Epoch: 54 [17920/59392 (30%)]	Loss: 0.001583
2020-06-07 23:21:43,248 | Train Epoch: 54 [20480/59392 (34%)]	Loss: 0.001887
2020-06-07 23:21:43,716 | Train Epoch: 54 [23040/59392 (39%)]	Loss: 0.001313
2020-06-07 23:21:44,183 | Train Epoch: 54 [25600/59392 (43%)]	Loss: 0.001823
2020-06-07 23:21:44,663 | Train Epoch: 54 [28160/59392 (47%)]	Loss: 0.002133
2020-06-07 23:21:45,136 | Train Epoch: 54 [30720/59392 (52%)]	Loss: 0.001548
2020-06-07 23:21:45,614 | Train Epoch: 54 [33280/59392 (56%)]	Loss: 0.001485
2020-06-07 23:21:46,083 | Train Epoch: 54 [35840/59392 (60%)]	Loss: 0.001327
2020-06-07 23:21:46,551 | Train Epoch: 54 [38400/59392 (65%)]	Loss: 0.001342
2020-06-07 23:21:47,025 | Train Epoch: 54 [40960/59392 (69%)]	Loss: 0.001439
2020-06-07 23:21:47,494 | Train Epoch: 54 [43520/59392 (73%)]	Loss: 0.001243
2020-06-07 23:21:48,009 | Train Epoch: 54 [46080/59392 (78%)]	Loss: 0.001370
2020-06-07 23:21:48,466 | Train Epoch: 54 [48640/59392 (82%)]	Loss: 0.001517
2020-06-07 23:21:48,951 | Train Epoch: 54 [51200/59392 (86%)]	Loss: 0.001413
2020-06-07 23:21:49,424 | Train Epoch: 54 [53760/59392 (91%)]	Loss: 0.001483
2020-06-07 23:21:49,889 | Train Epoch: 54 [56320/59392 (95%)]	Loss: 0.001430
2020-06-07 23:21:50,336 | Train Epoch: 54 [58880/59392 (99%)]	Loss: 0.003905
2020-06-07 23:21:50,503 | ================================================================================
2020-06-07 23:21:50,551 | Setting learning rate to 0.0123464
2020-06-07 23:21:50,954 | Train Epoch: 55 [0/59392 (0%)]	Loss: 0.001443
2020-06-07 23:21:51,443 | Train Epoch: 55 [2560/59392 (4%)]	Loss: 0.001553
2020-06-07 23:21:51,920 | Train Epoch: 55 [5120/59392 (9%)]	Loss: 0.001427
2020-06-07 23:21:52,392 | Train Epoch: 55 [7680/59392 (13%)]	Loss: 0.001432
2020-06-07 23:21:52,864 | Train Epoch: 55 [10240/59392 (17%)]	Loss: 0.001402
2020-06-07 23:21:53,325 | Train Epoch: 55 [12800/59392 (22%)]	Loss: 0.001572
2020-06-07 23:21:53,804 | Train Epoch: 55 [15360/59392 (26%)]	Loss: 0.001502
2020-06-07 23:21:54,270 | Train Epoch: 55 [17920/59392 (30%)]	Loss: 0.001578
2020-06-07 23:21:54,747 | Train Epoch: 55 [20480/59392 (34%)]	Loss: 0.001485
2020-06-07 23:21:55,208 | Train Epoch: 55 [23040/59392 (39%)]	Loss: 0.001558
2020-06-07 23:21:55,667 | Train Epoch: 55 [25600/59392 (43%)]	Loss: 0.001720
2020-06-07 23:21:56,133 | Train Epoch: 55 [28160/59392 (47%)]	Loss: 0.001557
2020-06-07 23:21:56,614 | Train Epoch: 55 [30720/59392 (52%)]	Loss: 0.001635
2020-06-07 23:21:57,085 | Train Epoch: 55 [33280/59392 (56%)]	Loss: 0.001426
2020-06-07 23:21:57,550 | Train Epoch: 55 [35840/59392 (60%)]	Loss: 0.001481
2020-06-07 23:21:58,016 | Train Epoch: 55 [38400/59392 (65%)]	Loss: 0.001371
2020-06-07 23:21:58,480 | Train Epoch: 55 [40960/59392 (69%)]	Loss: 0.001494
2020-06-07 23:21:58,935 | Train Epoch: 55 [43520/59392 (73%)]	Loss: 0.001748
2020-06-07 23:21:59,398 | Train Epoch: 55 [46080/59392 (78%)]	Loss: 0.001443
2020-06-07 23:21:59,858 | Train Epoch: 55 [48640/59392 (82%)]	Loss: 0.001450
2020-06-07 23:22:00,332 | Train Epoch: 55 [51200/59392 (86%)]	Loss: 0.001486
2020-06-07 23:22:00,883 | Train Epoch: 55 [53760/59392 (91%)]	Loss: 0.001530
2020-06-07 23:22:01,364 | Train Epoch: 55 [56320/59392 (95%)]	Loss: 0.001588
2020-06-07 23:22:01,822 | Train Epoch: 55 [58880/59392 (99%)]	Loss: 0.003098
2020-06-07 23:22:01,972 | ================================================================================
2020-06-07 23:22:02,024 | Setting learning rate to 0.0109084
2020-06-07 23:22:02,407 | Train Epoch: 56 [0/59392 (0%)]	Loss: 0.001591
2020-06-07 23:22:02,876 | Train Epoch: 56 [2560/59392 (4%)]	Loss: 0.001512
2020-06-07 23:22:03,345 | Train Epoch: 56 [5120/59392 (9%)]	Loss: 0.001716
2020-06-07 23:22:03,819 | Train Epoch: 56 [7680/59392 (13%)]	Loss: 0.001721
2020-06-07 23:22:04,290 | Train Epoch: 56 [10240/59392 (17%)]	Loss: 0.001416
2020-06-07 23:22:04,751 | Train Epoch: 56 [12800/59392 (22%)]	Loss: 0.001565
2020-06-07 23:22:05,218 | Train Epoch: 56 [15360/59392 (26%)]	Loss: 0.001322
2020-06-07 23:22:05,684 | Train Epoch: 56 [17920/59392 (30%)]	Loss: 0.001374
2020-06-07 23:22:06,146 | Train Epoch: 56 [20480/59392 (34%)]	Loss: 0.001550
2020-06-07 23:22:06,615 | Train Epoch: 56 [23040/59392 (39%)]	Loss: 0.001312
2020-06-07 23:22:07,075 | Train Epoch: 56 [25600/59392 (43%)]	Loss: 0.001545
2020-06-07 23:22:07,615 | Train Epoch: 56 [28160/59392 (47%)]	Loss: 0.001523
2020-06-07 23:22:08,070 | Train Epoch: 56 [30720/59392 (52%)]	Loss: 0.001420
2020-06-07 23:22:08,561 | Train Epoch: 56 [33280/59392 (56%)]	Loss: 0.001433
2020-06-07 23:22:09,022 | Train Epoch: 56 [35840/59392 (60%)]	Loss: 0.001482
2020-06-07 23:22:09,497 | Train Epoch: 56 [38400/59392 (65%)]	Loss: 0.001707
2020-06-07 23:22:09,959 | Train Epoch: 56 [40960/59392 (69%)]	Loss: 0.001626
2020-06-07 23:22:10,425 | Train Epoch: 56 [43520/59392 (73%)]	Loss: 0.001602
2020-06-07 23:22:10,894 | Train Epoch: 56 [46080/59392 (78%)]	Loss: 0.001407
2020-06-07 23:22:11,371 | Train Epoch: 56 [48640/59392 (82%)]	Loss: 0.001501
2020-06-07 23:22:11,835 | Train Epoch: 56 [51200/59392 (86%)]	Loss: 0.001405
2020-06-07 23:22:12,346 | Train Epoch: 56 [53760/59392 (91%)]	Loss: 0.001589
2020-06-07 23:22:12,813 | Train Epoch: 56 [56320/59392 (95%)]	Loss: 0.001445
2020-06-07 23:22:13,251 | Train Epoch: 56 [58880/59392 (99%)]	Loss: 0.002802
2020-06-07 23:22:13,430 | ================================================================================
2020-06-07 23:22:24,916 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 44/256 (17.19%)
2020-06-07 23:22:28,776 | TEST: Clean loss: 0.0364, Clean accuracy: 8924/9001 (99.14%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 37/256 (14.45%)
2020-06-07 23:22:28,787 | ================================================================================
2020-06-07 23:22:28,843 | Setting learning rate to 0.00954915
2020-06-07 23:22:29,257 | Train Epoch: 57 [0/59392 (0%)]	Loss: 0.001870
2020-06-07 23:22:29,738 | Train Epoch: 57 [2560/59392 (4%)]	Loss: 0.001473
2020-06-07 23:22:30,217 | Train Epoch: 57 [5120/59392 (9%)]	Loss: 0.001749
2020-06-07 23:22:30,683 | Train Epoch: 57 [7680/59392 (13%)]	Loss: 0.001610
2020-06-07 23:22:31,153 | Train Epoch: 57 [10240/59392 (17%)]	Loss: 0.001569
2020-06-07 23:22:31,672 | Train Epoch: 57 [12800/59392 (22%)]	Loss: 0.001656
2020-06-07 23:22:32,148 | Train Epoch: 57 [15360/59392 (26%)]	Loss: 0.001476
2020-06-07 23:22:32,620 | Train Epoch: 57 [17920/59392 (30%)]	Loss: 0.001676
2020-06-07 23:22:33,091 | Train Epoch: 57 [20480/59392 (34%)]	Loss: 0.001460
2020-06-07 23:22:33,560 | Train Epoch: 57 [23040/59392 (39%)]	Loss: 0.001329
2020-06-07 23:22:34,034 | Train Epoch: 57 [25600/59392 (43%)]	Loss: 0.001511
2020-06-07 23:22:34,495 | Train Epoch: 57 [28160/59392 (47%)]	Loss: 0.001609
2020-06-07 23:22:34,979 | Train Epoch: 57 [30720/59392 (52%)]	Loss: 0.001494
2020-06-07 23:22:35,445 | Train Epoch: 57 [33280/59392 (56%)]	Loss: 0.001500
2020-06-07 23:22:35,920 | Train Epoch: 57 [35840/59392 (60%)]	Loss: 0.001439
2020-06-07 23:22:36,383 | Train Epoch: 57 [38400/59392 (65%)]	Loss: 0.001471
2020-06-07 23:22:36,848 | Train Epoch: 57 [40960/59392 (69%)]	Loss: 0.001400
2020-06-07 23:22:37,330 | Train Epoch: 57 [43520/59392 (73%)]	Loss: 0.001575
2020-06-07 23:22:37,792 | Train Epoch: 57 [46080/59392 (78%)]	Loss: 0.001406
2020-06-07 23:22:38,266 | Train Epoch: 57 [48640/59392 (82%)]	Loss: 0.001601
2020-06-07 23:22:38,767 | Train Epoch: 57 [51200/59392 (86%)]	Loss: 0.001260
2020-06-07 23:22:39,240 | Train Epoch: 57 [53760/59392 (91%)]	Loss: 0.001258
2020-06-07 23:22:39,705 | Train Epoch: 57 [56320/59392 (95%)]	Loss: 0.001448
2020-06-07 23:22:40,149 | Train Epoch: 57 [58880/59392 (99%)]	Loss: 0.002152
2020-06-07 23:22:40,322 | ================================================================================
2020-06-07 23:22:40,379 | Setting learning rate to 0.00827134
2020-06-07 23:22:40,777 | Train Epoch: 58 [0/59392 (0%)]	Loss: 0.001624
2020-06-07 23:22:41,252 | Train Epoch: 58 [2560/59392 (4%)]	Loss: 0.001538
2020-06-07 23:22:41,740 | Train Epoch: 58 [5120/59392 (9%)]	Loss: 0.001333
2020-06-07 23:22:42,211 | Train Epoch: 58 [7680/59392 (13%)]	Loss: 0.001573
2020-06-07 23:22:42,688 | Train Epoch: 58 [10240/59392 (17%)]	Loss: 0.001741
2020-06-07 23:22:43,170 | Train Epoch: 58 [12800/59392 (22%)]	Loss: 0.001459
2020-06-07 23:22:43,715 | Train Epoch: 58 [15360/59392 (26%)]	Loss: 0.001442
2020-06-07 23:22:44,186 | Train Epoch: 58 [17920/59392 (30%)]	Loss: 0.001591
2020-06-07 23:22:44,655 | Train Epoch: 58 [20480/59392 (34%)]	Loss: 0.001440
2020-06-07 23:22:45,118 | Train Epoch: 58 [23040/59392 (39%)]	Loss: 0.001370
2020-06-07 23:22:45,593 | Train Epoch: 58 [25600/59392 (43%)]	Loss: 0.001703
2020-06-07 23:22:46,094 | Train Epoch: 58 [28160/59392 (47%)]	Loss: 0.001474
2020-06-07 23:22:46,574 | Train Epoch: 58 [30720/59392 (52%)]	Loss: 0.001507
2020-06-07 23:22:47,059 | Train Epoch: 58 [33280/59392 (56%)]	Loss: 0.001380
2020-06-07 23:22:47,539 | Train Epoch: 58 [35840/59392 (60%)]	Loss: 0.001732
2020-06-07 23:22:48,005 | Train Epoch: 58 [38400/59392 (65%)]	Loss: 0.001336
2020-06-07 23:22:48,465 | Train Epoch: 58 [40960/59392 (69%)]	Loss: 0.001421
2020-06-07 23:22:48,936 | Train Epoch: 58 [43520/59392 (73%)]	Loss: 0.001307
2020-06-07 23:22:49,404 | Train Epoch: 58 [46080/59392 (78%)]	Loss: 0.001468
2020-06-07 23:22:49,885 | Train Epoch: 58 [48640/59392 (82%)]	Loss: 0.001446
2020-06-07 23:22:50,358 | Train Epoch: 58 [51200/59392 (86%)]	Loss: 0.001558
2020-06-07 23:22:50,830 | Train Epoch: 58 [53760/59392 (91%)]	Loss: 0.001436
2020-06-07 23:22:51,298 | Train Epoch: 58 [56320/59392 (95%)]	Loss: 0.001598
2020-06-07 23:22:51,760 | Train Epoch: 58 [58880/59392 (99%)]	Loss: 0.003144
2020-06-07 23:22:51,917 | ================================================================================
2020-06-07 23:22:51,967 | Setting learning rate to 0.00707756
2020-06-07 23:22:52,352 | Train Epoch: 59 [0/59392 (0%)]	Loss: 0.001565
2020-06-07 23:22:52,828 | Train Epoch: 59 [2560/59392 (4%)]	Loss: 0.001504
2020-06-07 23:22:53,289 | Train Epoch: 59 [5120/59392 (9%)]	Loss: 0.001669
2020-06-07 23:22:53,765 | Train Epoch: 59 [7680/59392 (13%)]	Loss: 0.001653
2020-06-07 23:22:54,253 | Train Epoch: 59 [10240/59392 (17%)]	Loss: 0.001363
2020-06-07 23:22:54,744 | Train Epoch: 59 [12800/59392 (22%)]	Loss: 0.001530
2020-06-07 23:22:55,206 | Train Epoch: 59 [15360/59392 (26%)]	Loss: 0.001710
2020-06-07 23:22:55,690 | Train Epoch: 59 [17920/59392 (30%)]	Loss: 0.001299
2020-06-07 23:22:56,160 | Train Epoch: 59 [20480/59392 (34%)]	Loss: 0.001484
2020-06-07 23:22:56,754 | Train Epoch: 59 [23040/59392 (39%)]	Loss: 0.001514
2020-06-07 23:22:57,218 | Train Epoch: 59 [25600/59392 (43%)]	Loss: 0.001405
2020-06-07 23:22:57,697 | Train Epoch: 59 [28160/59392 (47%)]	Loss: 0.001412
2020-06-07 23:22:58,190 | Train Epoch: 59 [30720/59392 (52%)]	Loss: 0.001559
2020-06-07 23:22:58,699 | Train Epoch: 59 [33280/59392 (56%)]	Loss: 0.001736
2020-06-07 23:22:59,172 | Train Epoch: 59 [35840/59392 (60%)]	Loss: 0.001538
2020-06-07 23:22:59,645 | Train Epoch: 59 [38400/59392 (65%)]	Loss: 0.001391
2020-06-07 23:23:00,115 | Train Epoch: 59 [40960/59392 (69%)]	Loss: 0.001418
2020-06-07 23:23:00,589 | Train Epoch: 59 [43520/59392 (73%)]	Loss: 0.001677
2020-06-07 23:23:01,057 | Train Epoch: 59 [46080/59392 (78%)]	Loss: 0.001399
2020-06-07 23:23:01,528 | Train Epoch: 59 [48640/59392 (82%)]	Loss: 0.001526
2020-06-07 23:23:01,991 | Train Epoch: 59 [51200/59392 (86%)]	Loss: 0.001576
2020-06-07 23:23:02,472 | Train Epoch: 59 [53760/59392 (91%)]	Loss: 0.001333
2020-06-07 23:23:02,936 | Train Epoch: 59 [56320/59392 (95%)]	Loss: 0.001426
2020-06-07 23:23:03,437 | Train Epoch: 59 [58880/59392 (99%)]	Loss: 0.003775
2020-06-07 23:23:03,607 | ================================================================================
2020-06-07 23:23:03,696 | Setting learning rate to 0.00597022
2020-06-07 23:23:04,087 | Train Epoch: 60 [0/59392 (0%)]	Loss: 0.001702
2020-06-07 23:23:04,578 | Train Epoch: 60 [2560/59392 (4%)]	Loss: 0.001342
2020-06-07 23:23:05,051 | Train Epoch: 60 [5120/59392 (9%)]	Loss: 0.002106
2020-06-07 23:23:05,521 | Train Epoch: 60 [7680/59392 (13%)]	Loss: 0.001521
2020-06-07 23:23:05,984 | Train Epoch: 60 [10240/59392 (17%)]	Loss: 0.001851
2020-06-07 23:23:06,479 | Train Epoch: 60 [12800/59392 (22%)]	Loss: 0.001509
2020-06-07 23:23:06,973 | Train Epoch: 60 [15360/59392 (26%)]	Loss: 0.001422
2020-06-07 23:23:07,467 | Train Epoch: 60 [17920/59392 (30%)]	Loss: 0.001511
2020-06-07 23:23:07,937 | Train Epoch: 60 [20480/59392 (34%)]	Loss: 0.001476
2020-06-07 23:23:08,405 | Train Epoch: 60 [23040/59392 (39%)]	Loss: 0.001891
2020-06-07 23:23:08,951 | Train Epoch: 60 [25600/59392 (43%)]	Loss: 0.001521
2020-06-07 23:23:09,441 | Train Epoch: 60 [28160/59392 (47%)]	Loss: 0.001471
2020-06-07 23:23:09,912 | Train Epoch: 60 [30720/59392 (52%)]	Loss: 0.001351
2020-06-07 23:23:10,379 | Train Epoch: 60 [33280/59392 (56%)]	Loss: 0.001384
2020-06-07 23:23:10,843 | Train Epoch: 60 [35840/59392 (60%)]	Loss: 0.001450
2020-06-07 23:23:11,305 | Train Epoch: 60 [38400/59392 (65%)]	Loss: 0.001638
2020-06-07 23:23:11,767 | Train Epoch: 60 [40960/59392 (69%)]	Loss: 0.001477
2020-06-07 23:23:12,248 | Train Epoch: 60 [43520/59392 (73%)]	Loss: 0.001337
2020-06-07 23:23:12,714 | Train Epoch: 60 [46080/59392 (78%)]	Loss: 0.001316
2020-06-07 23:23:13,179 | Train Epoch: 60 [48640/59392 (82%)]	Loss: 0.001644
2020-06-07 23:23:13,645 | Train Epoch: 60 [51200/59392 (86%)]	Loss: 0.001443
2020-06-07 23:23:14,126 | Train Epoch: 60 [53760/59392 (91%)]	Loss: 0.001536
2020-06-07 23:23:14,593 | Train Epoch: 60 [56320/59392 (95%)]	Loss: 0.001437
2020-06-07 23:23:15,039 | Train Epoch: 60 [58880/59392 (99%)]	Loss: 0.001916
2020-06-07 23:23:15,187 | ================================================================================
2020-06-07 23:23:26,846 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 48/256 (18.75%)
2020-06-07 23:23:30,674 | TEST: Clean loss: 0.0359, Clean accuracy: 8927/9001 (99.18%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 37/256 (14.45%)
2020-06-07 23:23:30,683 | ================================================================================
2020-06-07 23:23:30,741 | Setting learning rate to 0.00495156
2020-06-07 23:23:31,197 | Train Epoch: 61 [0/59392 (0%)]	Loss: 0.001475
2020-06-07 23:23:31,664 | Train Epoch: 61 [2560/59392 (4%)]	Loss: 0.001787
2020-06-07 23:23:32,152 | Train Epoch: 61 [5120/59392 (9%)]	Loss: 0.001416
2020-06-07 23:23:32,619 | Train Epoch: 61 [7680/59392 (13%)]	Loss: 0.001437
2020-06-07 23:23:33,090 | Train Epoch: 61 [10240/59392 (17%)]	Loss: 0.001535
2020-06-07 23:23:33,558 | Train Epoch: 61 [12800/59392 (22%)]	Loss: 0.001819
2020-06-07 23:23:34,031 | Train Epoch: 61 [15360/59392 (26%)]	Loss: 0.001747
2020-06-07 23:23:34,587 | Train Epoch: 61 [17920/59392 (30%)]	Loss: 0.001714
2020-06-07 23:23:35,074 | Train Epoch: 61 [20480/59392 (34%)]	Loss: 0.001745
2020-06-07 23:23:35,553 | Train Epoch: 61 [23040/59392 (39%)]	Loss: 0.001511
2020-06-07 23:23:36,044 | Train Epoch: 61 [25600/59392 (43%)]	Loss: 0.001320
2020-06-07 23:23:36,535 | Train Epoch: 61 [28160/59392 (47%)]	Loss: 0.001545
2020-06-07 23:23:37,040 | Train Epoch: 61 [30720/59392 (52%)]	Loss: 0.001427
2020-06-07 23:23:37,527 | Train Epoch: 61 [33280/59392 (56%)]	Loss: 0.001734
2020-06-07 23:23:38,017 | Train Epoch: 61 [35840/59392 (60%)]	Loss: 0.002027
2020-06-07 23:23:38,495 | Train Epoch: 61 [38400/59392 (65%)]	Loss: 0.001555
2020-06-07 23:23:38,974 | Train Epoch: 61 [40960/59392 (69%)]	Loss: 0.001548
2020-06-07 23:23:39,504 | Train Epoch: 61 [43520/59392 (73%)]	Loss: 0.001434
2020-06-07 23:23:39,980 | Train Epoch: 61 [46080/59392 (78%)]	Loss: 0.001445
2020-06-07 23:23:40,439 | Train Epoch: 61 [48640/59392 (82%)]	Loss: 0.001494
2020-06-07 23:23:40,928 | Train Epoch: 61 [51200/59392 (86%)]	Loss: 0.001431
2020-06-07 23:23:41,412 | Train Epoch: 61 [53760/59392 (91%)]	Loss: 0.001588
2020-06-07 23:23:41,917 | Train Epoch: 61 [56320/59392 (95%)]	Loss: 0.001461
2020-06-07 23:23:42,391 | Train Epoch: 61 [58880/59392 (99%)]	Loss: 0.002361
2020-06-07 23:23:42,546 | ================================================================================
2020-06-07 23:23:42,607 | Setting learning rate to 0.00402361
2020-06-07 23:23:43,014 | Train Epoch: 62 [0/59392 (0%)]	Loss: 0.001422
2020-06-07 23:23:43,494 | Train Epoch: 62 [2560/59392 (4%)]	Loss: 0.001716
2020-06-07 23:23:43,964 | Train Epoch: 62 [5120/59392 (9%)]	Loss: 0.001437
2020-06-07 23:23:44,435 | Train Epoch: 62 [7680/59392 (13%)]	Loss: 0.001468
2020-06-07 23:23:44,904 | Train Epoch: 62 [10240/59392 (17%)]	Loss: 0.001320
2020-06-07 23:23:45,372 | Train Epoch: 62 [12800/59392 (22%)]	Loss: 0.001563
2020-06-07 23:23:45,844 | Train Epoch: 62 [15360/59392 (26%)]	Loss: 0.001475
2020-06-07 23:23:46,318 | Train Epoch: 62 [17920/59392 (30%)]	Loss: 0.001460
2020-06-07 23:23:46,785 | Train Epoch: 62 [20480/59392 (34%)]	Loss: 0.001524
2020-06-07 23:23:47,256 | Train Epoch: 62 [23040/59392 (39%)]	Loss: 0.001338
2020-06-07 23:23:47,729 | Train Epoch: 62 [25600/59392 (43%)]	Loss: 0.001458
2020-06-07 23:23:48,198 | Train Epoch: 62 [28160/59392 (47%)]	Loss: 0.001408
2020-06-07 23:23:48,660 | Train Epoch: 62 [30720/59392 (52%)]	Loss: 0.001575
2020-06-07 23:23:49,123 | Train Epoch: 62 [33280/59392 (56%)]	Loss: 0.001420
2020-06-07 23:23:49,641 | Train Epoch: 62 [35840/59392 (60%)]	Loss: 0.001681
2020-06-07 23:23:50,125 | Train Epoch: 62 [38400/59392 (65%)]	Loss: 0.001486
2020-06-07 23:23:50,629 | Train Epoch: 62 [40960/59392 (69%)]	Loss: 0.001546
2020-06-07 23:23:51,125 | Train Epoch: 62 [43520/59392 (73%)]	Loss: 0.001441
2020-06-07 23:23:51,600 | Train Epoch: 62 [46080/59392 (78%)]	Loss: 0.001398
2020-06-07 23:23:52,093 | Train Epoch: 62 [48640/59392 (82%)]	Loss: 0.001417
2020-06-07 23:23:52,709 | Train Epoch: 62 [51200/59392 (86%)]	Loss: 0.001396
2020-06-07 23:23:53,200 | Train Epoch: 62 [53760/59392 (91%)]	Loss: 0.001412
2020-06-07 23:23:53,676 | Train Epoch: 62 [56320/59392 (95%)]	Loss: 0.001545
2020-06-07 23:23:54,136 | Train Epoch: 62 [58880/59392 (99%)]	Loss: 0.003248
2020-06-07 23:23:54,286 | ================================================================================
2020-06-07 23:23:54,345 | Setting learning rate to 0.00318826
2020-06-07 23:23:54,748 | Train Epoch: 63 [0/59392 (0%)]	Loss: 0.001519
2020-06-07 23:23:55,228 | Train Epoch: 63 [2560/59392 (4%)]	Loss: 0.001750
2020-06-07 23:23:55,705 | Train Epoch: 63 [5120/59392 (9%)]	Loss: 0.001481
2020-06-07 23:23:56,179 | Train Epoch: 63 [7680/59392 (13%)]	Loss: 0.001455
2020-06-07 23:23:56,659 | Train Epoch: 63 [10240/59392 (17%)]	Loss: 0.001313
2020-06-07 23:23:57,144 | Train Epoch: 63 [12800/59392 (22%)]	Loss: 0.001562
2020-06-07 23:23:57,642 | Train Epoch: 63 [15360/59392 (26%)]	Loss: 0.001670
2020-06-07 23:23:58,148 | Train Epoch: 63 [17920/59392 (30%)]	Loss: 0.001604
2020-06-07 23:23:58,661 | Train Epoch: 63 [20480/59392 (34%)]	Loss: 0.001497
2020-06-07 23:23:59,150 | Train Epoch: 63 [23040/59392 (39%)]	Loss: 0.001414
2020-06-07 23:23:59,660 | Train Epoch: 63 [25600/59392 (43%)]	Loss: 0.001516
2020-06-07 23:24:00,270 | Train Epoch: 63 [28160/59392 (47%)]	Loss: 0.001354
2020-06-07 23:24:00,750 | Train Epoch: 63 [30720/59392 (52%)]	Loss: 0.001772
2020-06-07 23:24:01,241 | Train Epoch: 63 [33280/59392 (56%)]	Loss: 0.001532
2020-06-07 23:24:01,755 | Train Epoch: 63 [35840/59392 (60%)]	Loss: 0.001536
2020-06-07 23:24:02,247 | Train Epoch: 63 [38400/59392 (65%)]	Loss: 0.001510
2020-06-07 23:24:02,726 | Train Epoch: 63 [40960/59392 (69%)]	Loss: 0.001454
2020-06-07 23:24:03,216 | Train Epoch: 63 [43520/59392 (73%)]	Loss: 0.001544
2020-06-07 23:24:03,708 | Train Epoch: 63 [46080/59392 (78%)]	Loss: 0.001656
2020-06-07 23:24:04,200 | Train Epoch: 63 [48640/59392 (82%)]	Loss: 0.001489
2020-06-07 23:24:04,757 | Train Epoch: 63 [51200/59392 (86%)]	Loss: 0.001473
2020-06-07 23:24:05,241 | Train Epoch: 63 [53760/59392 (91%)]	Loss: 0.001704
2020-06-07 23:24:05,724 | Train Epoch: 63 [56320/59392 (95%)]	Loss: 0.001580
2020-06-07 23:24:06,186 | Train Epoch: 63 [58880/59392 (99%)]	Loss: 0.002155
2020-06-07 23:24:06,343 | ================================================================================
2020-06-07 23:24:06,408 | Setting learning rate to 0.00244717
2020-06-07 23:24:06,803 | Train Epoch: 64 [0/59392 (0%)]	Loss: 0.001467
2020-06-07 23:24:07,301 | Train Epoch: 64 [2560/59392 (4%)]	Loss: 0.001478
2020-06-07 23:24:07,787 | Train Epoch: 64 [5120/59392 (9%)]	Loss: 0.001708
2020-06-07 23:24:08,263 | Train Epoch: 64 [7680/59392 (13%)]	Loss: 0.001589
2020-06-07 23:24:08,735 | Train Epoch: 64 [10240/59392 (17%)]	Loss: 0.001495
2020-06-07 23:24:09,209 | Train Epoch: 64 [12800/59392 (22%)]	Loss: 0.001474
2020-06-07 23:24:09,687 | Train Epoch: 64 [15360/59392 (26%)]	Loss: 0.001527
2020-06-07 23:24:10,164 | Train Epoch: 64 [17920/59392 (30%)]	Loss: 0.001413
2020-06-07 23:24:10,637 | Train Epoch: 64 [20480/59392 (34%)]	Loss: 0.001541
2020-06-07 23:24:11,108 | Train Epoch: 64 [23040/59392 (39%)]	Loss: 0.001740
2020-06-07 23:24:11,629 | Train Epoch: 64 [25600/59392 (43%)]	Loss: 0.001423
2020-06-07 23:24:12,103 | Train Epoch: 64 [28160/59392 (47%)]	Loss: 0.001555
2020-06-07 23:24:12,580 | Train Epoch: 64 [30720/59392 (52%)]	Loss: 0.001487
2020-06-07 23:24:13,051 | Train Epoch: 64 [33280/59392 (56%)]	Loss: 0.001328
2020-06-07 23:24:13,523 | Train Epoch: 64 [35840/59392 (60%)]	Loss: 0.001515
2020-06-07 23:24:14,005 | Train Epoch: 64 [38400/59392 (65%)]	Loss: 0.001671
2020-06-07 23:24:14,476 | Train Epoch: 64 [40960/59392 (69%)]	Loss: 0.001666
2020-06-07 23:24:14,949 | Train Epoch: 64 [43520/59392 (73%)]	Loss: 0.001561
2020-06-07 23:24:15,432 | Train Epoch: 64 [46080/59392 (78%)]	Loss: 0.001442
2020-06-07 23:24:15,913 | Train Epoch: 64 [48640/59392 (82%)]	Loss: 0.001345
2020-06-07 23:24:16,389 | Train Epoch: 64 [51200/59392 (86%)]	Loss: 0.001378
2020-06-07 23:24:16,860 | Train Epoch: 64 [53760/59392 (91%)]	Loss: 0.001464
2020-06-07 23:24:17,336 | Train Epoch: 64 [56320/59392 (95%)]	Loss: 0.001393
2020-06-07 23:24:17,817 | Train Epoch: 64 [58880/59392 (99%)]	Loss: 0.002435
2020-06-07 23:24:17,975 | ================================================================================
2020-06-07 23:24:30,163 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 39/256 (15.23%)
2020-06-07 23:24:34,077 | TEST: Clean loss: 0.0361, Clean accuracy: 8928/9001 (99.19%), PGD clean accuracy: 254/256 (99.22%), Robust accuracy 40/256 (15.62%)
2020-06-07 23:24:34,084 | ================================================================================
2020-06-07 23:24:34,160 | Setting learning rate to 0.00180186
2020-06-07 23:24:34,620 | Train Epoch: 65 [0/59392 (0%)]	Loss: 0.001610
2020-06-07 23:24:35,135 | Train Epoch: 65 [2560/59392 (4%)]	Loss: 0.001844
2020-06-07 23:24:35,623 | Train Epoch: 65 [5120/59392 (9%)]	Loss: 0.001919
2020-06-07 23:24:36,118 | Train Epoch: 65 [7680/59392 (13%)]	Loss: 0.001472
2020-06-07 23:24:36,622 | Train Epoch: 65 [10240/59392 (17%)]	Loss: 0.001607
2020-06-07 23:24:37,201 | Train Epoch: 65 [12800/59392 (22%)]	Loss: 0.001341
2020-06-07 23:24:37,693 | Train Epoch: 65 [15360/59392 (26%)]	Loss: 0.001354
2020-06-07 23:24:38,207 | Train Epoch: 65 [17920/59392 (30%)]	Loss: 0.001412
2020-06-07 23:24:38,713 | Train Epoch: 65 [20480/59392 (34%)]	Loss: 0.001701
2020-06-07 23:24:39,214 | Train Epoch: 65 [23040/59392 (39%)]	Loss: 0.001481
2020-06-07 23:24:39,705 | Train Epoch: 65 [25600/59392 (43%)]	Loss: 0.001694
2020-06-07 23:24:40,228 | Train Epoch: 65 [28160/59392 (47%)]	Loss: 0.001552
2020-06-07 23:24:40,712 | Train Epoch: 65 [30720/59392 (52%)]	Loss: 0.001401
2020-06-07 23:24:41,191 | Train Epoch: 65 [33280/59392 (56%)]	Loss: 0.001683
2020-06-07 23:24:41,678 | Train Epoch: 65 [35840/59392 (60%)]	Loss: 0.001343
2020-06-07 23:24:42,164 | Train Epoch: 65 [38400/59392 (65%)]	Loss: 0.001336
2020-06-07 23:24:42,663 | Train Epoch: 65 [40960/59392 (69%)]	Loss: 0.001445
2020-06-07 23:24:43,173 | Train Epoch: 65 [43520/59392 (73%)]	Loss: 0.001508
2020-06-07 23:24:43,669 | Train Epoch: 65 [46080/59392 (78%)]	Loss: 0.001792
2020-06-07 23:24:44,188 | Train Epoch: 65 [48640/59392 (82%)]	Loss: 0.001804
2020-06-07 23:24:44,674 | Train Epoch: 65 [51200/59392 (86%)]	Loss: 0.001488
2020-06-07 23:24:45,195 | Train Epoch: 65 [53760/59392 (91%)]	Loss: 0.001634
2020-06-07 23:24:45,681 | Train Epoch: 65 [56320/59392 (95%)]	Loss: 0.001762
2020-06-07 23:24:46,158 | Train Epoch: 65 [58880/59392 (99%)]	Loss: 0.024163
2020-06-07 23:24:46,310 | ================================================================================
2020-06-07 23:24:46,372 | Setting learning rate to 0.0012536
2020-06-07 23:24:46,807 | Train Epoch: 66 [0/59392 (0%)]	Loss: 0.001389
2020-06-07 23:24:47,282 | Train Epoch: 66 [2560/59392 (4%)]	Loss: 0.001579
2020-06-07 23:24:47,759 | Train Epoch: 66 [5120/59392 (9%)]	Loss: 0.001694
2020-06-07 23:24:48,263 | Train Epoch: 66 [7680/59392 (13%)]	Loss: 0.001528
2020-06-07 23:24:48,755 | Train Epoch: 66 [10240/59392 (17%)]	Loss: 0.001618
2020-06-07 23:24:49,228 | Train Epoch: 66 [12800/59392 (22%)]	Loss: 0.001552
2020-06-07 23:24:49,718 | Train Epoch: 66 [15360/59392 (26%)]	Loss: 0.001418
2020-06-07 23:24:50,195 | Train Epoch: 66 [17920/59392 (30%)]	Loss: 0.001698
2020-06-07 23:24:50,788 | Train Epoch: 66 [20480/59392 (34%)]	Loss: 0.001475
2020-06-07 23:24:51,302 | Train Epoch: 66 [23040/59392 (39%)]	Loss: 0.001638
2020-06-07 23:24:51,785 | Train Epoch: 66 [25600/59392 (43%)]	Loss: 0.001487
2020-06-07 23:24:52,305 | Train Epoch: 66 [28160/59392 (47%)]	Loss: 0.001416
2020-06-07 23:24:52,806 | Train Epoch: 66 [30720/59392 (52%)]	Loss: 0.001588
2020-06-07 23:24:53,289 | Train Epoch: 66 [33280/59392 (56%)]	Loss: 0.001772
2020-06-07 23:24:53,796 | Train Epoch: 66 [35840/59392 (60%)]	Loss: 0.001781
2020-06-07 23:24:54,283 | Train Epoch: 66 [38400/59392 (65%)]	Loss: 0.001748
2020-06-07 23:24:54,785 | Train Epoch: 66 [40960/59392 (69%)]	Loss: 0.001450
2020-06-07 23:24:55,276 | Train Epoch: 66 [43520/59392 (73%)]	Loss: 0.001458
2020-06-07 23:24:55,777 | Train Epoch: 66 [46080/59392 (78%)]	Loss: 0.001435
2020-06-07 23:24:56,280 | Train Epoch: 66 [48640/59392 (82%)]	Loss: 0.001684
2020-06-07 23:24:56,788 | Train Epoch: 66 [51200/59392 (86%)]	Loss: 0.001448
2020-06-07 23:24:57,380 | Train Epoch: 66 [53760/59392 (91%)]	Loss: 0.001662
2020-06-07 23:24:57,864 | Train Epoch: 66 [56320/59392 (95%)]	Loss: 0.001480
2020-06-07 23:24:58,339 | Train Epoch: 66 [58880/59392 (99%)]	Loss: 0.003356
2020-06-07 23:24:58,490 | ================================================================================
2020-06-07 23:24:58,557 | Setting learning rate to 0.000803521
2020-06-07 23:24:58,949 | Train Epoch: 67 [0/59392 (0%)]	Loss: 0.001615
2020-06-07 23:24:59,435 | Train Epoch: 67 [2560/59392 (4%)]	Loss: 0.001550
2020-06-07 23:24:59,938 | Train Epoch: 67 [5120/59392 (9%)]	Loss: 0.001570
2020-06-07 23:25:00,446 | Train Epoch: 67 [7680/59392 (13%)]	Loss: 0.001489
2020-06-07 23:25:00,958 | Train Epoch: 67 [10240/59392 (17%)]	Loss: 0.001426
2020-06-07 23:25:01,445 | Train Epoch: 67 [12800/59392 (22%)]	Loss: 0.001454
2020-06-07 23:25:01,930 | Train Epoch: 67 [15360/59392 (26%)]	Loss: 0.001738
2020-06-07 23:25:02,426 | Train Epoch: 67 [17920/59392 (30%)]	Loss: 0.001597
2020-06-07 23:25:03,016 | Train Epoch: 67 [20480/59392 (34%)]	Loss: 0.001520
2020-06-07 23:25:03,518 | Train Epoch: 67 [23040/59392 (39%)]	Loss: 0.001520
2020-06-07 23:25:04,021 | Train Epoch: 67 [25600/59392 (43%)]	Loss: 0.001568
2020-06-07 23:25:04,504 | Train Epoch: 67 [28160/59392 (47%)]	Loss: 0.001695
2020-06-07 23:25:04,997 | Train Epoch: 67 [30720/59392 (52%)]	Loss: 0.001401
2020-06-07 23:25:05,484 | Train Epoch: 67 [33280/59392 (56%)]	Loss: 0.001462
2020-06-07 23:25:06,009 | Train Epoch: 67 [35840/59392 (60%)]	Loss: 0.001718
2020-06-07 23:25:06,524 | Train Epoch: 67 [38400/59392 (65%)]	Loss: 0.001960
2020-06-07 23:25:07,031 | Train Epoch: 67 [40960/59392 (69%)]	Loss: 0.001646
2020-06-07 23:25:07,543 | Train Epoch: 67 [43520/59392 (73%)]	Loss: 0.001663
2020-06-07 23:25:08,051 | Train Epoch: 67 [46080/59392 (78%)]	Loss: 0.001607
2020-06-07 23:25:08,557 | Train Epoch: 67 [48640/59392 (82%)]	Loss: 0.001558
2020-06-07 23:25:09,050 | Train Epoch: 67 [51200/59392 (86%)]	Loss: 0.001583
2020-06-07 23:25:09,543 | Train Epoch: 67 [53760/59392 (91%)]	Loss: 0.001752
2020-06-07 23:25:10,020 | Train Epoch: 67 [56320/59392 (95%)]	Loss: 0.001540
2020-06-07 23:25:10,477 | Train Epoch: 67 [58880/59392 (99%)]	Loss: 0.002510
2020-06-07 23:25:10,635 | ================================================================================
2020-06-07 23:25:10,697 | Setting learning rate to 0.000452512
2020-06-07 23:25:11,092 | Train Epoch: 68 [0/59392 (0%)]	Loss: 0.001399
2020-06-07 23:25:11,569 | Train Epoch: 68 [2560/59392 (4%)]	Loss: 0.001446
2020-06-07 23:25:12,029 | Train Epoch: 68 [5120/59392 (9%)]	Loss: 0.001333
2020-06-07 23:25:12,508 | Train Epoch: 68 [7680/59392 (13%)]	Loss: 0.001639
2020-06-07 23:25:12,973 | Train Epoch: 68 [10240/59392 (17%)]	Loss: 0.001373
2020-06-07 23:25:13,448 | Train Epoch: 68 [12800/59392 (22%)]	Loss: 0.001486
2020-06-07 23:25:13,917 | Train Epoch: 68 [15360/59392 (26%)]	Loss: 0.001538
2020-06-07 23:25:14,404 | Train Epoch: 68 [17920/59392 (30%)]	Loss: 0.001432
2020-06-07 23:25:14,901 | Train Epoch: 68 [20480/59392 (34%)]	Loss: 0.001387
2020-06-07 23:25:15,383 | Train Epoch: 68 [23040/59392 (39%)]	Loss: 0.001352
2020-06-07 23:25:15,846 | Train Epoch: 68 [25600/59392 (43%)]	Loss: 0.001510
2020-06-07 23:25:16,411 | Train Epoch: 68 [28160/59392 (47%)]	Loss: 0.001978
2020-06-07 23:25:16,884 | Train Epoch: 68 [30720/59392 (52%)]	Loss: 0.001981
2020-06-07 23:25:17,389 | Train Epoch: 68 [33280/59392 (56%)]	Loss: 0.001625
2020-06-07 23:25:17,861 | Train Epoch: 68 [35840/59392 (60%)]	Loss: 0.001697
2020-06-07 23:25:18,356 | Train Epoch: 68 [38400/59392 (65%)]	Loss: 0.001433
2020-06-07 23:25:18,833 | Train Epoch: 68 [40960/59392 (69%)]	Loss: 0.001555
2020-06-07 23:25:19,338 | Train Epoch: 68 [43520/59392 (73%)]	Loss: 0.001575
2020-06-07 23:25:19,804 | Train Epoch: 68 [46080/59392 (78%)]	Loss: 0.001685
2020-06-07 23:25:20,271 | Train Epoch: 68 [48640/59392 (82%)]	Loss: 0.001668
2020-06-07 23:25:20,733 | Train Epoch: 68 [51200/59392 (86%)]	Loss: 0.001685
2020-06-07 23:25:21,251 | Train Epoch: 68 [53760/59392 (91%)]	Loss: 0.001499
2020-06-07 23:25:21,743 | Train Epoch: 68 [56320/59392 (95%)]	Loss: 0.001742
2020-06-07 23:25:22,225 | Train Epoch: 68 [58880/59392 (99%)]	Loss: 0.002859
2020-06-07 23:25:22,425 | ================================================================================
2020-06-07 23:25:34,093 | TRAIN: Clean loss: 0.0011, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 40/256 (15.62%)
2020-06-07 23:25:37,973 | TEST: Clean loss: 0.0377, Clean accuracy: 8927/9001 (99.18%), PGD clean accuracy: 255/256 (99.61%), Robust accuracy 40/256 (15.62%)
2020-06-07 23:25:37,984 | ================================================================================
2020-06-07 23:25:38,051 | Setting learning rate to 0.000201285
2020-06-07 23:25:38,449 | Train Epoch: 69 [0/59392 (0%)]	Loss: 0.001456
2020-06-07 23:25:38,958 | Train Epoch: 69 [2560/59392 (4%)]	Loss: 0.001527
2020-06-07 23:25:39,435 | Train Epoch: 69 [5120/59392 (9%)]	Loss: 0.001798
2020-06-07 23:25:39,930 | Train Epoch: 69 [7680/59392 (13%)]	Loss: 0.001485
2020-06-07 23:25:40,426 | Train Epoch: 69 [10240/59392 (17%)]	Loss: 0.001491
2020-06-07 23:25:40,923 | Train Epoch: 69 [12800/59392 (22%)]	Loss: 0.002162
2020-06-07 23:25:41,392 | Train Epoch: 69 [15360/59392 (26%)]	Loss: 0.001612
2020-06-07 23:25:41,858 | Train Epoch: 69 [17920/59392 (30%)]	Loss: 0.001646
2020-06-07 23:25:42,346 | Train Epoch: 69 [20480/59392 (34%)]	Loss: 0.001776
2020-06-07 23:25:42,846 | Train Epoch: 69 [23040/59392 (39%)]	Loss: 0.001330
2020-06-07 23:25:43,348 | Train Epoch: 69 [25600/59392 (43%)]	Loss: 0.001793
2020-06-07 23:25:43,844 | Train Epoch: 69 [28160/59392 (47%)]	Loss: 0.001495
2020-06-07 23:25:44,349 | Train Epoch: 69 [30720/59392 (52%)]	Loss: 0.001492
2020-06-07 23:25:44,842 | Train Epoch: 69 [33280/59392 (56%)]	Loss: 0.001607
2020-06-07 23:25:45,339 | Train Epoch: 69 [35840/59392 (60%)]	Loss: 0.001550
2020-06-07 23:25:45,858 | Train Epoch: 69 [38400/59392 (65%)]	Loss: 0.001402
2020-06-07 23:25:46,352 | Train Epoch: 69 [40960/59392 (69%)]	Loss: 0.002160
2020-06-07 23:25:46,865 | Train Epoch: 69 [43520/59392 (73%)]	Loss: 0.001412
2020-06-07 23:25:47,382 | Train Epoch: 69 [46080/59392 (78%)]	Loss: 0.001590
2020-06-07 23:25:47,942 | Train Epoch: 69 [48640/59392 (82%)]	Loss: 0.001428
2020-06-07 23:25:48,453 | Train Epoch: 69 [51200/59392 (86%)]	Loss: 0.001489
2020-06-07 23:25:48,964 | Train Epoch: 69 [53760/59392 (91%)]	Loss: 0.001708
2020-06-07 23:25:49,454 | Train Epoch: 69 [56320/59392 (95%)]	Loss: 0.001502
2020-06-07 23:25:49,964 | Train Epoch: 69 [58880/59392 (99%)]	Loss: 0.003922
2020-06-07 23:25:50,138 | ================================================================================
2020-06-07 23:25:50,201 | Setting learning rate to 5.03467e-05
2020-06-07 23:25:50,614 | Train Epoch: 70 [0/59392 (0%)]	Loss: 0.001432
2020-06-07 23:25:51,096 | Train Epoch: 70 [2560/59392 (4%)]	Loss: 0.001772
2020-06-07 23:25:51,586 | Train Epoch: 70 [5120/59392 (9%)]	Loss: 0.001501
2020-06-07 23:25:52,061 | Train Epoch: 70 [7680/59392 (13%)]	Loss: 0.001370
2020-06-07 23:25:52,549 | Train Epoch: 70 [10240/59392 (17%)]	Loss: 0.001420
2020-06-07 23:25:53,018 | Train Epoch: 70 [12800/59392 (22%)]	Loss: 0.001487
2020-06-07 23:25:53,517 | Train Epoch: 70 [15360/59392 (26%)]	Loss: 0.001464
2020-06-07 23:25:54,002 | Train Epoch: 70 [17920/59392 (30%)]	Loss: 0.001667
2020-06-07 23:25:54,483 | Train Epoch: 70 [20480/59392 (34%)]	Loss: 0.001600
2020-06-07 23:25:55,063 | Train Epoch: 70 [23040/59392 (39%)]	Loss: 0.001605
2020-06-07 23:25:55,562 | Train Epoch: 70 [25600/59392 (43%)]	Loss: 0.001732
2020-06-07 23:25:56,074 | Train Epoch: 70 [28160/59392 (47%)]	Loss: 0.001503
2020-06-07 23:25:56,564 | Train Epoch: 70 [30720/59392 (52%)]	Loss: 0.001410
2020-06-07 23:25:57,058 | Train Epoch: 70 [33280/59392 (56%)]	Loss: 0.001582
2020-06-07 23:25:57,567 | Train Epoch: 70 [35840/59392 (60%)]	Loss: 0.001792
2020-06-07 23:25:58,057 | Train Epoch: 70 [38400/59392 (65%)]	Loss: 0.001544
2020-06-07 23:25:58,567 | Train Epoch: 70 [40960/59392 (69%)]	Loss: 0.001518
2020-06-07 23:25:59,078 | Train Epoch: 70 [43520/59392 (73%)]	Loss: 0.001623
2020-06-07 23:25:59,593 | Train Epoch: 70 [46080/59392 (78%)]	Loss: 0.001697
2020-06-07 23:26:00,165 | Train Epoch: 70 [48640/59392 (82%)]	Loss: 0.001602
2020-06-07 23:26:00,669 | Train Epoch: 70 [51200/59392 (86%)]	Loss: 0.001445
2020-06-07 23:26:01,168 | Train Epoch: 70 [53760/59392 (91%)]	Loss: 0.001503
2020-06-07 23:26:01,656 | Train Epoch: 70 [56320/59392 (95%)]	Loss: 0.001479
2020-06-07 23:26:02,128 | Train Epoch: 70 [58880/59392 (99%)]	Loss: 0.003255
2020-06-07 23:26:02,286 | ================================================================================
2020-06-07 23:26:13,926 | TRAIN: Clean loss: 0.0012, Clean accuracy: 59001/59001 (100.00%), PGD clean accuracy: 256/256 (100.00%), Robust accuracy 40/256 (15.62%)
2020-06-07 23:26:17,803 | TEST: Clean loss: 0.0384, Clean accuracy: 8927/9001 (99.18%), PGD clean accuracy: 255/256 (99.61%), Robust accuracy 38/256 (14.84%)
2020-06-07 23:26:17,810 | ================================================================================
